<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Little Umbrellas - ling</title><link href="http://dlukes.github.io/" rel="alternate"></link><link href="http://dlukes.github.io/feeds/ling.atom.xml" rel="self"></link><id>http://dlukes.github.io/</id><updated>2016-07-21T00:00:00+02:00</updated><entry><title>The Cathedral and the Bazaar: What is a Useful Notion of “Language”?</title><link href="http://dlukes.github.io/cathedral-and-bazaar.html" rel="alternate"></link><published>2016-07-21T00:00:00+02:00</published><updated>2016-07-21T00:00:00+02:00</updated><author><name>dlukes</name></author><id>tag:dlukes.github.io,2016-07-21:/cathedral-and-bazaar.html</id><summary type="html">&lt;p&gt;Why Noam Chomsky's approach to linguistics is broken, and why you should take a look at agent-based models of language evolution.&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you like the essay, then you'll definitely want to take a look at Luc
Steels's &lt;em&gt;The Talking Heads Experiment: Origins of Words and Meanings&lt;/em&gt;. It's
published as an open-access book by Language Science Press, so
&lt;a href="http://langsci-press.org//catalog/book/49"&gt;go grab the free download&lt;/a&gt;!&lt;/p&gt;
&lt;h1&gt;Abstract&lt;/h1&gt;
&lt;p&gt;The essay analyzes why Noam Chomsky’s notion of language (both its
essence — language as a set of grammatical sentences — and genesis)
leads neither to interesting discoveries nor even to useful questions
from the point of view of linguistics as a science. A much more fruitful
approach to language is to view it as a complex, dynamic, distributed
system with emergent properties stemming from its functions, as
advocated e.g. by Luc Steels. The argument will be developed against the
backdrop of the evolution of Ludwig Wittgenstein’s thought, from the
&lt;em&gt;Tractatus&lt;/em&gt; to the concept of language games, i.e. from an approach to
language based on thorough formal analysis but also misconceptions about
its functions, to a much keener though less formal grasp of its praxis
and purpose.&lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;At least since Thomas Kuhn’s &lt;em&gt;The Structure of Scientific Revolutions&lt;/em&gt;,
it has been a fairly commonplace notion that working within the confines
of a particular scientific paradigm conditions to a certain extent the
questions one is likely to ask and therefore also the answers that
ensue. This effectively limits the range of possible discoveries,
because some are not answers to meaningful questions within a given
framework while other observations still are taken as given axioms,
which means they cannot be the target of further scientific
investigation.&lt;/p&gt;
&lt;p&gt;In contemporary linguistics, one very prominent such paradigm is that of
&lt;em&gt;generative grammar&lt;/em&gt;, single-handedly established in 1957 by Noam
Chomsky in his seminal work &lt;em&gt;Syntactic Structures&lt;/em&gt;. While serious
criticism has been leveled over time against this initial exposition as
well as Chomsky’s subsequent elaborations on it (see Pullum 2011;
Sampson 2015; and Sampson 2005 for a book-length treatment), the book
undeniably attracted significant numbers of brilliant young minds under
the wings of its research program, which went from aspiring challenger
in the domain of linguistics to established heavyweight in a
comparatively short period of time (the transition had been achieved by
the mid-1970s at the latest). In the process, it co-opted or spawned
various other sub-fields of linguistics, and even rebranded itself, such
that &lt;em&gt;Cartesian linguistics&lt;/em&gt;, &lt;em&gt;cognitive linguistics&lt;/em&gt; and most recently
&lt;em&gt;biolinguistics&lt;/em&gt; are all labels which suggest a strong generativist
presence.&lt;/p&gt;
&lt;p&gt;One serious competitor to the Chomskyan account of language that has
emerged over the years is the field of &lt;em&gt;evolutionary linguistics&lt;/em&gt;. It
might seem strange at first glance why biolinguistics and evolutionary
linguistics should be at odds. As their names indicate, they both aspire
to a close relationship with biology, which seems to indicate their
research agendas and outlooks should largely overlap. Yet their
fundamental assumptions about what constitutes language are so
irreconcilable that they might as well be considered to deal with
different objects of study. Of the two, it is evolutionary linguistics
which leads to questions and investigations which can be conceived of as
scientific (in the Popperian sense of involving falsifiable hypotheses
instead of being merely speculative), consequently yielding the most
useful insights – in the fairly pedestrian sense that these can be
intersubjectively replicated without resorting to an argument from
authority, which makes them a better foundation to build upon, because
the superadded structures are less likely to crumble should said
authority ever change their mind, as Chomsky has done several times
already.&lt;/p&gt;
&lt;h1&gt;Wittgenstein on language: From logical calculus to language games&lt;/h1&gt;
&lt;p&gt;Let us now take a short détour through the development of Ludwig
Wittgenstein’s thoughts on language, so that we may couch our later
discussion of the differences between generative grammar /
biolinguistics and evolutionary linguistics in terms of a contrast that
is perhaps more familiar. The imagery in the title of the present essay
was borrowed from Eric S. Raymond’s book &lt;em&gt;The Cathedral &amp;amp; the Bazaar:
Musings on Linux and Open Source by an Accidental Revolutionary&lt;/em&gt;
(Raymond 1999). In it, Raymond describes two models of collaborative
software development, one of them very rigid, restrictive and hostile to
newcomers (the “cathedral”), the other overwhelmingly inclusive, open to
outside contributions and organic change, an effervescent hive of
activity (the “bazaar”), whose unexpected but empirically demonstrable
virtues he has come to embrace.&lt;/p&gt;
&lt;p&gt;This architectural metaphor also happens to be very apt when
characterizing Wittgenstein’s view of language in the two major stages
of his thought, as represented by his two books &lt;em&gt;Tractatus
Logico-Philosophicus&lt;/em&gt; and &lt;em&gt;Philosophical Investigations&lt;/em&gt;. In the
&lt;em&gt;Tractatus&lt;/em&gt;, Wittgenstein has a “preconceived idea of language as an
exact calculus operated according to precise rules” (McGinn 2006, 12)
and formalizing this system of rules leads him to the following dogmatic
conclusion: “what can be said at all can be said clearly, and what we
cannot talk about we must pass over in silence” (Wittgenstein 2001, 3).
The deontic force of the final injunction should be taken with a grain
of salt; it could perhaps be rephrased in the following less
epigraph-worthy manner: there is a sharp logical boundary to be drawn
between meaningful and nonsensical propositions, and the purpose of
language is to construct meaningful ones, therefore it is futile (rather
than strictly forbidden) to engage in nonsensical ones.&lt;/p&gt;
&lt;p&gt;There have been attempts to read the &lt;em&gt;Tractatus&lt;/em&gt; in an ironic mode, as a
consciously doomed, self-defeating attempt to circumscribe the limits to
the expression of thought, which prefigures the much more subtle
attitude towards language that Wittgenstein later exhibits in the
&lt;em&gt;Philosophical Investigations&lt;/em&gt; (see McGinn 2006, 5–6 and elsewhere for
an overview of this so-called “resolute” reading). In my opinion, such a
stance exhibits a blatant, possibly wilful disregard of his almost
penitent tone in the preface to &lt;em&gt;Philosophical Investigations&lt;/em&gt;: “I could
not but recognize grave mistakes in what I set out in that first book”
(Wittgenstein 2009, 4e).&lt;/p&gt;
&lt;p&gt;Where does Wittgenstein think he went wrong then? Arguably, the most
serious misconception was conferring a privileged ontological status to
language, seeing it as “the unique correlate, picture, of the world”
(Wittgenstein 2009, 49e), whereas in fact, these referential properties
are highly dependent on communicative context. It signifies only insofar
as it has an effect on the addressee (another human being, or even
myself) which to all practical intents and purposes the speaker can
identify as somehow related to what she was trying to achieve with her
utterance in the first place. But there is little meaning, in any
practical sense, outside these highly particular, localized (in both
physical and cultural space and time), embodied, grounded interactions.
Wittgenstein calls these interactions “language-games” to “emphasize the
fact that the &lt;em&gt;speaking&lt;/em&gt; of language is part of an activity, or of a
form of life” (Wittgenstein 2009, 15e, original emphasis). Of course,
the notion of game still involves some kind of rules, but by focusing on
the activity rather than its regulations, it is much easier to account
for “the case where we play, and make up the rules as we go along […]
and even where we alter them – as we go along” (Wittgenstein 2009, 44e).&lt;/p&gt;
&lt;p&gt;This is not to say that we cannot construct abstractions, although
Wittgenstein himself is clearly in favor of systematically examining
particular cases: “In order to see more clearly, here as in countless
similar cases, we must look at what really happens &lt;em&gt;in detail&lt;/em&gt;, as it
were from close up” (Wittgenstein 2009, 30e). However, once we do
abstract away, it is crucial to approach the resulting theory from a
pragmatic standpoint: “We want to establish an order in our knowledge of
language: an order for a particular purpose, one out of many possible
orders, not &lt;em&gt;the&lt;/em&gt; order” (Wittgenstein 2009, 56e, original emphasis).&lt;/p&gt;
&lt;h1&gt;Generative grammar&lt;/h1&gt;
&lt;p&gt;In many ways, Chomsky conceives of language as the early Wittgenstein
did, i.e. under the cathedral metaphor. This may come across as a
surprise because unlike Wittgenstein, he is not concerned with issues of
meaningfulness, philosophical or otherwise. Indeed, it is one of his
fundamental precepts that grammar can and should be dissociated from
meaning, as demonstrated by his famous example sentence “Colorless green
ideas sleep furiously”, which he claims is perfectly grammatical yet
meaningless&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; (Chomsky 2002, Chap. 2).&lt;/p&gt;
&lt;p&gt;Nevertheless, the goal for both is to describe language &lt;em&gt;per se&lt;/em&gt;, in the
abstract, without regard to its context-grounded use in actual
communication. Both strive to give a highly formal definition of the
system they think they are uncovering: while Wittgenstein attempts to
establish a logical calculus of how propositions can be said to carry
meaning in terms of their referential relationship to external reality,
Chomsky tries to hint at a calculus which would determine which
candidate sentences belong to the language encoded by this calculus,
i.e. separate those that are grammatical from those that are not.&lt;/p&gt;
&lt;p&gt;Another way to put this is that the descriptive part of linguistics can
be equated with formal language theory: a language is viewed as a
(potentially infinite) set of symbol strings (sentences), and the
linguist’s task is to find the simplest and most elegant set of rules
that would constitute the basis for a procedure to generate (hence
&lt;em&gt;generative&lt;/em&gt; grammar) all of them and only those, whether observed or
potential. Chomsky himself gives the following definition: “by a
generative grammar I mean simply a system of rules that in some explicit
and well-defined way assigns structural descriptions to sentences”
(Chomsky 1965, 8).&lt;/p&gt;
&lt;p&gt;Furthermore, “Linguistic theory is concerned primarily with an ideal
speaker-listener, in a completely homogeneous speech-community, who
knows its language perfectly” (Chomsky 1965, 3). Specifically, it is
concerned with his “&lt;em&gt;competence&lt;/em&gt; (the speaker-hearer’s [intrinsic]
knowledge of his language)”, not his “&lt;em&gt;performance&lt;/em&gt; (the actual use of
language in concrete situations)” (Chomsky 1965, 4). Additionally, no
claim is made as to the cognitive or neurophysiological accuracy of the
mechanisms described, although to hedge his bets both ways, Chomsky adds
that “No doubt, a reasonable model of language use will incorporate, as
a basic component, the generative grammar that expresses the
speaker-hearer’s knowledge of the language” (Chomsky 1965, 9).&lt;/p&gt;
&lt;p&gt;In short, Chomsky consciously sets up the playing field for a thoroughly
mentalistic, speculative discipline. At first, it might seem like
reasonable approximation and a small concession to make, especially in
the face of the sheer daunting complexity of all the intricate
mechanisms that conspire to yield the phenomenon we call language, but
only until one fully realizes the consequences of such a move. Observe
for instance the carefully crafted loophole claiming that linguistics is
primarily concerned with an ideal speaker-hearer’s competence and that
actual usage data is just circumstantial evidence. This effectively
allows linguists to dismiss inconvenient edge cases or counterexamples
to their theories purely on grounds of their being noisy data or slips
of the tongue, which is something they are allowed to determine based on
introspection. Mind you, this is not just a theoretical loophole;
Chomsky himself has repeatedly relied on it, especially with respect to
so-called linguistic universals (see e.g. Sampson 2005, 139 or 160).&lt;/p&gt;
&lt;p&gt;The net result is rampant, unchecked theorizing. One such example is the
postulation of a two-layer linguistic analysis, the observed language
data corresponding to a surface structure which provides hints as to an
underlying, more regular deep structure to be uncovered. The deep
structure is purportedly closer to the universal properties of language;
both layers are linked by a system of transformations:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We can greatly simplify the description of English and gain new and important
insight into its formal structure if we limit the direct description in terms
of phrase structure to a kernel of basic sentences (simple, declarative,
active, with no complex verb or noun phrases), deriving all other sentences
from these (more properly, from the strings that underlie them) by
transformation, possibly repeated. (Chomsky 2002, 106–7)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Constructing a formal framework for grammar modeling with cognitively
unmotivated levels of abstraction might have been a valid goal (though
arguably not within linguistics) if the result was indeed, as Chomsky
claims it to be, maximally elegant, as simple as can be but no simpler.
I was not able to track down a formal definition of this criterion, but
simplicity is clearly discursively construed as a desirable quality:
“simple and revealing” (Chomsky 2002, 11) or “effective and
illuminating” (Chomsky 2002, 13) are Chomsky’s choice epithets for what
to look for in a grammar. But that is not true either: transformations
are an unnecessary addition, singling them out as a separate category of
operations adds nothing to the generative power of his system (Pullum
2011, 290). They are therefore a wart under any reasonable definition of
“simplicity” and Chomsky thus manages to fall short of even the
self-defined, theory-internal standards that are the only ones he allows
his enterprise to be held to.&lt;/p&gt;
&lt;h1&gt;Ontogeny and phylogeny&lt;/h1&gt;
&lt;p&gt;As we have seen, generative grammar concerns itself with an ideal
speaker-hearer’s competence in a perfectly homogeneous community. The
trouble is that such an impoverished model eschews any possibility of
dynamism. The very dichotomy between grammatical and ungrammatical is
intuitively problematic if we consider that judgments are bound to
diverge when made in reference to different dialects, sociolects and
idiolects,&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; not to mention that binary classification might be too
reductive in some cases (how would you categorize, on first encounter, a
construction which you passively understand but would never produce
actively?). Though Chomsky sometimes mentions in passing the possibility
of levels of grammaticalness which would allow a finer-grained analysis
(e.g. Chomsky 2002, 16; Chomsky 1965, 11), it seems to be just another
instance of hedging his bets, he never makes it a fundamental component
of his theory. This would seem to indicate that Chomsky’s theory of
language has a serious problem in that it is unable to account for any
phenomena that involve fluctuations in linguistic ability, including
language emergence / diachronic change (phylogeny) and acquisition
(ontogeny).&lt;/p&gt;
&lt;p&gt;Chomsky’s response to this is that our language faculty is largely
innate: we are genetically endowed with a &lt;em&gt;language-acquisition device&lt;/em&gt;
in our brains (Chomsky 1965, 31–33) which can supposedly infer the
correct grammatical rules even given incomplete, limited and noisy
input, which is what Chomsky argues children get (the “poverty of
stimulus” argument), thanks to strong universal constraints on what a
human language can be like. Under this account, the capacity for
language, initially “a language of thought, later externalized and used
in many ways” (Chomsky 2007, 24), appeared as a random mutation in a
single individual and progressively spread through the population
because it offered a considerable competitive advantage: “capacities for
complex thought, planning, interpretation” (Chomsky 2007, 22).&lt;/p&gt;
&lt;p&gt;In his later career, Chomsky increasingly focused on exploring this
purported shared genetic basis for human language, hence the
aforementioned label “biolinguistics”. Make no mistake, this in no way
entails a turn from mentalism towards empirical neurophysiological or
genetic investigation. Quite to the contrary, liberated from the
constraints of having to account for individual existing languages in
detail, he soars to new heights of abstractness in postulating the
formal language underpinnings of human language. The &lt;em&gt;principles and
parameters&lt;/em&gt; model of Universal Grammar (Chomsky 1986) expands upon the
notion of linguistic universals by splitting them up into two sets:
principles, which are hardwired and immutable, and parameters, which are
hardwired too but can be flipped on or off based on linguistic behavior
observed by the child in her particular language community. Since the
choices are heavily constrained, the learner can infer correct parameter
settings in spite of deficient input. This line of research culminates
in the so-called &lt;em&gt;minimalist program&lt;/em&gt; (Chomsky 1995), where Chomsky
identifies the “core principle of language, [the operation of]
unbounded Merge” (Chomsky 2007, 22). Under the “strong” minimalist
hypothesis, this would be the only principle necessary to account for
human-like languages (Chomsky 2007, 20), which would paradoxically
essentially discard all work (or should I say speculation?) previously
done on the parameters side of the Universal Grammar project. All other
universal characteristics of language could then be explained by newly
introduced “interface” conditions,&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt; i.e. constraints on how language
inter-operates with other systems, including thought and physical
language production (Chomsky 2007, 14);&lt;sup id="fnref-4"&gt;&lt;a class="footnote-ref" href="#fn-4"&gt;4&lt;/a&gt;&lt;/sup&gt; all empirically documented
variation between the world’s languages would be chalked up to lexical
differences (Chomsky 2007, 25).&lt;/p&gt;
&lt;p&gt;The poverty of stimulus and language universals arguments for innateness
have been thoroughly debunked, especially in Geoffrey Sampson’s
book-length diatribe &lt;em&gt;The &lt;/em&gt;‘&lt;em&gt;Language Instinct&lt;/em&gt;’&lt;em&gt; Debate&lt;/em&gt;. In short, it
turns out that some of the grammatical constructions which were assumed
to be absent from a language learner’s input yet acquired nonetheless
have since been empirically proven to occur fairly commonly (Sampson
2005, 72–79). Moreover, there is no qualitative difference between a
statement like “the stimulus is too poor to allow language learning
without a genetic basis” and “the stimulus is just rich enough etc.”,
both are unverifiable unless we have already independently proven that
language learning occurs one way or the other, so to adduce either of
the statements as proof for the hypothesis at stake is misguided
(Sampson 2005, 47–48). Finally, the alleged language universals turn out
to be either false when checked against additional languages (Sampson
2005, 138–9) or so general as to be meaningless (Sampson 2005, Chap. 5).&lt;/p&gt;
&lt;p&gt;Irrespective of this, let us suppose for a moment that genetic mutation
and subsequent inheritance do play a role in the emergence of language,
and work out an account of language emergence consistent with this
hypothesis. If language started out through mutation in a single
individual as a purely internal advanced conceptualization faculty, then
once it started to spread, what was the motivation for the
genetically-endowed humans to externalize their thoughts? How did they
know to which of their peers they could speak (which had inherited the
mutation) and which not? And most importantly, how did they know which
parameters of Universal Grammar to flip on and which off, if there was
no prior language based on which to decide? Universal Grammar would have
had to be fairly detailed in order for intersubjective agreement on the
norms for the first ever human language to be reached on the basis of it
alone. Yet as we have seen, Chomsky has been moving away from this
notion – at the limit, the minimalist program posits only one very
general mechanism required for language. The poverty of stimulus
argument is turned against its creator as the argument from poverty of
the machinery supposed to make up for the poverty of said stimulus.&lt;/p&gt;
&lt;p&gt;Alternatively, if we fully subscribe to the minimalist program and the
notion that all the surface variety exhibited by language comes from the
lexicon, then how are individual words created, how do they propagate?
One might be tempted to say “people just invented them”, but consider
for a while that in the current setup, there is absolutely no mechanism
that would explain how a community of speakers reaches agreement on
their lexicon – this theory offers no incentive whatsoever for consensus
to be reached; from its point of view, a solution where each speaker
ends up with their own private lexicon is equally valid because
indistinguishable on the basis of the theory’s conceptual apparatus.
Chomsky’s ideas on phylogenesis appear thoroughly ridiculous when fully
carried out to their logical consequences, and this can all be blamed on
his sterile, idealized and static view of language which dismisses
actual communication as a secondary purpose and therefore a peripheral
issue.&lt;/p&gt;
&lt;p&gt;On a side note, it is hard to say which aspect of Chomsky’s theory of
language came first – whether innateness accommodated the mentalism and
the concomitant quest for formal purity (botched as it may be) of
generative grammar, whether it was the other way round, or whether they
perhaps co-evolved in his mind. The facts are that Chomsky’s initial
publications on generative grammar concentrate on the formal language
theory part (Chomsky 1956; Chomsky 2002), but he added the innateness
argument fairly early on, even tacking a seemingly respectable
philosophical lineage onto it in &lt;em&gt;Cartesian Linguistics&lt;/em&gt; (Chomsky 2009),
which pretends to trace back both innateness and mentalism to Descartes
and the Port-Royal grammarians, binding them as two sides of the same
coin. It is worth noting that in both formal language theory and history
of linguistics / philosophy, Chomsky is more of a dabbler than an
expert: he has provably borrowed most of his ideas in the former field
from others, sometimes mangling them or extending them in unfortunate
ways (Pullum 2011; Sampson 2015), and has thoroughly underresearched (or
wilfully twisted?) his understanding of the latter, which has resulted
in serious misrepresentations of the history of ideas (Miel 1969;
Aarsleff 1970).&lt;/p&gt;
&lt;h1&gt;Evolutionary linguistics&lt;/h1&gt;
&lt;p&gt;There are various sub-fields of linguistics which are in discord with
generative grammar, especially over the notion that performance data
should be used only as evidence for guiding the speculation and detailed
usage and frequency patterns should be disregarded; the primacy of
syntax (as advocated by Chomsky) is also disputed. One of these
sub-fields is obviously corpus linguistics, which takes a decidedly
empiricist stance and starts by assembling a large body of language data
(a corpus) from which patterns of language use are inferred.
Nevertheless, not all of these compete with generative grammar at the
fundamental explanatory level of how language came about
phylogenetically and how it is transmitted by ontogenetic acquisition.&lt;/p&gt;
&lt;p&gt;We have repeatedly encountered Chomsky’s emphasis on how communication,
actual interactions between speakers, are just an afterthought in the
system of language:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;evolutionary biologist Salvador Luria was the most forceful advocate of the
view that communicative needs would not have provided “any great selective
pressure to produce a system such as language,” with its crucial relation to
“development of abstract or productive thinking.” His fellow Nobel laureate
François Jacob (1977) added later that “the role of language as a
communication system between individuals would have come about only
secondarily, as many linguists believe,” (Chomsky 2007, 23)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Part of this vehemence dovetails with the single individual mutation
hypothesis of the origins of language – it helps if the significance of
communication is downplayed in an account where communication is
initially impossible, simply because there is no other language-endowed
being to communicate with. If communication were language’s killer
feature, then the selective pressure for the incriminated gene to
propagate would not kick in.&lt;/p&gt;
&lt;p&gt;The other part can reasonably be attributed to Chomsky’s intent to make
a clean break from a prior popular theory on language acquisition,
epitomized by B. F. Skinner’s 1957 monograph &lt;em&gt;Verbal Behavior&lt;/em&gt;, which
offered a heavily empiricist, behaviorist account of language learning
in terms of a stimulus-response cycle. Characteristically, Chomsky’s
strategy is to trivialize the function of the stimulus, casually
implying both that it might not be needed at all, and if it is, then
details of the role it plays are of little interest:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;it would not be at all surprising to find that normal language learning
requires use of language in real-life situations, in some way. But this, if
true [sic!], would not be sufficient to show that information regarding
situational context (in particular, a pairing of signals with structural
descriptions that is at least in part prior to assumptions about syntactic
structure) plays any role in determining how language is acquired, once the
mechanism is put to work and the task of language learning is undertaken by
the child. (Chomsky 1965, 33)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In retrospect, Skinner’s account may be simplistic in many ways, but the
basic notion that one has to pay attention to stimuli and responses in
the course of particular linguistic interactions is sound. In
particular, a theory of language built on this foundation successfully
copes with all of the impasses we have explored above regarding
Chomsky’s approach. One such framework is that of evolutionary
linguistics.&lt;/p&gt;
&lt;p&gt;Evolutionary linguistics views language as a &lt;em&gt;complex adaptive system&lt;/em&gt;
with &lt;em&gt;emergent properties&lt;/em&gt; (Steels 2015, 8–9). A complex adaptive system
is a system which is not centrally organized, coordinated or designed:
its “macroscopic” characteristics are said to “emerge” as the result of
localized interactions between individual entities (agents) with similar
“microscopic” characteristics (be they physical, behavioral or
motivational). The whole is more than the sum of its parts, and none of
the agents can be properly said to have designed the system, nor can
they deliberately change it in an arbitrary way; but all are
continuously shaping it by taking part in the interactions that
constitute its fabric. Examples of complex adaptive systems include the
dynamics of insect societies (beehives, ant nests) or patterns of
collective motion in large animal groups (flocks of birds or shoals of
fish). These and more are discussed in much greater depth in the first
chapter of Pierre-Yves Oudeyer’s book &lt;em&gt;Self-Organization in the
Evolution of Speech&lt;/em&gt;. Adaptiveness is a property that these systems
acquire by virtue of not being hardwired on the macro level: they are
defined functionally instead of structurally. If the conditions in the
environment change, the system will adapt to keep fulfilling its
function, because the agents are forced to modify their behavior in
order to achieve their individual goals. Of course, they may fail to do
so, in which case the system breaks down and ceases to exist.&lt;/p&gt;
&lt;p&gt;If we revert to the metaphor from the title of the present essay,
according to Chomsky, language is a cathedral erected by a single
unwitting architect, the random genetic mutation that endowed us with
the language faculty. Conversely, Luc Steels and fellow evolutionary
linguists argue that the apparent macroscopic orderliness of language is
the result of a myriad interactions of multiple individual agents, as
suggested by the the bazaar image.&lt;/p&gt;
&lt;p&gt;One form that linguistic research can take under this paradigm is
formulating and running computational models which simulate the behavior
of agent populations and study the microscopic conditions, i.e. the
cognitive and physical abilities, motivations etc. of each agent,
necessary for a system like language to emerge within the population and
stabilize. By direct inspiration from Wittgenstein’s &lt;em&gt;Philosophical
Investigations&lt;/em&gt;, the interactions between agents are termed “language
games” (Steels 2015, 167–8); depending on the topic being investigated,
the agents can play different types of language games with different
rules. It is openly acknowledged that such simulations represent only a
limited approximation of a well-defined subspace of the actual uses of
language. In the research to date, rules are generally definite and set
for the entire experiment, but simulating language games with fuzzy
rules remains a perfectly valid research topic within this framework, in
the Wittgensteinian spirit of allowing rules to be made up and modified
“as we go along” (Wittgenstein 2009, 44e).&lt;/p&gt;
&lt;p&gt;A relatively simple game that agents can play is the so-called &lt;em&gt;Guessing
Game&lt;/em&gt; (see Chap. 2 of Steels 2015 for more details). In this scenario, a
population of agents, embodied in physical robots, tries to establish a
shared lexicon and coupled ontology for a simple world consisting of
geometrical shapes. Each game is an interaction of two agents picked at
random, in the context of a scene consisting of said geometrical shapes.
One agent (the speaker) takes the initiative, selects a topic from the
scene and names it; the other (the hearer) tries to guess which object
the first one had in mind and points to it; the speaker decodes the
pointing gesture and the game succeeds if he interprets it as
referencing his original topic. If so, he acknowledges the match;
otherwise, he points at the intended topic as a repair strategy. At the
outset, neither the lexicon nor the ontology are given, only a set of
sensors and actuators (which allow the agents to interact with the
environment by taking in streams of raw perceptual data or producing
sound and pointing gestures) and very general cognitive principles.
These include an associative memory and feedback mechanisms to propagate
failures and successes in conceptualization and communication to all
components of the system and act on them.&lt;sup id="fnref-5"&gt;&lt;a class="footnote-ref" href="#fn-5"&gt;5&lt;/a&gt;&lt;/sup&gt; New distinctions along the
perceptual dimensions are introduced in a random fashion,&lt;sup id="fnref-6"&gt;&lt;a class="footnote-ref" href="#fn-6"&gt;6&lt;/a&gt;&lt;/sup&gt; but those
that lead to a successful unambiguous selection of a topic and
communicative success are strengthened over the course of many
interactions, while useless ones are dampened by lateral inhibition and
eventually pruned. At the same time, speakers create new words for
concepts that are as of yet missing from their lexicon, and hearers may
adopt them into theirs for their conceptualization of the topic the
speaker points at in case of failure. A similar feedback mechanism then
ensures that highly successful words are preferred and come to dominate
within the speech community. It is important to realize that at no time
do the individual agents share the same ontology or lexicon: newly
introduced distinctions and words are random and unique for each agent,
agents simply gradually learn which of these are useful in achieving
communicative success, which means that they naturally settle on
ontologies and lexicons that are close enough to those of others in the
population.&lt;/p&gt;
&lt;p&gt;This barely scratches the surface of how all these notions must be
orchestrated for a working computer implementation of this model, not to
mention the even more elaborate agent-based language game modeling
experiments that are already being conducted, investigating for instance
the emergence of grammar (see Part III of Steels 2015 for an overview of
recent scholarship). We see that even a seemingly simple task like
establishing a shared conceptualization of reality and agreeing on names
for these concepts is a complex endeavor which relies on a highly
sophisticated (though also highly general) machinery. Another key
observation is that while agent-based models can be fully virtual,
grounding them in physical reality (cf. the use of robots with sensors
and actuators) brings additional challenges that enable researchers to
reach vital insights which would otherwise be impossible. In particular,
grounding introduces fuzziness on the sensory input channels (by virtue
of different points of view for the two robots and analog-to-digital
conversion) which the agents must cope with, or else the mechanisms they
were endowed with cannot be considered as constituting a plausible,
sufficient model of the dynamics of human language. Unlike in generative
grammar, anything that is transient, imperfect, is eminently included in
the purview of linguistic inquiry. Failures are very much part of the
dynamics that steer the evolution of language. How could it adapt to the
speakers’ changing requirements if it did not include appropriate repair
strategies? Indeed, how could it be bootstrapped at all? The reward is a
model that successfully simulates not only language emergence, but also
transmission: if virgin agents are added into an existing population,
they gradually acquire its language (see Fig. 1).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img alt="communicative success plot" src="images/communicative_success.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Communicative success in a population of agents with a steady
influx of virgin agents and outflux of old ones (overall population size
remains the same). The game starts in phase 1 with 20 virgin agents; phases 2
and 4 show the behavior of the model at an agent renewal rate of 1/1000 games,
whereas phase 3 corresponds to a heavier rate of 1/100. (Figure from Steels
2015, 121.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Crucially, the drive to communicate, to interact, is built into the
agents, they just keep playing games as long as they can. But if it was
not, the simulation would have to be more complex and somehow elicit
this drive by introducing appropriate ecological constraints, e.g. by
requiring co-operation as a survival strategy (Steels 2015, 106).
Otherwise, the agents would have no motivation to strive for
communicative success in their mutual encounters, they would fail to
reach intersubjective alignment of their conceptual spaces and lexicons,
and language would not emerge. In other words, far from being an
afterthought, successful communication with a partner, grounded in an
external context, turns out to be a fundamental requirement to establish
the kind of dynamics which allow languages to appear.&lt;/p&gt;
&lt;p&gt;Paradoxically, since it concerns itself with simulations and
computational models, this branch of evolutionary linguistics is, like
generative grammar, also highly speculative. However, unlike generative
grammar, it is a kind of speculation which considers guidance by
empirical observations a necessity, not a nuisance. Furthermore,
simulations are meant to be tested: if an agent-based model of language
emergence fails to converge on the result stipulated for that particular
experiment, the model is plain wrong and the dynamics it is trying to
put into place (cognitive strategies, feedback propagation etc.) need to
be revised. There is thus a clear-cut criterion for validity. Lastly,
even if a simulation works, an accompanying debate as to whether the
mechanisms involved are actually plausible approximations of reality is
considered an integral part of hypothesis evaluation, with evidence from
strongly empirically grounded disciplines like biology and
neurophysiology a vital element in the process.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Taking a cue from Wittgenstein’s &lt;em&gt;Philosophical Investigations&lt;/em&gt;, this
essay should not be construed as an attempt to replace one doctrine with
another, but to advocate a “change of attitude” (cf. McGinn 2013, 33)
which allows asking more meaningful questions about language. This being
said, on the evidence presented above, it is hard not to conclude that
Noam Chomsky is fundamentally mistaken about the corrective that is
necessary for language learning to take place. According to Chomsky, the
criterion for evaluating linguistic rules lies within a dedicated
language organ we are genetically endowed with; the innate structures
themselves embody the metric by which conjectures pertaining to
linguistic rules will be judged. By contrast, in the evolutionary
linguistics perspective, genetics provide innate structures which are
capable of random growth, but the feedback (reinforcement and pruning)
which results in steering this growth in a particular direction comes
from interactions with the environment. This theory presupposes much
less specificity in the hardware infrastructure which makes this
possible and so should be preferred both on grounds of simplicity and
flexibility of the model, not to mention that it is biologically
plausible and has been empirically verified to work.&lt;/p&gt;
&lt;p&gt;In the context of science, Chomsky’s rhetorical strategy in and of
itself is dishonest: he preaches formal rigor while practicing sleight
of hand, and casually retreats to increasingly abstract ground on
reaching an impasse. He thus carves out a region in discursive space
which has no corresponding equivalent in a logically consistent
conceptual space, without which a piece of discourse can hardly
constitute a scientific theory. In other words, much like his famous
example sentence “Colorless green ideas sleep furiously”, his discourse
is grammatical but largely nonsensical under the requirements on a
system of thought which aspires to mirror reality in a coherent fashion.&lt;/p&gt;
&lt;p&gt;Requirements on scientific discourse notwithstanding, we as linguists
should keep in mind that language in general is much more than a system
for encoding logical propositions. Even Wittgenstein had to resign
himself to the fact – or perhaps knew all along – that the &lt;em&gt;Tractatus&lt;/em&gt;,
which he framed as the ultimate solution to all metaphysical
controversies, could only fan the flames of philosophical debate. It was
after all addressed to a diverse community of people bound perhaps
exclusively by their penchant for elaborate language games.&lt;/p&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;Aarsleff, Hans. 1970. “The History of Linguistics and Professor
Chomsky.” &lt;em&gt;Language&lt;/em&gt; 46 (3): 570–85.&lt;/p&gt;
&lt;p&gt;Chomsky, Noam. 1956. “Three Models for the Description of Language.”&lt;/p&gt;
&lt;p&gt;———. 1965. &lt;em&gt;Aspects of the Theory of Syntax&lt;/em&gt;. Cambridge, MA: The M.I.T.
Press.&lt;/p&gt;
&lt;p&gt;———. 1986. &lt;em&gt;Knowledge of Language: Its Nature, Origin, and Use&lt;/em&gt;.
Convergence. New York, Westport, London: Praeger.&lt;/p&gt;
&lt;p&gt;———. 1995. &lt;em&gt;The Minimalist Program&lt;/em&gt;. Cambridge, MA: The MIT Press.&lt;/p&gt;
&lt;p&gt;———. 2002. &lt;em&gt;Syntactic Structures&lt;/em&gt;. 2nd ed. Berlin, New York: Mouton de
Gruyter.&lt;/p&gt;
&lt;p&gt;———. 2007. “Of Minds and Language.” &lt;em&gt;Biolinguistics&lt;/em&gt;, no. 1: 9–27.&lt;/p&gt;
&lt;p&gt;———. 2009. &lt;em&gt;Cartesian Linguistics: A Chapter in the History of
Rationalist Thought&lt;/em&gt;. 3rd ed. Cambridge: Cambridge University Press.&lt;/p&gt;
&lt;p&gt;McGinn, Marie. 2006. &lt;em&gt;Elucidating the Tractatus: Wittgenstein’s Early
Philosophy of Logic and Language&lt;/em&gt;. Oxford: Oxford University Press.&lt;/p&gt;
&lt;p&gt;———. 2013. &lt;em&gt;The Routledge Guidebook to Wittgenstein’s Philosophical
Investigations&lt;/em&gt;. The Routledge Guides to Great Books. Routledge.&lt;/p&gt;
&lt;p&gt;Miel, Jan. 1969. “Pascal, Port-Royal, and Cartesian Linguistics.”
&lt;em&gt;Journal of the History of Ideas&lt;/em&gt; 30 (2): 261–71.&lt;/p&gt;
&lt;p&gt;Oudeyer, Pierre-Yves. 2006. &lt;em&gt;Self-Organization in the Evolution of
Speech&lt;/em&gt;. Translated by James R. Hurford. Oxford, New York: OUP.&lt;/p&gt;
&lt;p&gt;Pullum, Geoffrey K. 2011. “On the Mathematical Foundations of &lt;em&gt;Syntactic
Structures&lt;/em&gt;.” &lt;em&gt;Journal of Logic, Language and Information&lt;/em&gt; 20: 277–96.&lt;/p&gt;
&lt;p&gt;Raymond, Eric S. 1999. &lt;em&gt;The Cathedral &amp;amp; the Bazaar: Musings on Linux and
Open Source by an Accidental Revolutionary&lt;/em&gt;. O’Reilly Media.&lt;/p&gt;
&lt;p&gt;Sampson, Geoffrey. 2005. &lt;em&gt;The “Language Instinct” Debate&lt;/em&gt;. 3rd ed.
London, New York: Continuum.&lt;/p&gt;
&lt;p&gt;———. 2015. “Rigid Strings and Flaky Snowflakes.” &lt;em&gt;Language and
Cognition&lt;/em&gt; 10: 1–17.&lt;/p&gt;
&lt;p&gt;Skinner, B. F. 1957. &lt;em&gt;Verbal Behavior&lt;/em&gt;. The Century Psychology Series.
New York: Appleton – Century – Crofts.&lt;/p&gt;
&lt;p&gt;Steels, Luc. 2015. &lt;em&gt;The Talking Heads Experiment: Origins of Words and
Meanings&lt;/em&gt;. Computational Models of Language Evolution 1. Berlin:
Language Science Press.&lt;/p&gt;
&lt;p&gt;Wittgenstein, Ludwig. 2001. &lt;em&gt;Tractatus Logico-Philosophicus&lt;/em&gt;. Routledge
Classics. London, New York: Routledge.&lt;/p&gt;
&lt;p&gt;———. 2009. &lt;em&gt;Philosophical Investigations&lt;/em&gt;. Chichester, United Kingdom:
Blackwell Publishing.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Let us pretend for a moment that language games like “poetry” or
the surrealist pastime of &lt;em&gt;cadavre exquis&lt;/em&gt; do not exist; in these,
the quoted sentence could appear as perfectly valid and meaningful,
though perhaps not in the sense that Chomsky intended. “Meaningful”
in a late-Wittgensteinian perspective could be paraphrased as
“accepted by at least one involved party as a valid turn within the
context of a particular language game”.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;Arguing that this does not matter because we should be concerned
with the &lt;em&gt;ideal&lt;/em&gt; speaker-hearer’s competence just takes us further
down the impasse, because now we have to determine how to delimit
the purported “ideal”.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;This is the beauty of building empirically unmotivated, purely
speculative theories: at any moment, one can freely accommodate a
new element into the existing framework, substituting novelty and
amalgamation for critical evaluation.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-4"&gt;
&lt;p&gt;Cf. also Sampson’s riposte : “If complex properties of some aspect
of human behaviour have to be as they are as a matter of conceptual
necessity, then there is no reason to postulate complex genetically
inherited cognitive machinery determining those behaviour patterns”
(Sampson 2015, 9).&amp;#160;&lt;a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-5"&gt;
&lt;p&gt;This interconnected architecture stands in stark contrast to
Chomsky’s deliberately isolationist approach: “the relation between
semantics and syntax […] can only be studied after the syntactic
structure has been determined on independent grounds” (Chomsky 2002,
17).&amp;#160;&lt;a class="footnote-backref" href="#fnref-5" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-6"&gt;
&lt;p&gt;Wittgenstein only hints at the problem of conceptualization, but
he is prescient in realizing it is not a given: “The primary
elements [of the objects which constitute the world in this
particular language game] are the coloured squares. ‘But are these
simple?’ – I wouldn’t know what I could more naturally call a
‘simple’ in this language-game. But under other circumstances, I’d
call a monochrome square, consisting perhaps of two rectangles or of
the elements colour and shape, ‘composite’” (Wittgenstein 2009,
27e).&amp;#160;&lt;a class="footnote-backref" href="#fnref-6" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="linguistics"></category><category term="Wittgenstein"></category><category term="Chomsky"></category></entry><entry><title>How computers handle text: a gentle but thorough introduction to Unicode</title><link href="http://dlukes.github.io/unicode.html" rel="alternate"></link><published>2016-01-27T00:00:00+01:00</published><updated>2016-01-27T00:00:00+01:00</updated><author><name>dlukes</name></author><id>tag:dlukes.github.io,2016-01-27:/unicode.html</id><summary type="html">&lt;p&gt;An introductory text about computer text encodings, primarily aimed at linguists.&lt;/p&gt;</summary><content type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Or, &lt;a href="http://www.joelonsoftware.com/articles/Unicode.html"&gt;the absolute minimum every &lt;del&gt;software developer&lt;/del&gt; linguist absolutely, positively must know about Unicode and character sets (no excuses!)&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This text was written as part of a larger programming tutorial in Python, and the code samples are taken from an interactive session using the &lt;a href="http://jupyter.org/"&gt;Jupyter notebook&lt;/a&gt;. As a consequence, there are digressions here and there about playing with text data in Python. These might seem:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;useless if what you came for is just the part about text encoding;&lt;/li&gt;
&lt;li&gt;long-winded if you already know some Python;&lt;/li&gt;
&lt;li&gt;or confusing if, on the contrary, you're not familiar with programming at all, much less with Python.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If any of these is your case, my advice is: ignore the code, focus on the comments around it, they're more than enough to follow the thread of the explanation. Though if you've got a little more time, why not &lt;a href="https://repl.it/languages/python3"&gt;try some of these out in an interactive Python session&lt;/a&gt;? ;) And now, without further ado...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Much like any other piece of data inside a digital computer, text is represented as a series of binary digits (bits), i.e. 0's and 1's. A mapping between sequences of bits and characters is called an encoding. How many different characters your encoding can handle depends on how many bits you allow per character:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;with 1 bit you can have 2^1 = 2 characters (one is represented by 0, the other by 1)&lt;/li&gt;
&lt;li&gt;with 2 bits you can have 2^2 = 4 characters(represented by 00, 01, 10 and 11)&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The oldest encoding still in widespread use (it's what makes the Internet and the web tick) is &lt;a href="https://en.wikipedia.org/wiki/ASCII"&gt;&lt;code&gt;ASCII&lt;/code&gt;&lt;/a&gt;, which is a 7-bit encoding:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[1]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;128&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This means it can represent &lt;a href="http://www.ascii-code.com/"&gt;128 different characters&lt;/a&gt;, which comfortably fits the basic Latin alphabet (both lowercase and uppercase), Arabic numerals, punctuation and some "control characters" which were primarily useful on the old &lt;a href="https://en.wikipedia.org/wiki/Teleprinter"&gt;teletype terminals&lt;/a&gt; for which &lt;code&gt;ASCII&lt;/code&gt; was designed. For instance, the letter "A" corresponds to the number 65 (&lt;code&gt;1000001&lt;/code&gt; in binary, see below).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;"ASCII" stands for "&lt;strong&gt;American&lt;/strong&gt; Standard Code for Information Interchange" -- which explains why there are no accented characters, for instance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nowadays, &lt;code&gt;ASCII&lt;/code&gt; is represented using 8 bits (== 1 byte), because that's the unit of computer memory which has become ubiquitous (in terms of both hardware and software assumptions), but still uses only 7 bits' worth of information.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[2]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;256&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[3]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# how to find out the binary representation of a decimal number?&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{:b}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;65&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[3]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;1000001&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[4]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Digression/explanation: the format() method&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# the format() string method inserts its arguments into the string&lt;/span&gt;
&lt;span class="c1"&gt;# wherever there is a &amp;quot;{}&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;bar&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;baz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[4]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;foo bar baz&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[5]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# you can also specify a different order by using (zero-based) &lt;/span&gt;
&lt;span class="c1"&gt;# positional indices -- or even repeating them&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{1}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{0}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{1}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;bar&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[5]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;bar foo bar&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[6]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# for long strings with many insertions, where you might mess up the&lt;/span&gt;
&lt;span class="c1"&gt;# order of arguments, keyword arguments are also available&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{foo_arg}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{bar_arg}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bar_arg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;bar&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;foo_arg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[6]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;foo bar&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[7]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# and you can also request various formatting adjustments or conversions&lt;/span&gt;
&lt;span class="c1"&gt;# to be made by specifying them after a &amp;quot;:&amp;quot; -- e.g. &amp;quot;b&amp;quot; prints a given&lt;/span&gt;
&lt;span class="c1"&gt;# number in its binary representation&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{:b}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[7]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;101101&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[8]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# or simply&lt;/span&gt;
&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# but that has an ugly &amp;quot;0b&amp;quot; in front, and we would&amp;#39;ve missed out on&lt;/span&gt;
&lt;span class="c1"&gt;# format() if we&amp;#39;d used that directly!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[8]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;0b101101&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;What happens in the range [128; 256) is not covered by the &lt;code&gt;ASCII&lt;/code&gt; standard. In the 1990s, many encodings were standardized which used this range for their own purposes, usually representing additional accented characters used in a particular region. E.g. Czech (and Slovak, Polish...) alphabets can be represented using the ISO &lt;code&gt;latin-2&lt;/code&gt; encoding, or Microsoft's &lt;code&gt;cp-1250&lt;/code&gt;. Encodings which stick with the same character mappings as &lt;code&gt;ASCII&lt;/code&gt; in the range [0; 128) &lt;strong&gt;and represent them physically in the same way (as 1 byte)&lt;/strong&gt;, while potentially adding more character mappings beyond that, are called &lt;strong&gt;&lt;code&gt;ASCII&lt;/code&gt;-compatible&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ASCII&lt;/code&gt; compatibility is a good thing&amp;trade;, because when you start reading a character stream in a computer, there's &lt;strong&gt;no way to know in advance what encoding it is in&lt;/strong&gt; (unless it's a file you've encoded yourself). So in practice, a heuristic has been established to start reading the stream assuming it is &lt;code&gt;ASCII&lt;/code&gt; by default, and switch to a different encoding if evidence becomes available that motivates it. For instance, HTML files should all start something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
  ...
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This way, whenever a program wants to read a file like this, it can start off with &lt;code&gt;ASCII&lt;/code&gt;, waiting to see if it reaches the &lt;code&gt;charset&lt;/code&gt; (i.e. encoding) attribute, and once it does, it can switch from &lt;code&gt;ASCII&lt;/code&gt; to that encoding (&lt;code&gt;UTF-8&lt;/code&gt; here) and restart reading the file, now fairly sure that it's using the correct encoding. This trick works only if we can assume that whatever encoding the rest of the file is in, the first few lines can be considered as &lt;code&gt;ASCII&lt;/code&gt; for all practical intents and purposes.&lt;/p&gt;
&lt;p&gt;Without the &lt;code&gt;charset&lt;/code&gt; attribute, the only way to know if the encoding is right would be for you to look at the rendered text and see if it makes sense; if it did not, you'd have to resort to trial and error, manually switching the encodings and looking for the one in which the numbers behind the characters stop coming out as gibberish and are actually translated into intelligible text.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[9]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Let&amp;#39;s take a look at printable characters in the latin-2 character&lt;/span&gt;
&lt;span class="c1"&gt;# set. Each mapping is called a &amp;quot;codepoint&amp;quot;: it is a correspondence&lt;/span&gt;
&lt;span class="c1"&gt;# between an integer and a character.&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;codecs&lt;/span&gt;

&lt;span class="n"&gt;latin2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;codepoint&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;byte&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;codepoint&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;character&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;codecs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;latin2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;character&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isprintable&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;latin2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;codepoint&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;character&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;latin2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[9]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[(32, &amp;#39; &amp;#39;),
 (33, &amp;#39;!&amp;#39;),
 (34, &amp;#39;&amp;#34;&amp;#39;),
 (35, &amp;#39;#&amp;#39;),
 (36, &amp;#39;$&amp;#39;),
 (37, &amp;#39;%&amp;#39;),
 (38, &amp;#39;&amp;amp;&amp;#39;),
 (39, &amp;#34;&amp;#39;&amp;#34;),
 (40, &amp;#39;(&amp;#39;),
 (41, &amp;#39;)&amp;#39;),
 (42, &amp;#39;*&amp;#39;),
 (43, &amp;#39;+&amp;#39;),
 (44, &amp;#39;,&amp;#39;),
 (45, &amp;#39;-&amp;#39;),
 (46, &amp;#39;.&amp;#39;),
 (47, &amp;#39;/&amp;#39;),
 (48, &amp;#39;0&amp;#39;),
 (49, &amp;#39;1&amp;#39;),
 (50, &amp;#39;2&amp;#39;),
 (51, &amp;#39;3&amp;#39;),
 (52, &amp;#39;4&amp;#39;),
 (53, &amp;#39;5&amp;#39;),
 (54, &amp;#39;6&amp;#39;),
 (55, &amp;#39;7&amp;#39;),
 (56, &amp;#39;8&amp;#39;),
 (57, &amp;#39;9&amp;#39;),
 (58, &amp;#39;:&amp;#39;),
 (59, &amp;#39;;&amp;#39;),
 (60, &amp;#39;&amp;lt;&amp;#39;),
 (61, &amp;#39;=&amp;#39;),
 (62, &amp;#39;&amp;gt;&amp;#39;),
 (63, &amp;#39;?&amp;#39;),
 (64, &amp;#39;@&amp;#39;),
 (65, &amp;#39;A&amp;#39;),
 (66, &amp;#39;B&amp;#39;),
 (67, &amp;#39;C&amp;#39;),
 (68, &amp;#39;D&amp;#39;),
 (69, &amp;#39;E&amp;#39;),
 (70, &amp;#39;F&amp;#39;),
 (71, &amp;#39;G&amp;#39;),
 (72, &amp;#39;H&amp;#39;),
 (73, &amp;#39;I&amp;#39;),
 (74, &amp;#39;J&amp;#39;),
 (75, &amp;#39;K&amp;#39;),
 (76, &amp;#39;L&amp;#39;),
 (77, &amp;#39;M&amp;#39;),
 (78, &amp;#39;N&amp;#39;),
 (79, &amp;#39;O&amp;#39;),
 (80, &amp;#39;P&amp;#39;),
 (81, &amp;#39;Q&amp;#39;),
 (82, &amp;#39;R&amp;#39;),
 (83, &amp;#39;S&amp;#39;),
 (84, &amp;#39;T&amp;#39;),
 (85, &amp;#39;U&amp;#39;),
 (86, &amp;#39;V&amp;#39;),
 (87, &amp;#39;W&amp;#39;),
 (88, &amp;#39;X&amp;#39;),
 (89, &amp;#39;Y&amp;#39;),
 (90, &amp;#39;Z&amp;#39;),
 (91, &amp;#39;[&amp;#39;),
 (92, &amp;#39;\\&amp;#39;),
 (93, &amp;#39;]&amp;#39;),
 (94, &amp;#39;^&amp;#39;),
 (95, &amp;#39;_&amp;#39;),
 (96, &amp;#39;`&amp;#39;),
 (97, &amp;#39;a&amp;#39;),
 (98, &amp;#39;b&amp;#39;),
 (99, &amp;#39;c&amp;#39;),
 (100, &amp;#39;d&amp;#39;),
 (101, &amp;#39;e&amp;#39;),
 (102, &amp;#39;f&amp;#39;),
 (103, &amp;#39;g&amp;#39;),
 (104, &amp;#39;h&amp;#39;),
 (105, &amp;#39;i&amp;#39;),
 (106, &amp;#39;j&amp;#39;),
 (107, &amp;#39;k&amp;#39;),
 (108, &amp;#39;l&amp;#39;),
 (109, &amp;#39;m&amp;#39;),
 (110, &amp;#39;n&amp;#39;),
 (111, &amp;#39;o&amp;#39;),
 (112, &amp;#39;p&amp;#39;),
 (113, &amp;#39;q&amp;#39;),
 (114, &amp;#39;r&amp;#39;),
 (115, &amp;#39;s&amp;#39;),
 (116, &amp;#39;t&amp;#39;),
 (117, &amp;#39;u&amp;#39;),
 (118, &amp;#39;v&amp;#39;),
 (119, &amp;#39;w&amp;#39;),
 (120, &amp;#39;x&amp;#39;),
 (121, &amp;#39;y&amp;#39;),
 (122, &amp;#39;z&amp;#39;),
 (123, &amp;#39;{&amp;#39;),
 (124, &amp;#39;|&amp;#39;),
 (125, &amp;#39;}&amp;#39;),
 (126, &amp;#39;~&amp;#39;),
 (161, &amp;#39;Ą&amp;#39;),
 (162, &amp;#39;˘&amp;#39;),
 (163, &amp;#39;Ł&amp;#39;),
 (164, &amp;#39;¤&amp;#39;),
 (165, &amp;#39;Ľ&amp;#39;),
 (166, &amp;#39;Ś&amp;#39;),
 (167, &amp;#39;§&amp;#39;),
 (168, &amp;#39;¨&amp;#39;),
 (169, &amp;#39;Š&amp;#39;),
 (170, &amp;#39;Ş&amp;#39;),
 (171, &amp;#39;Ť&amp;#39;),
 (172, &amp;#39;Ź&amp;#39;),
 (174, &amp;#39;Ž&amp;#39;),
 (175, &amp;#39;Ż&amp;#39;),
 (176, &amp;#39;°&amp;#39;),
 (177, &amp;#39;ą&amp;#39;),
 (178, &amp;#39;˛&amp;#39;),
 (179, &amp;#39;ł&amp;#39;),
 (180, &amp;#39;´&amp;#39;),
 (181, &amp;#39;ľ&amp;#39;),
 (182, &amp;#39;ś&amp;#39;),
 (183, &amp;#39;ˇ&amp;#39;),
 (184, &amp;#39;¸&amp;#39;),
 (185, &amp;#39;š&amp;#39;),
 (186, &amp;#39;ş&amp;#39;),
 (187, &amp;#39;ť&amp;#39;),
 (188, &amp;#39;ź&amp;#39;),
 (189, &amp;#39;˝&amp;#39;),
 (190, &amp;#39;ž&amp;#39;),
 (191, &amp;#39;ż&amp;#39;),
 (192, &amp;#39;Ŕ&amp;#39;),
 (193, &amp;#39;Á&amp;#39;),
 (194, &amp;#39;Â&amp;#39;),
 (195, &amp;#39;Ă&amp;#39;),
 (196, &amp;#39;Ä&amp;#39;),
 (197, &amp;#39;Ĺ&amp;#39;),
 (198, &amp;#39;Ć&amp;#39;),
 (199, &amp;#39;Ç&amp;#39;),
 (200, &amp;#39;Č&amp;#39;),
 (201, &amp;#39;É&amp;#39;),
 (202, &amp;#39;Ę&amp;#39;),
 (203, &amp;#39;Ë&amp;#39;),
 (204, &amp;#39;Ě&amp;#39;),
 (205, &amp;#39;Í&amp;#39;),
 (206, &amp;#39;Î&amp;#39;),
 (207, &amp;#39;Ď&amp;#39;),
 (208, &amp;#39;Đ&amp;#39;),
 (209, &amp;#39;Ń&amp;#39;),
 (210, &amp;#39;Ň&amp;#39;),
 (211, &amp;#39;Ó&amp;#39;),
 (212, &amp;#39;Ô&amp;#39;),
 (213, &amp;#39;Ő&amp;#39;),
 (214, &amp;#39;Ö&amp;#39;),
 (215, &amp;#39;×&amp;#39;),
 (216, &amp;#39;Ř&amp;#39;),
 (217, &amp;#39;Ů&amp;#39;),
 (218, &amp;#39;Ú&amp;#39;),
 (219, &amp;#39;Ű&amp;#39;),
 (220, &amp;#39;Ü&amp;#39;),
 (221, &amp;#39;Ý&amp;#39;),
 (222, &amp;#39;Ţ&amp;#39;),
 (223, &amp;#39;ß&amp;#39;),
 (224, &amp;#39;ŕ&amp;#39;),
 (225, &amp;#39;á&amp;#39;),
 (226, &amp;#39;â&amp;#39;),
 (227, &amp;#39;ă&amp;#39;),
 (228, &amp;#39;ä&amp;#39;),
 (229, &amp;#39;ĺ&amp;#39;),
 (230, &amp;#39;ć&amp;#39;),
 (231, &amp;#39;ç&amp;#39;),
 (232, &amp;#39;č&amp;#39;),
 (233, &amp;#39;é&amp;#39;),
 (234, &amp;#39;ę&amp;#39;),
 (235, &amp;#39;ë&amp;#39;),
 (236, &amp;#39;ě&amp;#39;),
 (237, &amp;#39;í&amp;#39;),
 (238, &amp;#39;î&amp;#39;),
 (239, &amp;#39;ď&amp;#39;),
 (240, &amp;#39;đ&amp;#39;),
 (241, &amp;#39;ń&amp;#39;),
 (242, &amp;#39;ň&amp;#39;),
 (243, &amp;#39;ó&amp;#39;),
 (244, &amp;#39;ô&amp;#39;),
 (245, &amp;#39;ő&amp;#39;),
 (246, &amp;#39;ö&amp;#39;),
 (247, &amp;#39;÷&amp;#39;),
 (248, &amp;#39;ř&amp;#39;),
 (249, &amp;#39;ů&amp;#39;),
 (250, &amp;#39;ú&amp;#39;),
 (251, &amp;#39;ű&amp;#39;),
 (252, &amp;#39;ü&amp;#39;),
 (253, &amp;#39;ý&amp;#39;),
 (254, &amp;#39;ţ&amp;#39;),
 (255, &amp;#39;˙&amp;#39;)]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Using the 8th bit (and thus the codepoint range [128; 256)) solves the problem of handling languages with character sets different than that of American English, but introduces a lot of complexity -- whenever you come across a text file with an unknown encoding, it might be in one of literally dozens of encodings. Additional drawbacks include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how to handle multilingual text with characters from many different alphabets, which are not part of the same 8-bit encoding?&lt;/li&gt;
&lt;li&gt;how to handle writing systems which have way more than 256 "characters", e.g. Chinese, Japanese and Korean (CJK) ideograms?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For these purposes, a standard encoding known as &lt;a href="https://en.wikipedia.org/wiki/Unicode"&gt;&lt;strong&gt;Unicode&lt;/strong&gt;&lt;/a&gt; was developed which strives for universal coverage of all possible character sets. Unicode is much bigger than the encodings we've seen so far -- its most frequently used subset, the &lt;a href="https://en.wikipedia.org/wiki/Plane_%28Unicode%29#Basic_Multilingual_Plane"&gt;Basic Multilingual Plane&lt;/a&gt;, has 2^16 codepoints, but overall the number of codepoints is past 1M and there's room to accommodate many more.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[10]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[10]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;65536&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now, the most straightforward representation for 2^16 codepoints is what? Well, it's simply using 16 bits per character, i.e. 2 bytes. That encoding exists, it's called &lt;code&gt;UTF-16&lt;/code&gt;, but consider the drawbacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we've lost &lt;code&gt;ASCII&lt;/code&gt; compatibility by the simple fact of using 2 bytes per character instead of 1 (encoding "a" as &lt;code&gt;01100001&lt;/code&gt; or &lt;code&gt;01100001|00000000&lt;/code&gt;, with the &lt;code&gt;|&lt;/code&gt; indicating an imaginary boundary between bytes, is not the same thing)&lt;/li&gt;
&lt;li&gt;encoding a string in a character set which uses a "reasonable" number of characters (like any European language) now takes twice as much space without any added benefit (which is probably not a good idea, given the general dominance of English -- one of those "reasonable character set size" languages -- in electronic communication)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looks like we'll have to think outside the box. The box in question here is called &lt;strong&gt;fixed-width encodings&lt;/strong&gt; -- all of the encoding schemes we've encountered so far were fixed-width, meaning that each character was represented by either 7, 8 or 16 bits. In other word, you could jump around the string in multiples of 7, 8 or 16 and always land at the beginning of a character. (Not exactly true for &lt;code&gt;UTF-16&lt;/code&gt;, because it is something more than just a "16-bit &lt;code&gt;ASCII&lt;/code&gt;": it has ways of handling characters beyond 2^16 using so-called &lt;a href="https://en.wikipedia.org/wiki/UTF-16#U.2B10000_to_U.2B10FFFF"&gt;surrogate sequences&lt;/a&gt; -- but you get the gist.)&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;"UTF" stands for "Unicode Transformation Format".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The smart idea that some bright people have come up with was to use a &lt;strong&gt;variable-width encoding&lt;/strong&gt;. The most ubiquitous one currently is &lt;strong&gt;&lt;code&gt;UTF-8&lt;/code&gt;&lt;/strong&gt;, which we've already met in the HTML example above. &lt;code&gt;UTF-8&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; &lt;code&gt;ASCII&lt;/code&gt;-compatible, i.e. the 1's and 0's used to encode text containing only &lt;code&gt;ASCII&lt;/code&gt; characters are the same regardless of whether you use &lt;code&gt;ASCII&lt;/code&gt; or &lt;code&gt;UTF-8&lt;/code&gt;: it's a sequence of 8-bit bytes. But &lt;code&gt;UTF-8&lt;/code&gt; can also handle many more additional characters, as defined by the Unicode standard, by using progressively longer and longer sequences of bits.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[11]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Prints binary representation of string as encoded by UTF-8.&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;binary_bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="c1"&gt;# encode the string as UTF-8 and iterate over the bytes&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;byte&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# generate a string of general format &amp;quot;0b101...&amp;quot;, which&lt;/span&gt;
        &lt;span class="c1"&gt;# is the binary representation of the byte&lt;/span&gt;
        &lt;span class="n"&gt;binary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# remove the leading &amp;quot;0b&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;binary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;binary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="c1"&gt;# pad the representation with leading zeros to the size of&lt;/span&gt;
        &lt;span class="c1"&gt;# a full byte (= a sequence of 8 1&amp;#39;s and 0&amp;#39;s) if necessary&lt;/span&gt;
        &lt;span class="n"&gt;binary_byte&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;binary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;binary_bytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;binary_byte&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;#39; encoded in UTF-8 is: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;binary_bytes&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;A&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# the representations...&lt;/span&gt;
&lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;č&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# ... keep...&lt;/span&gt;
&lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;字&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# ... getting longer.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;&amp;#39;A&amp;#39; encoded in UTF-8 is: [&amp;#39;01000001&amp;#39;]
&amp;#39;č&amp;#39; encoded in UTF-8 is: [&amp;#39;11000100&amp;#39;, &amp;#39;10001101&amp;#39;]
&amp;#39;字&amp;#39; encoded in UTF-8 is: [&amp;#39;11100101&amp;#39;, &amp;#39;10101101&amp;#39;, &amp;#39;10010111&amp;#39;]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;How does it achieve that? The obvious problem here is that with a fixed-width encoding, you just chop up the string at regular intervals (7, 8, 16 bits) and you know that each interval represents one character. So &lt;strong&gt;how do you know where to chop up a variable width-encoded string, if each character can take up a different number of bits?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Essentially, the trick is to &lt;strong&gt;use some of the bits&lt;/strong&gt; in the representation of a codepoint &lt;strong&gt;to store information&lt;/strong&gt; not about which character it is (whether it's an "A" or a "字"), but &lt;strong&gt;how many bits it occupies&lt;/strong&gt;. In other words, if you want to skip ahead 10 characters in a string encoded with a variable width-encoding, you can't just skip 10 * 7 or 8 or 16 bits; you have to read all the intervening characters to figure out how much space they take up. Take the following example:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[12]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Básník 李白&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;&amp;#39;B&amp;#39; encoded in UTF-8 is: [&amp;#39;01000010&amp;#39;]
&amp;#39;á&amp;#39; encoded in UTF-8 is: [&amp;#39;11000011&amp;#39;, &amp;#39;10100001&amp;#39;]
&amp;#39;s&amp;#39; encoded in UTF-8 is: [&amp;#39;01110011&amp;#39;]
&amp;#39;n&amp;#39; encoded in UTF-8 is: [&amp;#39;01101110&amp;#39;]
&amp;#39;í&amp;#39; encoded in UTF-8 is: [&amp;#39;11000011&amp;#39;, &amp;#39;10101101&amp;#39;]
&amp;#39;k&amp;#39; encoded in UTF-8 is: [&amp;#39;01101011&amp;#39;]
&amp;#39; &amp;#39; encoded in UTF-8 is: [&amp;#39;00100000&amp;#39;]
&amp;#39;李&amp;#39; encoded in UTF-8 is: [&amp;#39;11100110&amp;#39;, &amp;#39;10011101&amp;#39;, &amp;#39;10001110&amp;#39;]
&amp;#39;白&amp;#39; encoded in UTF-8 is: [&amp;#39;11100111&amp;#39;, &amp;#39;10011001&amp;#39;, &amp;#39;10111101&amp;#39;]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Notice the initial bits in each byte of a character follow a pattern depending on how many bytes in total that character has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if it's a 1-byte character, that byte starts with 0&lt;/li&gt;
&lt;li&gt;if it's a 2-byte character, the first byte starts with 11 and the following one with 10&lt;/li&gt;
&lt;li&gt;if it's a 3-byte character, the first byte starts with 111 and the following ones with 10&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This makes it possible to find out which bytes belong to which characters, and also to spot invalid strings, as the &lt;strong&gt;leading&lt;/strong&gt; byte in a &lt;strong&gt;‹multi-byte sequence&lt;/strong&gt; always "announces" how many &lt;strong&gt;continuation&lt;/strong&gt; bytes (= starting with 10) should follow.&lt;/p&gt;
&lt;p&gt;So much for a quick introduction to &lt;code&gt;UTF-8&lt;/code&gt; (= the encoding), but there's much more to Unicode (= the character set). While &lt;code&gt;UTF-8&lt;/code&gt; defines just how codepoints (numbers) are to be represented as 1's and 0's in a computer's memory, Unicode specifies how those numbers are to be interpreted as characters, what their properties and mutual relationships are, what conversions (i.e. mappings between (sequences of) codepoints) they can undergo, etc.&lt;/p&gt;
&lt;p&gt;Consider for instance the various ways diacritics are handled: "č" can be represented either as a single codepoint (&lt;a href="http://www.fileformat.info/info/unicode/char/010D/index.htm"&gt;&lt;code&gt;LATIN SMALL LETTER C WITH CARON&lt;/code&gt;&lt;/a&gt; -- all Unicode codepoints have cute names like this) or a sequence of two codepoints, the character "c" and a combining diacritic mark (&lt;code&gt;COMBINING CARON&lt;/code&gt;). You can search for the codepoints corresponding to Unicode characters e.g. &lt;a href="http://www.fileformat.info/info/unicode/char/search.htm"&gt;here&lt;/a&gt; and play with them in Python using the &lt;code&gt;chr(0xXXXX)&lt;/code&gt; built-in function or with the special string escape sequence &lt;code&gt;\uXXXX&lt;/code&gt; (where &lt;code&gt;XXXX&lt;/code&gt; is the hexadecimal representation of the codepoint) -- both are ways to get the character corresponding to the given codepoint:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[13]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# &amp;quot;č&amp;quot; as LATIN SMALL LETTER C WITH CARON, codepoint 010d&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x010d&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u010d&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;č
č
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[14]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# &amp;quot;č&amp;quot; as a sequence of LATIN SMALL LETTER C, codepoint 0063, and&lt;/span&gt;
&lt;span class="c1"&gt;# COMBINING CARON, codepoint 030c&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x0063&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x030c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u0063\u030c&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;č
č
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;&lt;p&gt;Hexadecimal is just a more convenient way of representing sequences of bits, where each of the &lt;code&gt;X&lt;/code&gt;'s can be a number between 0 and 15 (10--15 are represented by the letters A--F). Each hexadecimal number can thus represent 16 different values, and therefore it can stand in for a sequence of 4 bits (2^4 == 16). Without worrying too much about the details right now, our old friend &lt;code&gt;ASCII&lt;/code&gt; uppercase "A" can be thought of equivalently either as decimal 65, binary &lt;code&gt;0b1000001&lt;/code&gt;, or hexadecimal &lt;code&gt;0x41&lt;/code&gt; (the "0b" / "0x" prefixes are there just to say "this is a binary / hexadecimal number").&lt;/p&gt;
&lt;p&gt;Binary and hexadecimal numbers are often written padded with leading zeros to some number of bytes, but these have no effect on the value, much like decimal 42 and 00000042 are effectively the same numbers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[15]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# use hex() to find out the hexadecimal representation of a decimal&lt;/span&gt;
&lt;span class="c1"&gt;# integer...&lt;/span&gt;
&lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;99&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[15]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;0x63&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[16]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... and int() to go back...&lt;/span&gt;
&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x63&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[16]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;99&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[17]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... or just evaluate the hexadecimal number&lt;/span&gt;
&lt;span class="mh"&gt;0x63&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[17]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;99&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[18]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# of course, chr() also works with decimal numbers&lt;/span&gt;
&lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;269&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[18]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;#39;č&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This means you have to be careful when working with languages that use accents, because &lt;strong&gt;for a computer, the two possible representations are of course different strings&lt;/strong&gt;, even though for you, they're conceptually the same:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[19]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u010d&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;s2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u0063\u030c&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# s1 and s2 look the same to the naked eye...&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;č č
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[20]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... but in the eternal realm of Plato&amp;#39;s Ideas, they&amp;#39;re not&lt;/span&gt;
&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[20]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;False&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Watch out, &lt;strong&gt;they even have different lengths&lt;/strong&gt;! This might come to bite you if you're trying to compute the length of a word in letters.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[21]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s1 is&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;character(s) long.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s2 is&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;character(s) long.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;s1 is 1 character(s) long.
s2 is 2 character(s) long.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;For this reason, even though we've been informally calling these Unicode entities "characters", it is more accurate and less confusing to use the technical term "codepoints".&lt;/p&gt;
&lt;p&gt;Generally, most text out there will use the first, single-codepoint approach whenever possible, and pre-packaged linguistic corpora will try to be consistent about this (unless they come from the web, which always warrants being suspicious and defensive about your material). If you're worried about inconsistencies in your data, you can perform a &lt;a href="https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization"&gt;normalization&lt;/a&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[22]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;unicodedata&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;

&lt;span class="c1"&gt;# NFC stands for Normal Form C; this normalization applies a canonical&lt;/span&gt;
&lt;span class="c1"&gt;# decomposition (into a multi-codepoint representation) followed by a&lt;/span&gt;
&lt;span class="c1"&gt;# canonical composition (into a single-codepoint representation)&lt;/span&gt;
&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;NFC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;s2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;NFC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[22]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;True&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Let's wrap things up by saying that Python itself uses Unicode internally, but the encoding it defaults to when opening an external file depends on the &lt;em&gt;locale&lt;/em&gt; of the system (broadly speaking, the set of region, language and character-encoding related settings of the operating system). On most modern Linux and macOS systems, this will probably be a &lt;code&gt;UTF-8&lt;/code&gt; locale and Python will therefore assume &lt;code&gt;UTF-8&lt;/code&gt; as the encoding by default. Unfortunately, Windows is different. To be on the safe side, whenever opening files in Python, you can specify the encoding explicitly:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[23]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;unicode.ipynb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[24]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# a good idea when dealing with Unicode text from an unknown and&lt;/span&gt;
&lt;span class="c1"&gt;# unreliable source is to look at the set of codepoints contained&lt;/span&gt;
&lt;span class="c1"&gt;# in it and eliminate or replace those that shouldn&amp;#39;t be there&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;unicodedata&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;inspect_codepoints&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;charset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;charset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; (\u&lt;/span&gt;&lt;span class="si"&gt;{:04x}&lt;/span&gt;&lt;span class="s2"&gt;): &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; (category: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;unicodedata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;unicodedata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        

&lt;span class="c1"&gt;# depending on your font configuration, it may be very hard to spot&lt;/span&gt;
&lt;span class="c1"&gt;# the two intruders in the sentence below that look like regular&lt;/span&gt;
&lt;span class="c1"&gt;# letters but really are specialized variants; you might want&lt;/span&gt;
&lt;span class="c1"&gt;# to replace them before doing further text processing...&lt;/span&gt;
&lt;span class="n"&gt;inspect_codepoints&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Intruders here, good 𝗍hinɡ I checked.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;  (\u0020): SPACE (category: Zs)
, (\u002c): COMMA (category: Po)
. (\u002e): FULL STOP (category: Po)
I (\u0049): LATIN CAPITAL LETTER I (category: Lu)
c (\u0063): LATIN SMALL LETTER C (category: Ll)
d (\u0064): LATIN SMALL LETTER D (category: Ll)
e (\u0065): LATIN SMALL LETTER E (category: Ll)
g (\u0067): LATIN SMALL LETTER G (category: Ll)
h (\u0068): LATIN SMALL LETTER H (category: Ll)
i (\u0069): LATIN SMALL LETTER I (category: Ll)
k (\u006b): LATIN SMALL LETTER K (category: Ll)
n (\u006e): LATIN SMALL LETTER N (category: Ll)
o (\u006f): LATIN SMALL LETTER O (category: Ll)
r (\u0072): LATIN SMALL LETTER R (category: Ll)
s (\u0073): LATIN SMALL LETTER S (category: Ll)
t (\u0074): LATIN SMALL LETTER T (category: Ll)
u (\u0075): LATIN SMALL LETTER U (category: Ll)
ɡ (\u0261): LATIN SMALL LETTER SCRIPT G (category: Ll)
𝗍 (\u1d5cd): MATHEMATICAL SANS-SERIF SMALL T (category: Ll)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[25]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... because of course, for a computer, the word &amp;quot;thing&amp;quot; written with&lt;/span&gt;
&lt;span class="c1"&gt;# two different variants of &amp;quot;g&amp;quot; is really just two different words, which&lt;/span&gt;
&lt;span class="c1"&gt;# is probably not what you want&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;thing&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;thinɡ&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[25]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;False&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In any case, here's what happens when processing text with Python ("Unicode" in the central box stands for Python's internal representation of Unicode, which is &lt;strong&gt;not&lt;/strong&gt; &lt;code&gt;UTF-8&lt;/code&gt; nor &lt;code&gt;UTF-16&lt;/code&gt;):&lt;/p&gt;
&lt;p&gt;&lt;img alt="Text IO in Python" src="http://www.nltk.org/images/unicode.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;p&gt;(Image shamelessly hotlinked from / courtesy of the &lt;a href="http://www.nltk.org/book/"&gt;NLTK Book&lt;/a&gt;. Go check it out, it's an awesome intro to Python programming for linguists!)&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A terminological postscript: we've been using some terms a bit informally and for the most part it's okay, but it's good to get the distinctions straight in one's head at least once. So, a &lt;strong&gt;character set&lt;/strong&gt; is a mapping between &lt;strong&gt;codepoints&lt;/strong&gt; (integers) and &lt;strong&gt;characters&lt;/strong&gt;. We may for instance say that in our character set, the integer 99 corresponds to the character "c".&lt;/p&gt;
&lt;p&gt;On the other hand, an &lt;strong&gt;encoding&lt;/strong&gt; is a mapping between a &lt;strong&gt;codepoint&lt;/strong&gt; (an integer) and a &lt;strong&gt;physical sequence of 1's and 0's that represent it in memory&lt;/strong&gt;. With fixed-width encodings, this mapping is generally straightforward -- the 1's and 0's directly represent the given integer, only in binary and padded with zeros to fit the desired width. With variable-width encodings, as the necessity creeps in to include the information about how many bits are spanned by the current character, this straightforward correspondence breaks down.&lt;/p&gt;
&lt;p&gt;A comparison might be helpful here: as encodings, &lt;code&gt;UTF-8&lt;/code&gt; and &lt;code&gt;UTF-16&lt;/code&gt; both use &lt;strong&gt;the same character set&lt;/strong&gt; -- the same integers corresponding to the same characters. But since they're &lt;strong&gt;different encodings&lt;/strong&gt;, when the time comes to turn these integers into sequences of bits to store in a computer's memory, each of them generates a different one.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For more on Unicode, a great read already hinted at above is Joel Spolsky's &lt;a href="http://www.joelonsoftware.com/articles/Unicode.html"&gt;The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)&lt;/a&gt;. Another great piece of material is the &lt;a href="https://youtu.be/MijmeoH9LT4"&gt;Characters, Symbols and the Unicode Miracle&lt;/a&gt; video by the &lt;a href="https://www.youtube.com/channel/UC9-y-6csu5WGm29I7JiwpnA"&gt;Computerphile&lt;/a&gt; channel on YouTube. To make the discussion digestible for newcomers, I sometimes slightly distorted facts about how things are "really really" done. And some inaccuracies may be genuine mistakes. In any case, please let me know in the comments! I'm grateful for feedback and looking to improve this material; I'll fix the mistakes and consider ditching some of the simplifications if they prove untenable :)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
 

&lt;/p&gt;</content><category term="unicode"></category><category term="encoding"></category><category term="charset"></category><category term="programming"></category><category term="linguistics"></category><category term="python"></category></entry><entry><title>Úprava rozhraní konkordanceru KonText -- vylepšená verze</title><link href="http://dlukes.github.io/kontext-interface-tweak-update.html" rel="alternate"></link><published>2015-05-14T00:00:00+02:00</published><updated>2015-05-14T00:00:00+02:00</updated><author><name>dlukes</name></author><id>tag:dlukes.github.io,2015-05-14:/kontext-interface-tweak-update.html</id><summary type="html">&lt;p&gt;Vylepšená verze skriptu, kterým si uživatel Českého národního korpusu může upravit rozhraní konkordanceru KonText.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Před nějakou dobou jsem zde vyvěsil
&lt;a href="http://dlukes.github.io/kontext-interface-tweak.html"&gt;skript&lt;/a&gt;, jehož pomocí lze lehce
"přeskládat" a upravit rozhraní korpusového konkordanceru
&lt;a href="https://kontext.korpus.cz"&gt;KonText&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;menu je umístěné po straně místo nahoře a permanentně rozbalené&lt;/li&gt;
&lt;li&gt;nad vyhledanou konkordancí je umístěn rychlý hledací box, v němž lze
  předchozí dotaz pohodlně upravit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Víc o motivaci těchto úprav se dočtete
&lt;a href="kontext-interface-tweak.html#background"&gt;v původním článku&lt;/a&gt;. Stále
platí, že ČNK nemá v plánu tyto změny začlenit přímo do oficiální verze
KonTextu, zejména proto, že rychlý hledací box sice v jistých situacích může
být užitečný, nicméně oproti standardnímu formuláři &lt;em&gt;Nový dotaz&lt;/em&gt; výrazně
omezuje možnosti pro zadání dotazu.&lt;/p&gt;
&lt;p&gt;Vylepšená verze, která je k dispozici níže, odstraňuje některé předchozí
nedostatky skriptu: rychlý hledací box nad konkordancí je větší, ukazuje &lt;strong&gt;vždy
CQL podobu posledního zadaného dotazu&lt;/strong&gt;&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;, a především zůstává zobrazený i
během listování konkordancí (tj. není k dispozici jen na její první
stránce). Dotaz lze nyní navíc pro větší přehlednost rozdělit do více řádků,
takže opětovné vyhledávání se nově spouští stiskem kombinace kláves
&lt;strong&gt;Ctrl+Enter&lt;/strong&gt; (místo jen Enteru).&lt;/p&gt;
&lt;p&gt;Výsledné upravené rozhraní KonText vypadá stále podobně:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Upravené rozhraní KonText." src="images/kontext_interface_tweak_update.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;h1&gt;Postup instalace skriptu&lt;/h1&gt;
&lt;p&gt;Nová verze skriptu je k dispozici zde:&lt;/p&gt;
&lt;script src="https://gist.github.com/dlukes/a99dca231db63c9d5bb7.js"&gt;&lt;/script&gt;

&lt;p&gt;Kroky k jeho zprovoznění zůstávají stejné:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Nainstalovat si do svého prohlížeče plugin
    &lt;a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en"&gt;Tampermonkey&lt;/a&gt;,
    pokud používáte Chrome, nebo
    &lt;a href="https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/"&gt;Greasemonkey&lt;/a&gt;,
    pokud používáte Firefox. (Pokud používáte Internet Explorer, budete muset
    dočasně přesedlat na Chrome nebo Firefox.) Testovaný je skript zatím jen na
    Chromu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Založit v daném pluginu nový skript (pro Chrome je tutorial
    &lt;a href="http://hibbard.eu/tampermonkey-tutorial/"&gt;zde&lt;/a&gt;, pro Firefox
    &lt;a href="http://hayageek.com/greasemonkey-tutorial/"&gt;zde&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Smazat kostru nového skriptu a nahradit ji skriptem, který si zkopírujete výše.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skript uložit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Používat KonText jako normálně -- skript už by podle adresy měl sám poznat,
    že se má spustit. Pokud se tak nestane, nejspíš to znamená, že je
    prohlížečový plugin (Tampermonkey nebo Greasemonkey) deaktivovaný a je
    potřeba jej znovu aktivovat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;V předchozí verzi se po aplikaci libovolného filtru změnil obsah
hledacího boxu na parametry filtrování.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="KonText"></category><category term="korpus"></category><category term="konkordance"></category><category term="NoSke"></category><category term="Bonito"></category></entry><entry><title>Úprava rozhraní konkordanceru KonText</title><link href="http://dlukes.github.io/kontext-interface-tweak.html" rel="alternate"></link><published>2015-02-17T00:00:00+01:00</published><updated>2015-02-17T00:00:00+01:00</updated><author><name>dlukes</name></author><id>tag:dlukes.github.io,2015-02-17:/kontext-interface-tweak.html</id><summary type="html">&lt;p&gt;Skript, kterým si uživatel Českého národního korpusu může upravit rozhraní konkordanceru KonText.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;!POZOR!&lt;/h1&gt;
&lt;p&gt;K dispozici je nyní
&lt;a href="http://dlukes.github.io/kontext-interface-tweak-update.html"&gt;vylepšená verze níže popsaného skriptu&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Hledání v korpusech ČNK&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://korpus.cz"&gt;Český národní korpus&lt;/a&gt; je sbírka jazykových korpusů částečně
vytvářených &lt;a href="http://ucnk.ff.cuni.cz"&gt;Ústavem Českého národního korpusu&lt;/a&gt; a
částečně jinými institucemi. Všechny jsou hostované na jednom serveru a
dostupné skrz různá vyhledávací rozhraní
(tzv. &lt;a href="http://wiki.korpus.cz/doku.php/pojmy:korpusovy_manazer"&gt;konkordancery&lt;/a&gt;),
např. &lt;a href="https://www.korpus.cz/corpora"&gt;NoSke&lt;/a&gt;,
&lt;a href="http://ucnk.ff.cuni.cz/bonito/index.php"&gt;Bonito&lt;/a&gt; či nejnověji
&lt;a href="https://kontext.korpus.cz"&gt;KonText&lt;/a&gt;. Koncem března 2015 ovšem bude podpora
starších rozhraní ukončena a nadále půjde k datům v ČNK přistupovat primárně
pouze přes KonText.&lt;/p&gt;
&lt;p&gt;(Pokud vám odstavec výše nedává příliš smysl, s jazykovými korpusy se setkáváte
poprvé, ale chcete se dozvědět víc, raději si místo tohoto postu přečtěte,
&lt;a href="http://wiki.korpus.cz/doku.php/pojmy:korpus"&gt;k čemu je takový korpus dobrý&lt;/a&gt;, a
&lt;a href="https://kontext.korpus.cz"&gt;zkuste si v něm něco pro zajímavost vyhledat&lt;/a&gt;. Pokud
se vám při vzpomínce na Bonito či NoSke naopak zaskvěla slza v oku, čtěte dál!)&lt;/p&gt;
&lt;h1&gt;&lt;a id="background"&gt;&lt;/a&gt;KonText vs. Bonito / NoSke&lt;/h1&gt;
&lt;p&gt;KonText má oproti starším rozhraním řadu výhod -- bohatší funkcionalitu, mnohé
pomůcky, které vám pomohou se zadáním složitějších dotazů (sestavení
morfologického tagu či podmínky &lt;code&gt;within&lt;/code&gt;), a v neposlední řadě mnohem lépe
vypadá, což kupříkladu mně při práci působí jako balzám na duši. Nicméně
dlouholetí uživatelé ČNK byli jednoduše zvyklí na některé aspekty Bonita a
NoSke, které jim teď v KonTextu chybí.&lt;/p&gt;
&lt;p&gt;Onehdy při rozhovoru s jedním z nich vyplavaly na povrch jako hodně důležité
dvě stížnosti:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Vrchní menu v KonTextu je zákeřné, schovává se, člověk nemá přehled nad
   dostupnými funkcemi. Oproti tomu NoSke má menu po straně a je permanentně
   rozvinuté, takže uživatel má všechny možnosti interakce s konkordancí
   soustavně jako na dlani.&lt;/li&gt;
&lt;li&gt;Po zadání dotazu člověk často na základě konkordance zjistí, že jej
   potřebuje ještě trochu upravit / zjemnit. KonText si sice předchozí dotazy
   pamatuje, je ale potřeba se k nim doklikat; šikovnější by bylo, kdyby tato
   možnost byla dostupná přímo ze stránky konkordance v podobě nějakého
   zjednodušeného hledacího boxu. (NoSke tohle vlastně taky neumí, v Bonitu je
   to jednodušší.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;V obou případech jde o smysluplné požadavky, jenže KonText je poměrně velká a
složitá aplikace, takže i pokud se ČNK rozhodne do ní tyto podněty v nějaké
podobě zapracovat (např. jako možnost přepnutí zobrazení menu), bude nějakou
chvíli trvat, než se implementace navrhne, vytvoří, řádně otestuje a konečně
dostane k uživatelům. Nicméně aby bylo možné alespoň vyzkoušet, jak by zmíněné
změny vypadaly v praxi, dal jsem dohromady krátký skript, který již v
prohlížeči nahraný KonText trochu "přestaví" a upraví. Výsledek vypadá
následovně:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Upravené rozhraní KonText." src="images/kontext_interface_tweak.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;p&gt;Rovnou předesílám: ten skript je nevzhledný bastl přilepený na KonText
zvnějšku; proto taky bylo možné jej dát dohromady poměrně rychle, protože si
neklade nárok na spolehlivost, která se vyžaduje od oficiální verze
KonTextu. Je to spíš prototyp, jehož účelem je otestovat výše popsané změny v
praxi a získat představu o tom, zda a do jaké míry jsou přínosné. (Vlastní
zkušenost: po chvíli používání mi přijde přídatný hledací box nad konkordancí
hodně šikovný a užitečný.)&lt;/p&gt;
&lt;p&gt;Teď k jádru pudla: &lt;strong&gt;pokud máte zájem, můžete si KonText takto k obrazu svému&lt;/strong&gt;
(resp. k obrázku o odstavec výš) &lt;strong&gt;upravit také&lt;/strong&gt; a vyzkoušet, jak vám takové
nastavení vyhovuje. Když se vám jedna z úprav bude líbit (nebo vás u toho
napadne jiná, kterou by si KonText zasloužil), můžete pak zadat
&lt;a href="https://podpora.korpus.cz/projects/kontext/issues/new"&gt;požadavek na nový feature&lt;/a&gt;.
Návod, jak si KonText upravit, následuje níže.&lt;/p&gt;
&lt;h1&gt;Postup instalace skriptu&lt;/h1&gt;
&lt;p&gt;Skript samotný je k dispozici zde:&lt;/p&gt;
&lt;script src="https://gist.github.com/dlukes/0764590b7a8464cbd000.js"&gt;&lt;/script&gt;

&lt;p&gt;K jeho zprovoznění jsou potřeba následující kroky:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Nainstalovat si do svého prohlížeče plugin
    &lt;a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en"&gt;Tampermonkey&lt;/a&gt;,
    pokud používáte Chrome, nebo
    &lt;a href="https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/"&gt;Greasemonkey&lt;/a&gt;,
    pokud používáte Firefox. (Pokud používáte Internet Explorer, budete muset
    dočasně přesedlat na Chrome nebo Firefox.) Testovaný je skript zatím jen na
    Chromu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Založit v daném pluginu nový skript (pro Chrome je tutorial
    &lt;a href="http://hibbard.eu/tampermonkey-tutorial/"&gt;zde&lt;/a&gt;, pro Firefox
    &lt;a href="http://hayageek.com/greasemonkey-tutorial/"&gt;zde&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Smazat kostru nového skriptu a nahradit ji skriptem, který si zkopírujete výše.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skript uložit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Používat KonText jako normálně -- skript už by podle adresy měl sám poznat,
    že se má spustit. Pokud se tak nestane, nejspíš to znamená, že je
    prohlížečový plugin (Tampermonkey nebo Greasemonkey) deaktivovaný a je
    potřeba jej znovu aktivovat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Omezení&lt;/h1&gt;
&lt;p&gt;Skript má pravděpodobně hromadu drobných much, na které se mi zatím nepodařilo
přijít -- budu se je snažit průběžně opravovat, když na ně padnu, nebo
&lt;a href="pages/about.html"&gt;když mi o nich dáte vědět&lt;/a&gt;. Krom toho má i některé mouchy, o
nichž už vím, ale bohužel toho s nimi nejde moc dělat.&lt;/p&gt;
&lt;p&gt;Asi nejnápadnější je, že přidaný hledací box funguje jen na těch stránkách, kde
je původní dotaz i součástí adresy URL (což nejsou všechny -- třeba když
začnete &lt;strong&gt;listovat konkordancí&lt;/strong&gt; na druhou stránku a dál, &lt;strong&gt;dotaz je z adresy
vyjmut&lt;/strong&gt; a &lt;strong&gt;pomocný hledací box tedy zmizí&lt;/strong&gt;). Ale vzhledem k tomu, že jeho
hlavní účel má být možnost lehce upravit dotaz po prvním rychlém nahlédnutí do
konkordance, snad to nebude takový problém. Pokud někdy bude podobný box řádně
přidán přímo do KonTextu, takovými nedostatky samozřejmě trpět nebude.&lt;/p&gt;
&lt;p&gt;A ještě k &lt;strong&gt;používání přidaného hledacího boxu&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Typ dotazu, který je do něj potřeba zadat, je stejný jako ten, který jste
   při prvotním vyhledání konkordance zadali na stránce
   &lt;a href="https://kontext.korpus.cz/first_form"&gt;Nový dotaz&lt;/a&gt;. Pokud tento prvotní
   dotaz byl &lt;em&gt;Základní&lt;/em&gt; dotaz, můžete pomocí rychlého boxu zadat jiný
   &lt;em&gt;Základní&lt;/em&gt; dotaz; pokud to byl &lt;em&gt;CQL&lt;/em&gt; dotaz, můžete ho upravit zas jen na
   další &lt;em&gt;CQL&lt;/em&gt; dotaz. Důvodem je, že &lt;strong&gt;smyslem&lt;/strong&gt; tohoto pomocného boxu &lt;strong&gt;není
   nahradit plnohodnotný formulář&lt;/strong&gt; pro zadání dotazu, jen poskytnout rychlou
   možnost, jak již &lt;strong&gt;zadaný dotaz upravit&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Pomocný hledací box se objeví i poté, co na konkordanci provedete
   filtrování. V takové situaci se dá použít k tomu, abyste &lt;strong&gt;pozměnili zadání
   aktuálního filtru&lt;/strong&gt;, tj. filtrování se provede znovu na původní konkordanci,
   ne na této již filtrované. Pokud chcete opakovaně filtrovat tu samou
   konkordanci a postupně podle daných kritérií vyřazovat / přidávat řádky, je
   potřeba místo hledacího boxu opakovaně použít menu &lt;em&gt;Filtr&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Komu si stěžovat, když to nebude fungovat&lt;/h1&gt;
&lt;p&gt;Skript je volně šiřitelný pod licencí
&lt;a href="http://www.gnu.org/copyleft/gpl.html"&gt;GNU GPL v3&lt;/a&gt;, takže se na něj neváže
žádná záruka. Když se vám ale nebude dařit jej zprovoznit, rád se pokusím
pomoct! Stačí se ozvat na adresu uvedenou &lt;a href="pages/about.html"&gt;zde&lt;/a&gt;.&lt;/p&gt;</content><category term="KonText"></category><category term="korpus"></category><category term="konkordance"></category><category term="NoSke"></category><category term="Bonito"></category></entry></feed>