<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Little Umbrellas</title><link href="http://dlukes.github.io/" rel="alternate"></link><link href="http://dlukes.github.io/feeds/all.atom.xml" rel="self"></link><id>http://dlukes.github.io/</id><updated>2016-07-21T00:00:00+02:00</updated><entry><title>The Cathedral and the Bazaar: What is a Useful Notion of “Language”?</title><link href="http://dlukes.github.io/cathedral-and-bazaar.html" rel="alternate"></link><published>2016-07-21T00:00:00+02:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2016-07-21:cathedral-and-bazaar.html</id><summary type="html">&lt;p&gt;If you like the essay, then you'll definitely want to take a look at Luc
Steels's &lt;em&gt;The Talking Heads Experiment: Origins of Words and Meanings&lt;/em&gt;. It's
published as an open-access book by Language Science Press, so
&lt;a href="http://langsci-press.org//catalog/book/49"&gt;go grab the free download&lt;/a&gt;!&lt;/p&gt;
&lt;h1&gt;Abstract&lt;/h1&gt;
&lt;p&gt;The essay analyzes why Noam Chomsky’s notion of language (both its
essence — language as a set of grammatical sentences — and genesis)
leads neither to interesting discoveries nor even to useful questions
from the point of view of linguistics as a science. A much more fruitful
approach to language is to view it as a complex, dynamic, distributed
system with emergent properties stemming from its functions, as
advocated e.g. by Luc Steels. The argument will be developed against the
backdrop of the evolution of Ludwig Wittgenstein’s thought, from the
&lt;em&gt;Tractatus&lt;/em&gt; to the concept of language games, i.e. from an approach to
language based on thorough formal analysis but also misconceptions about
its functions, to a much keener though less formal grasp of its praxis
and purpose.&lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;At least since Thomas Kuhn’s &lt;em&gt;The Structure of Scientific Revolutions&lt;/em&gt;,
it has been a fairly commonplace notion that working within the confines
of a particular scientific paradigm conditions to a certain extent the
questions one is likely to ask and therefore also the answers that
ensue. This effectively limits the range of possible discoveries,
because some are not answers to meaningful questions within a given
framework while other observations still are taken as given axioms,
which means they cannot be the target of further scientific
investigation.&lt;/p&gt;
&lt;p&gt;In contemporary linguistics, one very prominent such paradigm is that of
&lt;em&gt;generative grammar&lt;/em&gt;, single-handedly established in 1957 by Noam
Chomsky in his seminal work &lt;em&gt;Syntactic Structures&lt;/em&gt;. While serious
criticism has been leveled over time against this initial exposition as
well as Chomsky’s subsequent elaborations on it (see Pullum 2011;
Sampson 2015; and Sampson 2005 for a book-length treatment), the book
undeniably attracted significant numbers of brilliant young minds under
the wings of its research program, which went from aspiring challenger
in the domain of linguistics to established heavyweight in a
comparatively short period of time (the transition had been achieved by
the mid-1970s at the latest). In the process, it co-opted or spawned
various other sub-fields of linguistics, and even rebranded itself, such
that &lt;em&gt;Cartesian linguistics&lt;/em&gt;, &lt;em&gt;cognitive linguistics&lt;/em&gt; and most recently
&lt;em&gt;biolinguistics&lt;/em&gt; are all labels which suggest a strong generativist
presence.&lt;/p&gt;
&lt;p&gt;One serious competitor to the Chomskyan account of language that has
emerged over the years is the field of &lt;em&gt;evolutionary linguistics&lt;/em&gt;. It
might seem strange at first glance why biolinguistics and evolutionary
linguistics should be at odds. As their names indicate, they both aspire
to a close relationship with biology, which seems to indicate their
research agendas and outlooks should largely overlap. Yet their
fundamental assumptions about what constitutes language are so
irreconcilable that they might as well be considered to deal with
different objects of study. Of the two, it is evolutionary linguistics
which leads to questions and investigations which can be conceived of as
scientific (in the Popperian sense of involving falsifiable hypotheses
instead of being merely speculative), consequently yielding the most
useful insights – in the fairly pedestrian sense that these can be
intersubjectively replicated without resorting to an argument from
authority, which makes them a better foundation to build upon, because
the superadded structures are less likely to crumble should said
authority ever change their mind, as Chomsky has done several times
already.&lt;/p&gt;
&lt;h1&gt;Wittgenstein on language: From logical calculus to language games&lt;/h1&gt;
&lt;p&gt;Let us now take a short détour through the development of Ludwig
Wittgenstein’s thoughts on language, so that we may couch our later
discussion of the differences between generative grammar /
biolinguistics and evolutionary linguistics in terms of a contrast that
is perhaps more familiar. The imagery in the title of the present essay
was borrowed from Eric S. Raymond’s book &lt;em&gt;The Cathedral &amp;amp; the Bazaar:
Musings on Linux and Open Source by an Accidental Revolutionary&lt;/em&gt;
(Raymond 1999). In it, Raymond describes two models of collaborative
software development, one of them very rigid, restrictive and hostile to
newcomers (the “cathedral”), the other overwhelmingly inclusive, open to
outside contributions and organic change, an effervescent hive of
activity (the “bazaar”), whose unexpected but empirically demonstrable
virtues he has come to embrace.&lt;/p&gt;
&lt;p&gt;This architectural metaphor also happens to be very apt when
characterizing Wittgenstein’s view of language in the two major stages
of his thought, as represented by his two books &lt;em&gt;Tractatus
Logico-Philosophicus&lt;/em&gt; and &lt;em&gt;Philosophical Investigations&lt;/em&gt;. In the
&lt;em&gt;Tractatus&lt;/em&gt;, Wittgenstein has a “preconceived idea of language as an
exact calculus operated according to precise rules” (McGinn 2006, 12)
and formalizing this system of rules leads him to the following dogmatic
conclusion: “what can be said at all can be said clearly, and what we
cannot talk about we must pass over in silence” (Wittgenstein 2001, 3).
The deontic force of the final injunction should be taken with a grain
of salt; it could perhaps be rephrased in the following less
epigraph-worthy manner: there is a sharp logical boundary to be drawn
between meaningful and nonsensical propositions, and the purpose of
language is to construct meaningful ones, therefore it is futile (rather
than strictly forbidden) to engage in nonsensical ones.&lt;/p&gt;
&lt;p&gt;There have been attempts to read the &lt;em&gt;Tractatus&lt;/em&gt; in an ironic mode, as a
consciously doomed, self-defeating attempt to circumscribe the limits to
the expression of thought, which prefigures the much more subtle
attitude towards language that Wittgenstein later exhibits in the
&lt;em&gt;Philosophical Investigations&lt;/em&gt; (see McGinn 2006, 5–6 and elsewhere for
an overview of this so-called “resolute” reading). In my opinion, such a
stance exhibits a blatant, possibly wilful disregard of his almost
penitent tone in the preface to &lt;em&gt;Philosophical Investigations&lt;/em&gt;: “I could
not but recognize grave mistakes in what I set out in that first book”
(Wittgenstein 2009, 4e).&lt;/p&gt;
&lt;p&gt;Where does Wittgenstein think he went wrong then? Arguably, the most
serious misconception was conferring a privileged ontological status to
language, seeing it as “the unique correlate, picture, of the world”
(Wittgenstein 2009, 49e), whereas in fact, these referential properties
are highly dependent on communicative context. It signifies only insofar
as it has an effect on the addressee (another human being, or even
myself) which to all practical intents and purposes the speaker can
identify as somehow related to what she was trying to achieve with her
utterance in the first place. But there is little meaning, in any
practical sense, outside these highly particular, localized (in both
physical and cultural space and time), embodied, grounded interactions.
Wittgenstein calls these interactions “language-games” to “emphasize the
fact that the &lt;em&gt;speaking&lt;/em&gt; of language is part of an activity, or of a
form of life” (Wittgenstein 2009, 15e, original emphasis). Of course,
the notion of game still involves some kind of rules, but by focusing on
the activity rather than its regulations, it is much easier to account
for “the case where we play, and make up the rules as we go along […]
and even where we alter them – as we go along” (Wittgenstein 2009, 44e).&lt;/p&gt;
&lt;p&gt;This is not to say that we cannot construct abstractions, although
Wittgenstein himself is clearly in favor of systematically examining
particular cases: “In order to see more clearly, here as in countless
similar cases, we must look at what really happens &lt;em&gt;in detail&lt;/em&gt;, as it
were from close up” (Wittgenstein 2009, 30e). However, once we do
abstract away, it is crucial to approach the resulting theory from a
pragmatic standpoint: “We want to establish an order in our knowledge of
language: an order for a particular purpose, one out of many possible
orders, not &lt;em&gt;the&lt;/em&gt; order” (Wittgenstein 2009, 56e, original emphasis).&lt;/p&gt;
&lt;h1&gt;Generative grammar&lt;/h1&gt;
&lt;p&gt;In many ways, Chomsky conceives of language as the early Wittgenstein
did, i.e. under the cathedral metaphor. This may come across as a
surprise because unlike Wittgenstein, he is not concerned with issues of
meaningfulness, philosophical or otherwise. Indeed, it is one of his
fundamental precepts that grammar can and should be dissociated from
meaning, as demonstrated by his famous example sentence “Colorless green
ideas sleep furiously”, which he claims is perfectly grammatical yet
meaningless&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; (Chomsky 2002, Chap. 2).&lt;/p&gt;
&lt;p&gt;Nevertheless, the goal for both is to describe language &lt;em&gt;per se&lt;/em&gt;, in the
abstract, without regard to its context-grounded use in actual
communication. Both strive to give a highly formal definition of the
system they think they are uncovering: while Wittgenstein attempts to
establish a logical calculus of how propositions can be said to carry
meaning in terms of their referential relationship to external reality,
Chomsky tries to hint at a calculus which would determine which
candidate sentences belong to the language encoded by this calculus,
i.e. separate those that are grammatical from those that are not.&lt;/p&gt;
&lt;p&gt;Another way to put this is that the descriptive part of linguistics can
be equated with formal language theory: a language is viewed as a
(potentially infinite) set of symbol strings (sentences), and the
linguist’s task is to find the simplest and most elegant set of rules
that would constitute the basis for a procedure to generate (hence
&lt;em&gt;generative&lt;/em&gt; grammar) all of them and only those, whether observed or
potential. Chomsky himself gives the following definition: “by a
generative grammar I mean simply a system of rules that in some explicit
and well-defined way assigns structural descriptions to sentences”
(Chomsky 1965, 8).&lt;/p&gt;
&lt;p&gt;Furthermore, “Linguistic theory is concerned primarily with an ideal
speaker-listener, in a completely homogeneous speech-community, who
knows its language perfectly” (Chomsky 1965, 3). Specifically, it is
concerned with his “&lt;em&gt;competence&lt;/em&gt; (the speaker-hearer’s [intrinsic]
knowledge of his language)”, not his “&lt;em&gt;performance&lt;/em&gt; (the actual use of
language in concrete situations)” (Chomsky 1965, 4). Additionally, no
claim is made as to the cognitive or neurophysiological accuracy of the
mechanisms described, although to hedge his bets both ways, Chomsky adds
that “No doubt, a reasonable model of language use will incorporate, as
a basic component, the generative grammar that expresses the
speaker-hearer’s knowledge of the language” (Chomsky 1965, 9).&lt;/p&gt;
&lt;p&gt;In short, Chomsky consciously sets up the playing field for a thoroughly
mentalistic, speculative discipline. At first, it might seem like
reasonable approximation and a small concession to make, especially in
the face of the sheer daunting complexity of all the intricate
mechanisms that conspire to yield the phenomenon we call language, but
only until one fully realizes the consequences of such a move. Observe
for instance the carefully crafted loophole claiming that linguistics is
primarily concerned with an ideal speaker-hearer’s competence and that
actual usage data is just circumstantial evidence. This effectively
allows linguists to dismiss inconvenient edge cases or counterexamples
to their theories purely on grounds of their being noisy data or slips
of the tongue, which is something they are allowed to determine based on
introspection. Mind you, this is not just a theoretical loophole;
Chomsky himself has repeatedly relied on it, especially with respect to
so-called linguistic universals (see e.g. Sampson 2005, 139 or 160).&lt;/p&gt;
&lt;p&gt;The net result is rampant, unchecked theorizing. One such example is the
postulation of a two-layer linguistic analysis, the observed language
data corresponding to a surface structure which provides hints as to an
underlying, more regular deep structure to be uncovered. The deep
structure is purportedly closer to the universal properties of language;
both layers are linked by a system of transformations:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We can greatly simplify the description of English and gain new and important
insight into its formal structure if we limit the direct description in terms
of phrase structure to a kernel of basic sentences (simple, declarative,
active, with no complex verb or noun phrases), deriving all other sentences
from these (more properly, from the strings that underlie them) by
transformation, possibly repeated. (Chomsky 2002, 106–7)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Constructing a formal framework for grammar modeling with cognitively
unmotivated levels of abstraction might have been a valid goal (though
arguably not within linguistics) if the result was indeed, as Chomsky
claims it to be, maximally elegant, as simple as can be but no simpler.
I was not able to track down a formal definition of this criterion, but
simplicity is clearly discursively construed as a desirable quality:
“simple and revealing” (Chomsky 2002, 11) or “effective and
illuminating” (Chomsky 2002, 13) are Chomsky’s choice epithets for what
to look for in a grammar. But that is not true either: transformations
are an unnecessary addition, singling them out as a separate category of
operations adds nothing to the generative power of his system (Pullum
2011, 290). They are therefore a wart under any reasonable definition of
“simplicity” and Chomsky thus manages to fall short of even the
self-defined, theory-internal standards that are the only ones he allows
his enterprise to be held to.&lt;/p&gt;
&lt;h1&gt;Ontogeny and phylogeny&lt;/h1&gt;
&lt;p&gt;As we have seen, generative grammar concerns itself with an ideal
speaker-hearer’s competence in a perfectly homogeneous community. The
trouble is that such an impoverished model eschews any possibility of
dynamism. The very dichotomy between grammatical and ungrammatical is
intuitively problematic if we consider that judgments are bound to
diverge when made in reference to different dialects, sociolects and
idiolects,&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; not to mention that binary classification might be too
reductive in some cases (how would you categorize, on first encounter, a
construction which you passively understand but would never produce
actively?). Though Chomsky sometimes mentions in passing the possibility
of levels of grammaticalness which would allow a finer-grained analysis
(e.g. Chomsky 2002, 16; Chomsky 1965, 11), it seems to be just another
instance of hedging his bets, he never makes it a fundamental component
of his theory. This would seem to indicate that Chomsky’s theory of
language has a serious problem in that it is unable to account for any
phenomena that involve fluctuations in linguistic ability, including
language emergence / diachronic change (phylogeny) and acquisition
(ontogeny).&lt;/p&gt;
&lt;p&gt;Chomsky’s response to this is that our language faculty is largely
innate: we are genetically endowed with a &lt;em&gt;language-acquisition device&lt;/em&gt;
in our brains (Chomsky 1965, 31–33) which can supposedly infer the
correct grammatical rules even given incomplete, limited and noisy
input, which is what Chomsky argues children get (the “poverty of
stimulus” argument), thanks to strong universal constraints on what a
human language can be like. Under this account, the capacity for
language, initially “a language of thought, later externalized and used
in many ways” (Chomsky 2007, 24), appeared as a random mutation in a
single individual and progressively spread through the population
because it offered a considerable competitive advantage: “capacities for
complex thought, planning, interpretation” (Chomsky 2007, 22).&lt;/p&gt;
&lt;p&gt;In his later career, Chomsky increasingly focused on exploring this
purported shared genetic basis for human language, hence the
aforementioned label “biolinguistics”. Make no mistake, this in no way
entails a turn from mentalism towards empirical neurophysiological or
genetic investigation. Quite to the contrary, liberated from the
constraints of having to account for individual existing languages in
detail, he soars to new heights of abstractness in postulating the
formal language underpinnings of human language. The &lt;em&gt;principles and
parameters&lt;/em&gt; model of Universal Grammar (Chomsky 1986) expands upon the
notion of linguistic universals by splitting them up into two sets:
principles, which are hardwired and immutable, and parameters, which are
hardwired too but can be flipped on or off based on linguistic behavior
observed by the child in her particular language community. Since the
choices are heavily constrained, the learner can infer correct parameter
settings in spite of deficient input. This line of research culminates
in the so-called &lt;em&gt;minimalist program&lt;/em&gt; (Chomsky 1995), where Chomsky
identifies the “core principle of language, [the operation of]
unbounded Merge” (Chomsky 2007, 22). Under the “strong” minimalist
hypothesis, this would be the only principle necessary to account for
human-like languages (Chomsky 2007, 20), which would paradoxically
essentially discard all work (or should I say speculation?) previously
done on the parameters side of the Universal Grammar project. All other
universal characteristics of language could then be explained by newly
introduced “interface” conditions,&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; i.e. constraints on how language
inter-operates with other systems, including thought and physical
language production (Chomsky 2007, 14);&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; all empirically documented
variation between the world’s languages would be chalked up to lexical
differences (Chomsky 2007, 25).&lt;/p&gt;
&lt;p&gt;The poverty of stimulus and language universals arguments for innateness
have been thoroughly debunked, especially in Geoffrey Sampson’s
book-length diatribe &lt;em&gt;The &lt;/em&gt;‘&lt;em&gt;Language Instinct&lt;/em&gt;’&lt;em&gt; Debate&lt;/em&gt;. In short, it
turns out that some of the grammatical constructions which were assumed
to be absent from a language learner’s input yet acquired nonetheless
have since been empirically proven to occur fairly commonly (Sampson
2005, 72–79). Moreover, there is no qualitative difference between a
statement like “the stimulus is too poor to allow language learning
without a genetic basis” and “the stimulus is just rich enough etc.”,
both are unverifiable unless we have already independently proven that
language learning occurs one way or the other, so to adduce either of
the statements as proof for the hypothesis at stake is misguided
(Sampson 2005, 47–48). Finally, the alleged language universals turn out
to be either false when checked against additional languages (Sampson
2005, 138–9) or so general as to be meaningless (Sampson 2005, Chap. 5).&lt;/p&gt;
&lt;p&gt;Irrespective of this, let us suppose for a moment that genetic mutation
and subsequent inheritance do play a role in the emergence of language,
and work out an account of language emergence consistent with this
hypothesis. If language started out through mutation in a single
individual as a purely internal advanced conceptualization faculty, then
once it started to spread, what was the motivation for the
genetically-endowed humans to externalize their thoughts? How did they
know to which of their peers they could speak (which had inherited the
mutation) and which not? And most importantly, how did they know which
parameters of Universal Grammar to flip on and which off, if there was
no prior language based on which to decide? Universal Grammar would have
had to be fairly detailed in order for intersubjective agreement on the
norms for the first ever human language to be reached on the basis of it
alone. Yet as we have seen, Chomsky has been moving away from this
notion – at the limit, the minimalist program posits only one very
general mechanism required for language. The poverty of stimulus
argument is turned against its creator as the argument from poverty of
the machinery supposed to make up for the poverty of said stimulus.&lt;/p&gt;
&lt;p&gt;Alternatively, if we fully subscribe to the minimalist program and the
notion that all the surface variety exhibited by language comes from the
lexicon, then how are individual words created, how do they propagate?
One might be tempted to say “people just invented them”, but consider
for a while that in the current setup, there is absolutely no mechanism
that would explain how a community of speakers reaches agreement on
their lexicon – this theory offers no incentive whatsoever for consensus
to be reached; from its point of view, a solution where each speaker
ends up with their own private lexicon is equally valid because
indistinguishable on the basis of the theory’s conceptual apparatus.
Chomsky’s ideas on phylogenesis appear thoroughly ridiculous when fully
carried out to their logical consequences, and this can all be blamed on
his sterile, idealized and static view of language which dismisses
actual communication as a secondary purpose and therefore a peripheral
issue.&lt;/p&gt;
&lt;p&gt;On a side note, it is hard to say which aspect of Chomsky’s theory of
language came first – whether innateness accommodated the mentalism and
the concomitant quest for formal purity (botched as it may be) of
generative grammar, whether it was the other way round, or whether they
perhaps co-evolved in his mind. The facts are that Chomsky’s initial
publications on generative grammar concentrate on the formal language
theory part (Chomsky 1956; Chomsky 2002), but he added the innateness
argument fairly early on, even tacking a seemingly respectable
philosophical lineage onto it in &lt;em&gt;Cartesian Linguistics&lt;/em&gt; (Chomsky 2009),
which pretends to trace back both innateness and mentalism to Descartes
and the Port-Royal grammarians, binding them as two sides of the same
coin. It is worth noting that in both formal language theory and history
of linguistics / philosophy, Chomsky is more of a dabbler than an
expert: he has provably borrowed most of his ideas in the former field
from others, sometimes mangling them or extending them in unfortunate
ways (Pullum 2011; Sampson 2015), and has thoroughly underresearched (or
wilfully twisted?) his understanding of the latter, which has resulted
in serious misrepresentations of the history of ideas (Miel 1969;
Aarsleff 1970).&lt;/p&gt;
&lt;h1&gt;Evolutionary linguistics&lt;/h1&gt;
&lt;p&gt;There are various sub-fields of linguistics which are in discord with
generative grammar, especially over the notion that performance data
should be used only as evidence for guiding the speculation and detailed
usage and frequency patterns should be disregarded; the primacy of
syntax (as advocated by Chomsky) is also disputed. One of these
sub-fields is obviously corpus linguistics, which takes a decidedly
empiricist stance and starts by assembling a large body of language data
(a corpus) from which patterns of language use are inferred.
Nevertheless, not all of these compete with generative grammar at the
fundamental explanatory level of how language came about
phylogenetically and how it is transmitted by ontogenetic acquisition.&lt;/p&gt;
&lt;p&gt;We have repeatedly encountered Chomsky’s emphasis on how communication,
actual interactions between speakers, are just an afterthought in the
system of language:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;evolutionary biologist Salvador Luria was the most forceful advocate of the
view that communicative needs would not have provided “any great selective
pressure to produce a system such as language,” with its crucial relation to
“development of abstract or productive thinking.” His fellow Nobel laureate
François Jacob (1977) added later that “the role of language as a
communication system between individuals would have come about only
secondarily, as many linguists believe,” (Chomsky 2007, 23)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Part of this vehemence dovetails with the single individual mutation
hypothesis of the origins of language – it helps if the significance of
communication is downplayed in an account where communication is
initially impossible, simply because there is no other language-endowed
being to communicate with. If communication were language’s killer
feature, then the selective pressure for the incriminated gene to
propagate would not kick in.&lt;/p&gt;
&lt;p&gt;The other part can reasonably be attributed to Chomsky’s intent to make
a clean break from a prior popular theory on language acquisition,
epitomized by B. F. Skinner’s 1957 monograph &lt;em&gt;Verbal Behavior&lt;/em&gt;, which
offered a heavily empiricist, behaviorist account of language learning
in terms of a stimulus-response cycle. Characteristically, Chomsky’s
strategy is to trivialize the function of the stimulus, casually
implying both that it might not be needed at all, and if it is, then
details of the role it plays are of little interest:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;it would not be at all surprising to find that normal language learning
requires use of language in real-life situations, in some way. But this, if
true [sic!], would not be sufficient to show that information regarding
situational context (in particular, a pairing of signals with structural
descriptions that is at least in part prior to assumptions about syntactic
structure) plays any role in determining how language is acquired, once the
mechanism is put to work and the task of language learning is undertaken by
the child. (Chomsky 1965, 33)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In retrospect, Skinner’s account may be simplistic in many ways, but the
basic notion that one has to pay attention to stimuli and responses in
the course of particular linguistic interactions is sound. In
particular, a theory of language built on this foundation successfully
copes with all of the impasses we have explored above regarding
Chomsky’s approach. One such framework is that of evolutionary
linguistics.&lt;/p&gt;
&lt;p&gt;Evolutionary linguistics views language as a &lt;em&gt;complex adaptive system&lt;/em&gt;
with &lt;em&gt;emergent properties&lt;/em&gt; (Steels 2015, 8–9). A complex adaptive system
is a system which is not centrally organized, coordinated or designed:
its “macroscopic” characteristics are said to “emerge” as the result of
localized interactions between individual entities (agents) with similar
“microscopic” characteristics (be they physical, behavioral or
motivational). The whole is more than the sum of its parts, and none of
the agents can be properly said to have designed the system, nor can
they deliberately change it in an arbitrary way; but all are
continuously shaping it by taking part in the interactions that
constitute its fabric. Examples of complex adaptive systems include the
dynamics of insect societies (beehives, ant nests) or patterns of
collective motion in large animal groups (flocks of birds or shoals of
fish). These and more are discussed in much greater depth in the first
chapter of Pierre-Yves Oudeyer’s book &lt;em&gt;Self-Organization in the
Evolution of Speech&lt;/em&gt;. Adaptiveness is a property that these systems
acquire by virtue of not being hardwired on the macro level: they are
defined functionally instead of structurally. If the conditions in the
environment change, the system will adapt to keep fulfilling its
function, because the agents are forced to modify their behavior in
order to achieve their individual goals. Of course, they may fail to do
so, in which case the system breaks down and ceases to exist.&lt;/p&gt;
&lt;p&gt;If we revert to the metaphor from the title of the present essay,
according to Chomsky, language is a cathedral erected by a single
unwitting architect, the random genetic mutation that endowed us with
the language faculty. Conversely, Luc Steels and fellow evolutionary
linguists argue that the apparent macroscopic orderliness of language is
the result of a myriad interactions of multiple individual agents, as
suggested by the the bazaar image.&lt;/p&gt;
&lt;p&gt;One form that linguistic research can take under this paradigm is
formulating and running computational models which simulate the behavior
of agent populations and study the microscopic conditions, i.e. the
cognitive and physical abilities, motivations etc. of each agent,
necessary for a system like language to emerge within the population and
stabilize. By direct inspiration from Wittgenstein’s &lt;em&gt;Philosophical
Investigations&lt;/em&gt;, the interactions between agents are termed “language
games” (Steels 2015, 167–8); depending on the topic being investigated,
the agents can play different types of language games with different
rules. It is openly acknowledged that such simulations represent only a
limited approximation of a well-defined subspace of the actual uses of
language. In the research to date, rules are generally definite and set
for the entire experiment, but simulating language games with fuzzy
rules remains a perfectly valid research topic within this framework, in
the Wittgensteinian spirit of allowing rules to be made up and modified
“as we go along” (Wittgenstein 2009, 44e).&lt;/p&gt;
&lt;p&gt;A relatively simple game that agents can play is the so-called &lt;em&gt;Guessing
Game&lt;/em&gt; (see Chap. 2 of Steels 2015 for more details). In this scenario, a
population of agents, embodied in physical robots, tries to establish a
shared lexicon and coupled ontology for a simple world consisting of
geometrical shapes. Each game is an interaction of two agents picked at
random, in the context of a scene consisting of said geometrical shapes.
One agent (the speaker) takes the initiative, selects a topic from the
scene and names it; the other (the hearer) tries to guess which object
the first one had in mind and points to it; the speaker decodes the
pointing gesture and the game succeeds if he interprets it as
referencing his original topic. If so, he acknowledges the match;
otherwise, he points at the intended topic as a repair strategy. At the
outset, neither the lexicon nor the ontology are given, only a set of
sensors and actuators (which allow the agents to interact with the
environment by taking in streams of raw perceptual data or producing
sound and pointing gestures) and very general cognitive principles.
These include an associative memory and feedback mechanisms to propagate
failures and successes in conceptualization and communication to all
components of the system and act on them.&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt; New distinctions along the
perceptual dimensions are introduced in a random fashion,&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt; but those
that lead to a successful unambiguous selection of a topic and
communicative success are strengthened over the course of many
interactions, while useless ones are dampened by lateral inhibition and
eventually pruned. At the same time, speakers create new words for
concepts that are as of yet missing from their lexicon, and hearers may
adopt them into theirs for their conceptualization of the topic the
speaker points at in case of failure. A similar feedback mechanism then
ensures that highly successful words are preferred and come to dominate
within the speech community. It is important to realize that at no time
do the individual agents share the same ontology or lexicon: newly
introduced distinctions and words are random and unique for each agent,
agents simply gradually learn which of these are useful in achieving
communicative success, which means that they naturally settle on
ontologies and lexicons that are close enough to those of others in the
population.&lt;/p&gt;
&lt;p&gt;This barely scratches the surface of how all these notions must be
orchestrated for a working computer implementation of this model, not to
mention the even more elaborate agent-based language game modeling
experiments that are already being conducted, investigating for instance
the emergence of grammar (see Part III of Steels 2015 for an overview of
recent scholarship). We see that even a seemingly simple task like
establishing a shared conceptualization of reality and agreeing on names
for these concepts is a complex endeavor which relies on a highly
sophisticated (though also highly general) machinery. Another key
observation is that while agent-based models can be fully virtual,
grounding them in physical reality (cf. the use of robots with sensors
and actuators) brings additional challenges that enable researchers to
reach vital insights which would otherwise be impossible. In particular,
grounding introduces fuzziness on the sensory input channels (by virtue
of different points of view for the two robots and analog-to-digital
conversion) which the agents must cope with, or else the mechanisms they
were endowed with cannot be considered as constituting a plausible,
sufficient model of the dynamics of human language. Unlike in generative
grammar, anything that is transient, imperfect, is eminently included in
the purview of linguistic inquiry. Failures are very much part of the
dynamics that steer the evolution of language. How could it adapt to the
speakers’ changing requirements if it did not include appropriate repair
strategies? Indeed, how could it be bootstrapped at all? The reward is a
model that successfully simulates not only language emergence, but also
transmission: if virgin agents are added into an existing population,
they gradually acquire its language (see Fig. 1).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img alt="communicative success plot" src="images/communicative_success.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Communicative success in a population of agents with a steady
influx of virgin agents and outflux of old ones (overall population size
remains the same). The game starts in phase 1 with 20 virgin agents; phases 2
and 4 show the behavior of the model at an agent renewal rate of 1/1000 games,
whereas phase 3 corresponds to a heavier rate of 1/100. (Figure from Steels
2015, 121.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Crucially, the drive to communicate, to interact, is built into the
agents, they just keep playing games as long as they can. But if it was
not, the simulation would have to be more complex and somehow elicit
this drive by introducing appropriate ecological constraints, e.g. by
requiring co-operation as a survival strategy (Steels 2015, 106).
Otherwise, the agents would have no motivation to strive for
communicative success in their mutual encounters, they would fail to
reach intersubjective alignment of their conceptual spaces and lexicons,
and language would not emerge. In other words, far from being an
afterthought, successful communication with a partner, grounded in an
external context, turns out to be a fundamental requirement to establish
the kind of dynamics which allow languages to appear.&lt;/p&gt;
&lt;p&gt;Paradoxically, since it concerns itself with simulations and
computational models, this branch of evolutionary linguistics is, like
generative grammar, also highly speculative. However, unlike generative
grammar, it is a kind of speculation which considers guidance by
empirical observations a necessity, not a nuisance. Furthermore,
simulations are meant to be tested: if an agent-based model of language
emergence fails to converge on the result stipulated for that particular
experiment, the model is plain wrong and the dynamics it is trying to
put into place (cognitive strategies, feedback propagation etc.) need to
be revised. There is thus a clear-cut criterion for validity. Lastly,
even if a simulation works, an accompanying debate as to whether the
mechanisms involved are actually plausible approximations of reality is
considered an integral part of hypothesis evaluation, with evidence from
strongly empirically grounded disciplines like biology and
neurophysiology a vital element in the process.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Taking a cue from Wittgenstein’s &lt;em&gt;Philosophical Investigations&lt;/em&gt;, this
essay should not be construed as an attempt to replace one doctrine with
another, but to advocate a “change of attitude” (cf. McGinn 2013, 33)
which allows asking more meaningful questions about language. This being
said, on the evidence presented above, it is hard not to conclude that
Noam Chomsky is fundamentally mistaken about the corrective that is
necessary for language learning to take place. According to Chomsky, the
criterion for evaluating linguistic rules lies within a dedicated
language organ we are genetically endowed with; the innate structures
themselves embody the metric by which conjectures pertaining to
linguistic rules will be judged. By contrast, in the evolutionary
linguistics perspective, genetics provide innate structures which are
capable of random growth, but the feedback (reinforcement and pruning)
which results in steering this growth in a particular direction comes
from interactions with the environment. This theory presupposes much
less specificity in the hardware infrastructure which makes this
possible and so should be preferred both on grounds of simplicity and
flexibility of the model, not to mention that it is biologically
plausible and has been empirically verified to work.&lt;/p&gt;
&lt;p&gt;In the context of science, Chomsky’s rhetorical strategy in and of
itself is dishonest: he preaches formal rigor while practicing sleight
of hand, and casually retreats to increasingly abstract ground on
reaching an impasse. He thus carves out a region in discursive space
which has no corresponding equivalent in a logically consistent
conceptual space, without which a piece of discourse can hardly
constitute a scientific theory. In other words, much like his famous
example sentence “Colorless green ideas sleep furiously”, his discourse
is grammatical but largely nonsensical under the requirements on a
system of thought which aspires to mirror reality in a coherent fashion.&lt;/p&gt;
&lt;p&gt;Requirements on scientific discourse notwithstanding, we as linguists
should keep in mind that language in general is much more than a system
for encoding logical propositions. Even Wittgenstein had to resign
himself to the fact – or perhaps knew all along – that the &lt;em&gt;Tractatus&lt;/em&gt;,
which he framed as the ultimate solution to all metaphysical
controversies, could only fan the flames of philosophical debate. It was
after all addressed to a diverse community of people bound perhaps
exclusively by their penchant for elaborate language games.&lt;/p&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;Aarsleff, Hans. 1970. “The History of Linguistics and Professor
Chomsky.” &lt;em&gt;Language&lt;/em&gt; 46 (3): 570–85.&lt;/p&gt;
&lt;p&gt;Chomsky, Noam. 1956. “Three Models for the Description of Language.”&lt;/p&gt;
&lt;p&gt;———. 1965. &lt;em&gt;Aspects of the Theory of Syntax&lt;/em&gt;. Cambridge, MA: The M.I.T.
Press.&lt;/p&gt;
&lt;p&gt;———. 1986. &lt;em&gt;Knowledge of Language: Its Nature, Origin, and Use&lt;/em&gt;.
Convergence. New York, Westport, London: Praeger.&lt;/p&gt;
&lt;p&gt;———. 1995. &lt;em&gt;The Minimalist Program&lt;/em&gt;. Cambridge, MA: The MIT Press.&lt;/p&gt;
&lt;p&gt;———. 2002. &lt;em&gt;Syntactic Structures&lt;/em&gt;. 2nd ed. Berlin, New York: Mouton de
Gruyter.&lt;/p&gt;
&lt;p&gt;———. 2007. “Of Minds and Language.” &lt;em&gt;Biolinguistics&lt;/em&gt;, no. 1: 9–27.&lt;/p&gt;
&lt;p&gt;———. 2009. &lt;em&gt;Cartesian Linguistics: A Chapter in the History of
Rationalist Thought&lt;/em&gt;. 3rd ed. Cambridge: Cambridge University Press.&lt;/p&gt;
&lt;p&gt;McGinn, Marie. 2006. &lt;em&gt;Elucidating the Tractatus: Wittgenstein’s Early
Philosophy of Logic and Language&lt;/em&gt;. Oxford: Oxford University Press.&lt;/p&gt;
&lt;p&gt;———. 2013. &lt;em&gt;The Routledge Guidebook to Wittgenstein’s Philosophical
Investigations&lt;/em&gt;. The Routledge Guides to Great Books. Routledge.&lt;/p&gt;
&lt;p&gt;Miel, Jan. 1969. “Pascal, Port-Royal, and Cartesian Linguistics.”
&lt;em&gt;Journal of the History of Ideas&lt;/em&gt; 30 (2): 261–71.&lt;/p&gt;
&lt;p&gt;Oudeyer, Pierre-Yves. 2006. &lt;em&gt;Self-Organization in the Evolution of
Speech&lt;/em&gt;. Translated by James R. Hurford. Oxford, New York: OUP.&lt;/p&gt;
&lt;p&gt;Pullum, Geoffrey K. 2011. “On the Mathematical Foundations of &lt;em&gt;Syntactic
Structures&lt;/em&gt;.” &lt;em&gt;Journal of Logic, Language and Information&lt;/em&gt; 20: 277–96.&lt;/p&gt;
&lt;p&gt;Raymond, Eric S. 1999. &lt;em&gt;The Cathedral &amp;amp; the Bazaar: Musings on Linux and
Open Source by an Accidental Revolutionary&lt;/em&gt;. O’Reilly Media.&lt;/p&gt;
&lt;p&gt;Sampson, Geoffrey. 2005. &lt;em&gt;The “Language Instinct” Debate&lt;/em&gt;. 3rd ed.
London, New York: Continuum.&lt;/p&gt;
&lt;p&gt;———. 2015. “Rigid Strings and Flaky Snowflakes.” &lt;em&gt;Language and
Cognition&lt;/em&gt; 10: 1–17.&lt;/p&gt;
&lt;p&gt;Skinner, B. F. 1957. &lt;em&gt;Verbal Behavior&lt;/em&gt;. The Century Psychology Series.
New York: Appleton – Century – Crofts.&lt;/p&gt;
&lt;p&gt;Steels, Luc. 2015. &lt;em&gt;The Talking Heads Experiment: Origins of Words and
Meanings&lt;/em&gt;. Computational Models of Language Evolution 1. Berlin:
Language Science Press.&lt;/p&gt;
&lt;p&gt;Wittgenstein, Ludwig. 2001. &lt;em&gt;Tractatus Logico-Philosophicus&lt;/em&gt;. Routledge
Classics. London, New York: Routledge.&lt;/p&gt;
&lt;p&gt;———. 2009. &lt;em&gt;Philosophical Investigations&lt;/em&gt;. Chichester, United Kingdom:
Blackwell Publishing.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Let us pretend for a moment that language games like “poetry” or
the surrealist pastime of &lt;em&gt;cadavre exquis&lt;/em&gt; do not exist; in these,
the quoted sentence could appear as perfectly valid and meaningful,
though perhaps not in the sense that Chomsky intended. “Meaningful”
in a late-Wittgensteinian perspective could be paraphrased as
“accepted by at least one involved party as a valid turn within the
context of a particular language game”.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Arguing that this does not matter because we should be concerned
with the &lt;em&gt;ideal&lt;/em&gt; speaker-hearer’s competence just takes us further
down the impasse, because now we have to determine how to delimit
the purported “ideal”.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;This is the beauty of building empirically unmotivated, purely
speculative theories: at any moment, one can freely accommodate a
new element into the existing framework, substituting novelty and
amalgamation for critical evaluation.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Cf. also Sampson’s riposte : “If complex properties of some aspect
of human behaviour have to be as they are as a matter of conceptual
necessity, then there is no reason to postulate complex genetically
inherited cognitive machinery determining those behaviour patterns”
(Sampson 2015, 9).&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;This interconnected architecture stands in stark contrast to
Chomsky’s deliberately isolationist approach: “the relation between
semantics and syntax […] can only be studied after the syntactic
structure has been determined on independent grounds” (Chomsky 2002,
17).&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;Wittgenstein only hints at the problem of conceptualization, but
he is prescient in realizing it is not a given: “The primary
elements [of the objects which constitute the world in this
particular language game] are the coloured squares. ‘But are these
simple?’ – I wouldn’t know what I could more naturally call a
‘simple’ in this language-game. But under other circumstances, I’d
call a monochrome square, consisting perhaps of two rectangles or of
the elements colour and shape, ‘composite’” (Wittgenstein 2009,
27e).&amp;#160;&lt;a class="footnote-backref" href="#fnref:6" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="linguistics"></category><category term="Wittgenstein"></category><category term="Chomsky"></category></entry><entry><title>Configuring Emacs Daemon on Mac OS X</title><link href="http://dlukes.github.io/emacs-daemon-osx.html" rel="alternate"></link><published>2016-02-20T00:00:00+01:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2016-02-20:emacs-daemon-osx.html</id><summary type="html">&lt;p&gt;I know I promised this article a loooong time ago (June 2014, when I first got a
Mac, to judge by the previous timestamp in the header of this file), but since
the historically attested readership of this blog is 2 + a bunch of my facebook
friends who I nagged to read
&lt;a href="http://dlukes.github.io/unicode.html"&gt;my attempt at explaining character encodings to non-technical people&lt;/a&gt;,
I don't suppose it's as if a legion of fans have been restlessly looking forward
to this one ;) Nevertheless, the distinct advantage is that my OS X Emacs setup
has had the opportunity to grow more mature and also much simpler in the
meantime, which means that if a third reader accidentally stumbles over this
note (exploding my ratings...), they might actually find something genuinely
useful here.&lt;/p&gt;
&lt;h1&gt;tl;dr&lt;/h1&gt;
&lt;p&gt;This article presents a way to &lt;strong&gt;start Emacs Daemon&lt;/strong&gt; (a persistent Emacs
session) &lt;strong&gt;from the GUI&lt;/strong&gt; and &lt;strong&gt;subsequently connect to it&lt;/strong&gt; (creating frames on
demand) using an &lt;strong&gt;Automator script&lt;/strong&gt;. The &lt;strong&gt;benefit&lt;/strong&gt; is that you &lt;strong&gt;incur
startup time lag only once&lt;/strong&gt; (when you start the daemon) while still being able
to &lt;strong&gt;close all frames&lt;/strong&gt; when you're not using Emacs, keeping a &lt;strong&gt;clean
workspace&lt;/strong&gt;. This is &lt;strong&gt;especially useful&lt;/strong&gt; if your Emacs is &lt;strong&gt;heavily
customized&lt;/strong&gt; and &lt;strong&gt;loading it takes a while&lt;/strong&gt;. Another &lt;strong&gt;benefit&lt;/strong&gt; is that
whenever you open a frame connected to an Emacs daemon, &lt;strong&gt;all your previously
open buffers are still there as you left them&lt;/strong&gt; (as opposed to opening a fresh
instance of Emacs).&lt;/p&gt;
&lt;p&gt;Skim over the code blocks to get the
important gist without the verbose sauce. Tested on OS X 10.11 El Capitan, with
Homebrew Emacs and Spacemacs config.&lt;/p&gt;
&lt;h1&gt;Why Emacs Daemon, why this post&lt;/h1&gt;
&lt;p&gt;Installing Emacs on a Mac in and of itself is not that much of a problem --
there are several options, ranging from Homebrew and Macports to
&lt;a href="http://emacsformacosx.com/"&gt;Emacs for Mac OS X&lt;/a&gt;,
&lt;a href="https://github.com/railwaycat/emacs-mac-port"&gt;Emacs Mac Port&lt;/a&gt; and
&lt;a href="http://aquamacs.org/"&gt;Aquamacs&lt;/a&gt;. The last two in this list have some OS X
specific tweaks (smooth scrolling, tabs, adapted keyboard shortcuts), which
makes them perhaps more appealing out of the box but also less extensible, as
some of the information out there about generic Emacs might not apply to them as
straightforwardly or indeed at all.&lt;/p&gt;
&lt;p&gt;With that in mind, if you want to tinker with your Emacs config, it's a good
idea to stick with &lt;a href="http://brew.sh/"&gt;Homebrew's&lt;/a&gt; fairly conservative version of
Emacs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ brew update
$ brew install emacs --with-cocoa
&lt;span class="c1"&gt;# this step gets you a standard OS X launcher icon&lt;/span&gt;
$ brew linkapps emacs
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But now that you've got Emacs, and especially if you're transferring some heavy
customization over from say Linux, you might be unhappy that each time you start
it from cold, it takes a while, typically a few seconds. That's what &lt;code&gt;emacs
--daemon&lt;/code&gt; and &lt;code&gt;emacsclient&lt;/code&gt; are for: &lt;strong&gt;Emacs&lt;/strong&gt; is run as a &lt;strong&gt;daemon&lt;/strong&gt; in the
&lt;strong&gt;backround&lt;/strong&gt; and you connect to it with &lt;strong&gt;client frames&lt;/strong&gt; that &lt;strong&gt;spawn almost
instantly&lt;/strong&gt;. This also means that you can close all existing frames to keep your
workspace clean if you won't be using Emacs for a while (hard to imagine, right,
since you can even
&lt;a href="https://github.com/vibhavp/emacs-xkcd"&gt;read xkcd from inside Emacs&lt;/a&gt;) and then
whip up a frame at the speed of a thought when need arises.&lt;/p&gt;
&lt;p&gt;Now this is all
&lt;a href="http://stackoverflow.com/a/5578718/1826241"&gt;easy to achieve when using the terminal&lt;/a&gt;,
but since you probably bought that Mac in great part for its shiny pretty
elegant ergonomic GUI, you might want Emacs to use GUI frames instead of
terminal ones and connect to the Emacs daemon (or start it if it's not running)
by just clicking on an app icon in the launcher or finding it from Spotlight.
That's where Automator comes in.&lt;/p&gt;
&lt;h1&gt;An Automator script&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://www.macosxautomation.com/automator/"&gt;Automator&lt;/a&gt; is a built-in OS X app
for creating custom automated user workflows for just about any installed app
you might have or even OS functionality. Among other things, this means that it
allows you to wrap the daemon auto-start functionality available from the
terminal (as described in the previous paragraph) into an app launchable from
the GUI. Let's get down to business:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Launch Automator and create a new document. Select &lt;em&gt;Application&lt;/em&gt; as its type.&lt;/li&gt;
&lt;li&gt;Search the Actions palette on the left for the &lt;em&gt;Run Shell Script&lt;/em&gt; action and
   add it to your Automator document.&lt;/li&gt;
&lt;li&gt;In the &lt;em&gt;Run Shell Script&lt;/em&gt; building block, change the following:&lt;ul&gt;
&lt;li&gt;set &lt;em&gt;Shell&lt;/em&gt; to the shell you're using and whose init files have thus the
  &lt;code&gt;PATH&lt;/code&gt; correctly set to the &lt;code&gt;emacs&lt;/code&gt; and &lt;code&gt;emacsclient&lt;/code&gt; executables (if
  you're using Homebrew, it probably told you how to properly set up your
  &lt;code&gt;PATH&lt;/code&gt; as a post-install step)&lt;/li&gt;
&lt;li&gt;set &lt;em&gt;Pass input&lt;/em&gt; to "as arguments" (if you then
  &lt;a href="http://osxdaily.com/2013/08/08/change-default-application-open-files-mac-os-x/"&gt;set this Automator app as the default for opening a given type of file&lt;/a&gt;,
  you'll be able to use &lt;code&gt;emacsclient&lt;/code&gt; to open files by double-clicking on them
  in Finder)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Finally, paste in the following code snippet and save the app e.g. as
   &lt;code&gt;EmacsClient.app&lt;/code&gt;, preferably in your Applications folder so that it is
   easily accessible from the launcher.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;emacsclient --no-wait -c -a emacs &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt;/dev/null 2&amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;: An earlier version of this article had &lt;code&gt;nohup&lt;/code&gt; prepended to the
command above; as pointed out in the comments by &lt;strong&gt;MaTres&lt;/strong&gt; (thanks!), this is
&lt;a href="https://developer.apple.com/library/mac/technotes/tn2065/_index.html"&gt;unnecessary&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the end of the day, your Automator EmacsClient.app should look something like
this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="EmacsClient.app" src="images/emacsclientapp.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;p&gt;The core of the command that you might want to tweak based on your particular
Emacs setup is &lt;code&gt;emacsclient --no-wait -c -a emacs&lt;/code&gt;; mine is optimized to work
with mostly stock Spacemacs config (see below). If it doesn't work, you might
also want to try a simple &lt;code&gt;emacsclient -c -a ""&lt;/code&gt; and variations; a good
debugging technique is to try these out in the terminal: as soon as you get the
line working there, it'll start working in the Automator task as well.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;"$@"&lt;/code&gt; is just the list of files (if any) passed to Emacs to open (the
aforementioned double-click in Finder use case). The rest is some black magic to
ensure that the shell which spawns the Emacs process (because this Automator app
is after all, at heart, only a shell script) totally and utterly disowns it, so
that the shell script is allowed to return and the Automator task completes as
soon as Emacs has started (or the client has spawned a new frame). Otherwise,
you'd end up with an irritating spinning cog wheel in your notification area
which would stay there until you completely quit Emacs. Which is probably not
what you want, since you're undergoing all this hassle in the first place to get
a zen, distraction-free Emacs experience.&lt;/p&gt;
&lt;p&gt;The details of the various incantations are discussed in
&lt;a href="https://discussions.apple.com/thread/6474971?start=0&amp;amp;tstart=0"&gt;this Apple forum thread&lt;/a&gt;,
but let's have a whirlwind tour for the moderately interested (my knowledge of
Unix processes is far from perfect, so feel free to correct me on these points!):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;/dev/null&lt;/code&gt; redirects standard output to oblivion and &lt;code&gt;2&amp;gt;&amp;amp;1&lt;/code&gt; redirects
   standard error to standard output (i.e. also to oblivion), which persuades
   Automator that you're really not expecting to hear from the process via these
   standard streams ever again, so there's no point in keeping the shell script
   running. These can be shortened to &lt;code&gt;&amp;amp;&amp;gt;/dev/null&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;the final &lt;code&gt;&amp;amp;&lt;/code&gt; runs the command in the background, which ensures control of
   the shell is returned to the user as soon as the process is spawned; since
   there are no additional commands in the shell script and all remaining ties
   have been severed, Automator finally agrees that the task has probably done
   all it was expected to do and exits it.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;Whew! That's it. It's really not that complicated, it's just that my prose is
verbose, so it makes it look like there's lots and lots to do. Trust me, there
isn't. My first go at solving this usability problem -- the one I originally
wanted to post way back in 2014 -- was a lengthy, godawful Applescript prone to
subtle breakage. This is &lt;em&gt;much&lt;/em&gt; better.&lt;/p&gt;
&lt;p&gt;And the ability to just use a single GUI app for transparently launching &lt;strong&gt;and&lt;/strong&gt;
connecting to the Emacs daemon is pure bliss. While you're at it, for an even
better Emacs experience, go fetch the excellent
&lt;a href="http://spacemacs.org"&gt;Spacemacs Emacs config distribution&lt;/a&gt;, which pulls this
venerable piece of software screaming into the 21st century. &lt;strong&gt;The best editor
is neither Vim nor Emacs, its Vim + Emacs!&lt;/strong&gt; The addictive icing of Vim modal
editing on the outside, a creamy Elisp core -- what more could you want from
life? ;)&lt;/p&gt;
&lt;p&gt;Oh and if, like me, you love
&lt;a href="https://github.com/nashamri/spacemacs-logo"&gt;Spacemacs' snappy icon&lt;/a&gt; with the
Evil spaceship over planet Emacs -- or if, like me, you have OCD -- you'll
&lt;a href="http://www.macworld.co.uk/how-to/mac-software/how-change-os-x-yosemites-icons-3597494/"&gt;definitely want to switch your Emacs logo to the Spacemacs one&lt;/a&gt;!&lt;/p&gt;</summary><category term="osx"></category><category term="gui"></category><category term="emacs"></category><category term="daemon"></category><category term="emacsclient"></category><category term="spacemacs"></category><category term="automator"></category></entry><entry><title>How computers handle text: a gentle but thorough introduction to Unicode</title><link href="http://dlukes.github.io/unicode.html" rel="alternate"></link><published>2016-01-27T00:00:00+01:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2016-01-27:unicode.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Or, &lt;a href="http://www.joelonsoftware.com/articles/Unicode.html"&gt;the absolute minimum every &lt;del&gt;software developer&lt;/del&gt; linguist absolutely, positively must know about Unicode and character sets (no excuses!)&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This text was written as part of a larger programming tutorial in Python, and the code samples are taken from an interactive session using the &lt;a href="http://jupyter.org/"&gt;Jupyter notebook&lt;/a&gt;. As a consequence, there are digressions here and there about playing with text data in Python. These might seem:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;useless if what you came for is just the part about text encoding;&lt;/li&gt;
&lt;li&gt;long-winded if you already know some Python;&lt;/li&gt;
&lt;li&gt;or confusing if, on the contrary, you're not familiar with programming at all, much less with Python.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If any of these is your case, my advice is: ignore the code, focus on the comments around it, they're more than enough to follow the thread of the explanation. Though if you've got a little more time, why not &lt;a href="https://repl.it/languages/python3"&gt;try some of these out in an interactive Python session&lt;/a&gt;? ;) And now, without further ado...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Much like any other piece of data inside a digital computer, text is represented as a series of binary digits (bits), i.e. 0's and 1's. A mapping between sequences of bits and characters is called an encoding. How many different characters your encoding can handle depends on how many bits you allow per character:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;with 1 bit you can have 2^1 = 2 characters (one is represented by 0, the other by 1)&lt;/li&gt;
&lt;li&gt;with 2 bits you can have 2^2 = 4 characters(represented by 00, 01, 10 and 11)&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The oldest encoding still in widespread use (it's what makes the Internet and the web tick) is &lt;a href="https://en.wikipedia.org/wiki/ASCII"&gt;&lt;code&gt;ASCII&lt;/code&gt;&lt;/a&gt;, which is a 7-bit encoding:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[1]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;128&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This means it can represent &lt;a href="http://www.ascii-code.com/"&gt;128 different characters&lt;/a&gt;, which comfortably fits the basic Latin alphabet (both lowercase and uppercase), Arabic numerals, punctuation and some "control characters" which were primarily useful on the old &lt;a href="https://en.wikipedia.org/wiki/Teleprinter"&gt;teletype terminals&lt;/a&gt; for which &lt;code&gt;ASCII&lt;/code&gt; was designed. For instance, the letter "A" corresponds to the number 65 (&lt;code&gt;1000001&lt;/code&gt; in binary, see below).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;"ASCII" stands for "&lt;strong&gt;American&lt;/strong&gt; Standard Code for Information Interchange" -- which explains why there are no accented characters, for instance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nowadays, &lt;code&gt;ASCII&lt;/code&gt; is represented using 8 bits (== 1 byte), because that's the unit of computer memory which has become ubiquitous (in terms of both hardware and software assumptions), but still uses only 7 bits' worth of information.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[2]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;256&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[3]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# how to find out the binary representation of a decimal number?&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{:b}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;65&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[3]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;1000001&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[4]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Digression/explanation: the format() method&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# the format() string method inserts its arguments into the string&lt;/span&gt;
&lt;span class="c1"&gt;# wherever there is a &amp;quot;{}&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;bar&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;baz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[4]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;foo bar baz&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[5]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# you can also specify a different order by using (zero-based) &lt;/span&gt;
&lt;span class="c1"&gt;# positional indices -- or even repeating them&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{1}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{0}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{1}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;bar&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[5]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;bar foo bar&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[6]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# for long strings with many insertions, where you might mess up the&lt;/span&gt;
&lt;span class="c1"&gt;# order of arguments, keyword arguments are also available&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{foo_arg}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{bar_arg}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bar_arg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;bar&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;foo_arg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[6]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;foo bar&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[7]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# and you can also request various formatting adjustments or conversions&lt;/span&gt;
&lt;span class="c1"&gt;# to be made by specifying them after a &amp;quot;:&amp;quot; -- e.g. &amp;quot;b&amp;quot; prints a given&lt;/span&gt;
&lt;span class="c1"&gt;# number in its binary representation&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{:b}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[7]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;101101&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[8]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# or simply&lt;/span&gt;
&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# but that has an ugly &amp;quot;0b&amp;quot; in front, and we would&amp;#39;ve missed out on&lt;/span&gt;
&lt;span class="c1"&gt;# format() if we&amp;#39;d used that directly!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[8]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;0b101101&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;What happens in the range [128; 256) is not covered by the &lt;code&gt;ASCII&lt;/code&gt; standard. In the 1990s, many encodings were standardized which used this range for their own purposes, usually representing additional accented characters used in a particular region. E.g. Czech (and Slovak, Polish...) alphabets can be represented using the ISO &lt;code&gt;latin-2&lt;/code&gt; encoding, or Microsoft's &lt;code&gt;cp-1250&lt;/code&gt;. Encodings which stick with the same character mappings as &lt;code&gt;ASCII&lt;/code&gt; in the range [0; 128) &lt;strong&gt;and represent them physically in the same way (as 1 byte)&lt;/strong&gt;, while potentially adding more character mappings beyond that, are called &lt;strong&gt;&lt;code&gt;ASCII&lt;/code&gt;-compatible&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ASCII&lt;/code&gt; compatibility is a good thing&amp;trade;, because when you start reading a character stream in a computer, there's &lt;strong&gt;no way to know in advance what encoding it is in&lt;/strong&gt; (unless it's a file you've encoded yourself). So in practice, a heuristic has been established to start reading the stream assuming it is &lt;code&gt;ASCII&lt;/code&gt; by default, and switch to a different encoding if evidence becomes available that motivates it. For instance, HTML files should all start something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
  ...
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This way, whenever a program wants to read a file like this, it can start off with &lt;code&gt;ASCII&lt;/code&gt;, waiting to see if it reaches the &lt;code&gt;charset&lt;/code&gt; (i.e. encoding) attribute, and once it does, it can switch from &lt;code&gt;ASCII&lt;/code&gt; to that encoding (&lt;code&gt;UTF-8&lt;/code&gt; here) and restart reading the file, now fairly sure that it's using the correct encoding. This trick works only if we can assume that whatever encoding the rest of the file is in, the first few lines can be considered as &lt;code&gt;ASCII&lt;/code&gt; for all practical intents and purposes.&lt;/p&gt;
&lt;p&gt;Without the &lt;code&gt;charset&lt;/code&gt; attribute, the only way to know if the encoding is right would be for you to look at the rendered text and see if it makes sense; if it did not, you'd have to resort to trial and error, manually switching the encodings and looking for the one in which the numbers behind the characters stop coming out as gibberish and are actually translated into intelligible text.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[9]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Let&amp;#39;s take a look at printable characters in the latin-2 character&lt;/span&gt;
&lt;span class="c1"&gt;# set. Each mapping is called a &amp;quot;codepoint&amp;quot;: it is a correspondence&lt;/span&gt;
&lt;span class="c1"&gt;# between an integer and a character.&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;codecs&lt;/span&gt;

&lt;span class="n"&gt;latin2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;codepoint&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;byte&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;codepoint&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;character&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;codecs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;latin2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;character&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isprintable&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;latin2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;codepoint&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;character&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;latin2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[9]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[(32, &amp;apos; &amp;apos;),
 (33, &amp;apos;!&amp;apos;),
 (34, &amp;apos;&amp;quot;&amp;apos;),
 (35, &amp;apos;#&amp;apos;),
 (36, &amp;apos;$&amp;apos;),
 (37, &amp;apos;%&amp;apos;),
 (38, &amp;apos;&amp;amp;&amp;apos;),
 (39, &amp;quot;&amp;apos;&amp;quot;),
 (40, &amp;apos;(&amp;apos;),
 (41, &amp;apos;)&amp;apos;),
 (42, &amp;apos;*&amp;apos;),
 (43, &amp;apos;+&amp;apos;),
 (44, &amp;apos;,&amp;apos;),
 (45, &amp;apos;-&amp;apos;),
 (46, &amp;apos;.&amp;apos;),
 (47, &amp;apos;/&amp;apos;),
 (48, &amp;apos;0&amp;apos;),
 (49, &amp;apos;1&amp;apos;),
 (50, &amp;apos;2&amp;apos;),
 (51, &amp;apos;3&amp;apos;),
 (52, &amp;apos;4&amp;apos;),
 (53, &amp;apos;5&amp;apos;),
 (54, &amp;apos;6&amp;apos;),
 (55, &amp;apos;7&amp;apos;),
 (56, &amp;apos;8&amp;apos;),
 (57, &amp;apos;9&amp;apos;),
 (58, &amp;apos;:&amp;apos;),
 (59, &amp;apos;;&amp;apos;),
 (60, &amp;apos;&amp;lt;&amp;apos;),
 (61, &amp;apos;=&amp;apos;),
 (62, &amp;apos;&amp;gt;&amp;apos;),
 (63, &amp;apos;?&amp;apos;),
 (64, &amp;apos;@&amp;apos;),
 (65, &amp;apos;A&amp;apos;),
 (66, &amp;apos;B&amp;apos;),
 (67, &amp;apos;C&amp;apos;),
 (68, &amp;apos;D&amp;apos;),
 (69, &amp;apos;E&amp;apos;),
 (70, &amp;apos;F&amp;apos;),
 (71, &amp;apos;G&amp;apos;),
 (72, &amp;apos;H&amp;apos;),
 (73, &amp;apos;I&amp;apos;),
 (74, &amp;apos;J&amp;apos;),
 (75, &amp;apos;K&amp;apos;),
 (76, &amp;apos;L&amp;apos;),
 (77, &amp;apos;M&amp;apos;),
 (78, &amp;apos;N&amp;apos;),
 (79, &amp;apos;O&amp;apos;),
 (80, &amp;apos;P&amp;apos;),
 (81, &amp;apos;Q&amp;apos;),
 (82, &amp;apos;R&amp;apos;),
 (83, &amp;apos;S&amp;apos;),
 (84, &amp;apos;T&amp;apos;),
 (85, &amp;apos;U&amp;apos;),
 (86, &amp;apos;V&amp;apos;),
 (87, &amp;apos;W&amp;apos;),
 (88, &amp;apos;X&amp;apos;),
 (89, &amp;apos;Y&amp;apos;),
 (90, &amp;apos;Z&amp;apos;),
 (91, &amp;apos;[&amp;apos;),
 (92, &amp;apos;\\&amp;apos;),
 (93, &amp;apos;]&amp;apos;),
 (94, &amp;apos;^&amp;apos;),
 (95, &amp;apos;_&amp;apos;),
 (96, &amp;apos;&amp;#96;&amp;apos;),
 (97, &amp;apos;a&amp;apos;),
 (98, &amp;apos;b&amp;apos;),
 (99, &amp;apos;c&amp;apos;),
 (100, &amp;apos;d&amp;apos;),
 (101, &amp;apos;e&amp;apos;),
 (102, &amp;apos;f&amp;apos;),
 (103, &amp;apos;g&amp;apos;),
 (104, &amp;apos;h&amp;apos;),
 (105, &amp;apos;i&amp;apos;),
 (106, &amp;apos;j&amp;apos;),
 (107, &amp;apos;k&amp;apos;),
 (108, &amp;apos;l&amp;apos;),
 (109, &amp;apos;m&amp;apos;),
 (110, &amp;apos;n&amp;apos;),
 (111, &amp;apos;o&amp;apos;),
 (112, &amp;apos;p&amp;apos;),
 (113, &amp;apos;q&amp;apos;),
 (114, &amp;apos;r&amp;apos;),
 (115, &amp;apos;s&amp;apos;),
 (116, &amp;apos;t&amp;apos;),
 (117, &amp;apos;u&amp;apos;),
 (118, &amp;apos;v&amp;apos;),
 (119, &amp;apos;w&amp;apos;),
 (120, &amp;apos;x&amp;apos;),
 (121, &amp;apos;y&amp;apos;),
 (122, &amp;apos;z&amp;apos;),
 (123, &amp;apos;{&amp;apos;),
 (124, &amp;apos;|&amp;apos;),
 (125, &amp;apos;}&amp;apos;),
 (126, &amp;apos;~&amp;apos;),
 (161, &amp;apos;Ą&amp;apos;),
 (162, &amp;apos;˘&amp;apos;),
 (163, &amp;apos;Ł&amp;apos;),
 (164, &amp;apos;¤&amp;apos;),
 (165, &amp;apos;Ľ&amp;apos;),
 (166, &amp;apos;Ś&amp;apos;),
 (167, &amp;apos;§&amp;apos;),
 (168, &amp;apos;¨&amp;apos;),
 (169, &amp;apos;Š&amp;apos;),
 (170, &amp;apos;Ş&amp;apos;),
 (171, &amp;apos;Ť&amp;apos;),
 (172, &amp;apos;Ź&amp;apos;),
 (174, &amp;apos;Ž&amp;apos;),
 (175, &amp;apos;Ż&amp;apos;),
 (176, &amp;apos;°&amp;apos;),
 (177, &amp;apos;ą&amp;apos;),
 (178, &amp;apos;˛&amp;apos;),
 (179, &amp;apos;ł&amp;apos;),
 (180, &amp;apos;´&amp;apos;),
 (181, &amp;apos;ľ&amp;apos;),
 (182, &amp;apos;ś&amp;apos;),
 (183, &amp;apos;ˇ&amp;apos;),
 (184, &amp;apos;¸&amp;apos;),
 (185, &amp;apos;š&amp;apos;),
 (186, &amp;apos;ş&amp;apos;),
 (187, &amp;apos;ť&amp;apos;),
 (188, &amp;apos;ź&amp;apos;),
 (189, &amp;apos;˝&amp;apos;),
 (190, &amp;apos;ž&amp;apos;),
 (191, &amp;apos;ż&amp;apos;),
 (192, &amp;apos;Ŕ&amp;apos;),
 (193, &amp;apos;Á&amp;apos;),
 (194, &amp;apos;Â&amp;apos;),
 (195, &amp;apos;Ă&amp;apos;),
 (196, &amp;apos;Ä&amp;apos;),
 (197, &amp;apos;Ĺ&amp;apos;),
 (198, &amp;apos;Ć&amp;apos;),
 (199, &amp;apos;Ç&amp;apos;),
 (200, &amp;apos;Č&amp;apos;),
 (201, &amp;apos;É&amp;apos;),
 (202, &amp;apos;Ę&amp;apos;),
 (203, &amp;apos;Ë&amp;apos;),
 (204, &amp;apos;Ě&amp;apos;),
 (205, &amp;apos;Í&amp;apos;),
 (206, &amp;apos;Î&amp;apos;),
 (207, &amp;apos;Ď&amp;apos;),
 (208, &amp;apos;Đ&amp;apos;),
 (209, &amp;apos;Ń&amp;apos;),
 (210, &amp;apos;Ň&amp;apos;),
 (211, &amp;apos;Ó&amp;apos;),
 (212, &amp;apos;Ô&amp;apos;),
 (213, &amp;apos;Ő&amp;apos;),
 (214, &amp;apos;Ö&amp;apos;),
 (215, &amp;apos;×&amp;apos;),
 (216, &amp;apos;Ř&amp;apos;),
 (217, &amp;apos;Ů&amp;apos;),
 (218, &amp;apos;Ú&amp;apos;),
 (219, &amp;apos;Ű&amp;apos;),
 (220, &amp;apos;Ü&amp;apos;),
 (221, &amp;apos;Ý&amp;apos;),
 (222, &amp;apos;Ţ&amp;apos;),
 (223, &amp;apos;ß&amp;apos;),
 (224, &amp;apos;ŕ&amp;apos;),
 (225, &amp;apos;á&amp;apos;),
 (226, &amp;apos;â&amp;apos;),
 (227, &amp;apos;ă&amp;apos;),
 (228, &amp;apos;ä&amp;apos;),
 (229, &amp;apos;ĺ&amp;apos;),
 (230, &amp;apos;ć&amp;apos;),
 (231, &amp;apos;ç&amp;apos;),
 (232, &amp;apos;č&amp;apos;),
 (233, &amp;apos;é&amp;apos;),
 (234, &amp;apos;ę&amp;apos;),
 (235, &amp;apos;ë&amp;apos;),
 (236, &amp;apos;ě&amp;apos;),
 (237, &amp;apos;í&amp;apos;),
 (238, &amp;apos;î&amp;apos;),
 (239, &amp;apos;ď&amp;apos;),
 (240, &amp;apos;đ&amp;apos;),
 (241, &amp;apos;ń&amp;apos;),
 (242, &amp;apos;ň&amp;apos;),
 (243, &amp;apos;ó&amp;apos;),
 (244, &amp;apos;ô&amp;apos;),
 (245, &amp;apos;ő&amp;apos;),
 (246, &amp;apos;ö&amp;apos;),
 (247, &amp;apos;÷&amp;apos;),
 (248, &amp;apos;ř&amp;apos;),
 (249, &amp;apos;ů&amp;apos;),
 (250, &amp;apos;ú&amp;apos;),
 (251, &amp;apos;ű&amp;apos;),
 (252, &amp;apos;ü&amp;apos;),
 (253, &amp;apos;ý&amp;apos;),
 (254, &amp;apos;ţ&amp;apos;),
 (255, &amp;apos;˙&amp;apos;)]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Using the 8th bit (and thus the codepoint range [128; 256)) solves the problem of handling languages with character sets different than that of American English, but introduces a lot of complexity -- whenever you come across a text file with an unknown encoding, it might be in one of literally dozens of encodings. Additional drawbacks include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how to handle multilingual text with characters from many different alphabets, which are not part of the same 8-bit encoding?&lt;/li&gt;
&lt;li&gt;how to handle writing systems which have way more than 256 "characters", e.g. Chinese, Japanese and Korean (CJK) ideograms?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For these purposes, a standard encoding known as &lt;a href="https://en.wikipedia.org/wiki/Unicode"&gt;&lt;strong&gt;Unicode&lt;/strong&gt;&lt;/a&gt; was developed which strives for universal coverage of all possible character sets. Unicode is much bigger than the encodings we've seen so far -- its most frequently used subset, the &lt;a href="https://en.wikipedia.org/wiki/Plane_%28Unicode%29#Basic_Multilingual_Plane"&gt;Basic Multilingual Plane&lt;/a&gt;, has 2^16 codepoints, but overall the number of codepoints is past 1M and there's room to accommodate many more.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[10]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[10]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;65536&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now, the most straightforward representation for 2^16 codepoints is what? Well, it's simply using 16 bits per character, i.e. 2 bytes. That encoding exists, it's called &lt;code&gt;UTF-16&lt;/code&gt;, but consider the drawbacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we've lost &lt;code&gt;ASCII&lt;/code&gt; compatibility by the simple fact of using 2 bytes per character instead of 1 (encoding "a" as &lt;code&gt;01100001&lt;/code&gt; or &lt;code&gt;01100001|00000000&lt;/code&gt;, with the &lt;code&gt;|&lt;/code&gt; indicating an imaginary boundary between bytes, is not the same thing)&lt;/li&gt;
&lt;li&gt;encoding a string in a character set which uses a "reasonable" number of characters (like any European language) now takes twice as much space without any added benefit (which is probably not a good idea, given the general dominance of English -- one of those "reasonable character set size" languages -- in electronic communication)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looks like we'll have to think outside the box. The box in question here is called &lt;strong&gt;fixed-width encodings&lt;/strong&gt; -- all of the encoding schemes we've encountered so far were fixed-width, meaning that each character was represented by either 7, 8 or 16 bits. In other word, you could jump around the string in multiples of 7, 8 or 16 and always land at the beginning of a character. (Not exactly true for &lt;code&gt;UTF-16&lt;/code&gt;, because it is something more than just a "16-bit &lt;code&gt;ASCII&lt;/code&gt;": it has ways of handling characters beyond 2^16 using so-called &lt;a href="https://en.wikipedia.org/wiki/UTF-16#U.2B10000_to_U.2B10FFFF"&gt;surrogate sequences&lt;/a&gt; -- but you get the gist.)&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;"UTF" stands for "Unicode Transformation Format".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The smart idea that some bright people have come up with was to use a &lt;strong&gt;variable-width encoding&lt;/strong&gt;. The most ubiquitous one currently is &lt;strong&gt;&lt;code&gt;UTF-8&lt;/code&gt;&lt;/strong&gt;, which we've already met in the HTML example above. &lt;code&gt;UTF-8&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; &lt;code&gt;ASCII&lt;/code&gt;-compatible, i.e. the 1's and 0's used to encode text containing only &lt;code&gt;ASCII&lt;/code&gt; characters are the same regardless of whether you use &lt;code&gt;ASCII&lt;/code&gt; or &lt;code&gt;UTF-8&lt;/code&gt;: it's a sequence of 8-bit bytes. But &lt;code&gt;UTF-8&lt;/code&gt; can also handle many more additional characters, as defined by the Unicode standard, by using progressively longer and longer sequences of bits.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[11]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Prints binary representation of string as encoded by UTF-8.&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;binary_bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="c1"&gt;# encode the string as UTF-8 and iterate over the bytes&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;byte&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# generate a string of general format &amp;quot;0b101...&amp;quot;, which&lt;/span&gt;
        &lt;span class="c1"&gt;# is the binary representation of the byte&lt;/span&gt;
        &lt;span class="n"&gt;binary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# remove the leading &amp;quot;0b&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;binary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;binary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="c1"&gt;# pad the representation with leading zeros to the size of&lt;/span&gt;
        &lt;span class="c1"&gt;# a full byte (= a sequence of 8 1&amp;#39;s and 0&amp;#39;s) if necessary&lt;/span&gt;
        &lt;span class="n"&gt;binary_byte&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;binary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;binary_bytes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;binary_byte&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;#39; encoded in UTF-8 is: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;binary_bytes&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;A&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# the representations...&lt;/span&gt;
&lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;č&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# ... keep...&lt;/span&gt;
&lt;span class="n"&gt;print_as_binary_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;字&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# ... getting longer.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;&amp;apos;A&amp;apos; encoded in UTF-8 is: [&amp;apos;01000001&amp;apos;]
&amp;apos;č&amp;apos; encoded in UTF-8 is: [&amp;apos;11000100&amp;apos;, &amp;apos;10001101&amp;apos;]
&amp;apos;字&amp;apos; encoded in UTF-8 is: [&amp;apos;11100101&amp;apos;, &amp;apos;10101101&amp;apos;, &amp;apos;10010111&amp;apos;]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;How does it achieve that? The obvious problem here is that with a fixed-width encoding, you just chop up the string at regular intervals (7, 8, 16 bits) and you know that each interval represents one character. So &lt;strong&gt;how do you know where to chop up a variable width-encoded string, if each character can take up a different number of bits?&lt;/strong&gt; We won't go into the details, but essentially, the trick is to &lt;strong&gt;use some of the bits&lt;/strong&gt; in the representation of a codepoint &lt;strong&gt;to store information&lt;/strong&gt; not about which character it is (whether it's an "A" or a "字"), but &lt;strong&gt;how many bits it occupies&lt;/strong&gt;. In other words, if you want to skip ahead 10 characters in a string encoded with a variable width-encoding, you can't just skip 10 * 7 or 8 or 16 bits; you have to read all the intervening characters to figure out how much space they take up.&lt;/p&gt;
&lt;p&gt;There's much more to Unicode than this simple introduction, for instance the various ways diacritics are handled: "č" can be represented either as a single codepoint (&lt;a href="http://www.fileformat.info/info/unicode/char/010D/index.htm"&gt;&lt;code&gt;LATIN SMALL LETTER C WITH CARON&lt;/code&gt;&lt;/a&gt; -- all Unicode codepoints have cute names like this) or a sequence of two codepoints, the character "c" and a combining diacritic mark (&lt;code&gt;COMBINING CARON&lt;/code&gt;). You can search for the codepoints corresponding to Unicode characters e.g. &lt;a href="http://www.fileformat.info/info/unicode/char/search.htm"&gt;here&lt;/a&gt; and play with them in Python using the &lt;code&gt;chr(0xXXXX)&lt;/code&gt; built-in function or with the special string escape sequence &lt;code&gt;\uXXXX&lt;/code&gt; (where &lt;code&gt;XXXX&lt;/code&gt; is the hexadecimal representation of the codepoint) -- both are ways to get the character corresponding to the given codepoint:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[12]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# &amp;quot;č&amp;quot; as LATIN SMALL LETTER C WITH CARON, codepoint 010D&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x010D&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u010D&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;č
č
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[13]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# &amp;quot;č&amp;quot; as a sequence of LATIN SMALL LETTER C, codepoint 0063, and&lt;/span&gt;
&lt;span class="c1"&gt;# COMBINING CARON, codepoint 030c&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x0063&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;chr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x030c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u0063\u030c&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;č
č
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;&lt;p&gt;Hexadecimal is just a more convenient way of representing sequences of bits, where each of the &lt;code&gt;X&lt;/code&gt;'s can be a number between 0 and 15 (10--15 are represented by the letters A--F). Each hexadecimal number can thus represent 16 different values, and therefore it can stand in for a sequence of 4 bits (2^4 == 16). Without worrying too much about the details right now, our old friend &lt;code&gt;ASCII&lt;/code&gt; uppercase "A" can be thought of equivalently either as decimal 65, binary &lt;code&gt;1000001&lt;/code&gt;, or hexadecimal &lt;code&gt;0x41&lt;/code&gt; (the "0x" prefix is there just to say "this is a hexadecimal number"). &amp;gt;&lt;/p&gt;
&lt;p&gt;Binary and hexadecimal numbers are often written padded with leading zeros to some number of bytes, but these have no effect on the value, much like decimal 42 and 00000042 are effectively the same numbers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[14]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# use hex() to find out the hexadecimal representation of a decimal&lt;/span&gt;
&lt;span class="c1"&gt;# integer...&lt;/span&gt;
&lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;99&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[14]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;apos;0x63&amp;apos;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[15]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... and int() to go back&lt;/span&gt;
&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x63&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[15]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;99&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This means you have to be careful when working with languages that use accents, because &lt;strong&gt;for a computer, the two possible representations are of course different strings&lt;/strong&gt;, even though for you, they're conceptually the same:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[16]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u010D&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;s2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\u0063\u030c&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# s1 and s2 look the same to the naked eye...&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;č č
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[17]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... but in the eternal realm of Plato&amp;#39;s Ideas, they&amp;#39;re not&lt;/span&gt;
&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[17]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;False&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Watch out, &lt;strong&gt;they even have different lengths&lt;/strong&gt;! This might come to bite you if you're trying to compute the length of a word in letters.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[18]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s1 is&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;character(s) long.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s2 is&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;character(s) long.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;s1 is 1 character(s) long.
s2 is 2 character(s) long.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Generally, most text out there will use the first, single-codepoint approach whenever possible, and pre-packaged linguistic corpora will try to be consistent about this (unless they come from the web, which always warrants being suspicious and defensive about your material). If you're worried about inconsistencies in your data, you can perform a &lt;a href="https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization"&gt;normalization&lt;/a&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[19]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;unicodedata&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;

&lt;span class="c1"&gt;# NFC stands for Normal Form C; this normalization applies a canonical&lt;/span&gt;
&lt;span class="c1"&gt;# decomposition (into a multi-codepoint representation) followed by a&lt;/span&gt;
&lt;span class="c1"&gt;# canonical composition (into a single-codepoint representation)&lt;/span&gt;
&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;NFC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;s2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;NFC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[19]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;True&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Let's wrap things up by saying that Python itself uses Unicode internally and (mostly?) assumes &lt;code&gt;UTF-8&lt;/code&gt; when reading files. So if you're using &lt;code&gt;UTF-8&lt;/code&gt; as is increasingly the case (and you should be), you won't have to worry too much about encodings, except perhaps for normalization.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[20]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# a good idea when dealing with Unicode text from an unknown and&lt;/span&gt;
&lt;span class="c1"&gt;# unreliable source is to look at the set of codepoints contained&lt;/span&gt;
&lt;span class="c1"&gt;# in it and eliminate or replace those that shouldn&amp;#39;t be there&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;unicodedata&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;inspect_codepoints&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;charset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;charset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;r&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; (\u&lt;/span&gt;&lt;span class="si"&gt;{:04x}&lt;/span&gt;&lt;span class="s2"&gt;): &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; (category: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;unicodedata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;unicodedata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        

&lt;span class="c1"&gt;# depending on your font configuration, it may be very hard to spot&lt;/span&gt;
&lt;span class="c1"&gt;# the two intruders in the sentence below that look like regular&lt;/span&gt;
&lt;span class="c1"&gt;# letters but really are specialized variants; you might want&lt;/span&gt;
&lt;span class="c1"&gt;# to replace them before doing further text processing...&lt;/span&gt;
&lt;span class="n"&gt;inspect_codepoints&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Intruders here, good 𝗍hinɡ I checked.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;  (\u0020): SPACE (category: Zs)
, (\u002c): COMMA (category: Po)
. (\u002e): FULL STOP (category: Po)
I (\u0049): LATIN CAPITAL LETTER I (category: Lu)
c (\u0063): LATIN SMALL LETTER C (category: Ll)
d (\u0064): LATIN SMALL LETTER D (category: Ll)
e (\u0065): LATIN SMALL LETTER E (category: Ll)
g (\u0067): LATIN SMALL LETTER G (category: Ll)
h (\u0068): LATIN SMALL LETTER H (category: Ll)
i (\u0069): LATIN SMALL LETTER I (category: Ll)
k (\u006b): LATIN SMALL LETTER K (category: Ll)
n (\u006e): LATIN SMALL LETTER N (category: Ll)
o (\u006f): LATIN SMALL LETTER O (category: Ll)
r (\u0072): LATIN SMALL LETTER R (category: Ll)
s (\u0073): LATIN SMALL LETTER S (category: Ll)
t (\u0074): LATIN SMALL LETTER T (category: Ll)
u (\u0075): LATIN SMALL LETTER U (category: Ll)
ɡ (\u0261): LATIN SMALL LETTER SCRIPT G (category: Ll)
𝗍 (\u1d5cd): MATHEMATICAL SANS-SERIF SMALL T (category: Ll)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[21]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ... because of course, for a computer, the word &amp;quot;thing&amp;quot; written with&lt;/span&gt;
&lt;span class="c1"&gt;# two different variants of &amp;quot;g&amp;quot; is really just two different words, which&lt;/span&gt;
&lt;span class="c1"&gt;# is probably not what you want&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;thing&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;thinɡ&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[21]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;False&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In any case, here's what happens when processing text with Python ("Unicode" in the central box stands for Python's internal representation of Unicode, which is &lt;strong&gt;not&lt;/strong&gt; &lt;code&gt;UTF-8&lt;/code&gt; nor &lt;code&gt;UTF-16&lt;/code&gt;):&lt;/p&gt;
&lt;p&gt;&lt;img alt="Text IO in Python" src="http://www.nltk.org/images/unicode.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;p&gt;(Image shamelessly hotlinked from / courtesy of the &lt;a href="http://www.nltk.org/book/"&gt;NLTK Book&lt;/a&gt;. Go check it out, it's an awesome intro to Python programming for linguists!)&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A terminological postscript: we've been using some terms a bit informally and for the most part it's okay, but it's good to get the distinctions straight in one's head at least once. So, a &lt;strong&gt;character set&lt;/strong&gt; is a mapping between &lt;strong&gt;codepoints&lt;/strong&gt; (integers) and &lt;strong&gt;characters&lt;/strong&gt;. We may for instance say that in our character set, the integer 99 corresponds to the character "c".&lt;/p&gt;
&lt;p&gt;On the other hand, an &lt;strong&gt;encoding&lt;/strong&gt; is a mapping between a &lt;strong&gt;codepoint&lt;/strong&gt; (an integer) and a &lt;strong&gt;physical sequence of 1's and 0's that represent it in memory&lt;/strong&gt;. With fixed-width encodings, this mapping is generally straightforward -- the 1's and 0's directly represent the given integer, only in binary and padded with zeros to fit the desired width. With variable-width encodings, as the necessity creeps in to include the information about how many bits are spanned by the current character, this straightforward correspondence breaks down.&lt;/p&gt;
&lt;p&gt;A comparison might be helpful here: as encodings, &lt;code&gt;UTF-8&lt;/code&gt; and &lt;code&gt;UTF-16&lt;/code&gt; both use &lt;strong&gt;the same character set&lt;/strong&gt; -- the same integers corresponding to the same characters. But since they're &lt;strong&gt;different encodings&lt;/strong&gt;, when the time comes to turn these integers into sequences of bits to store in a computer's memory, each of them generates a different one.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For more on Unicode, a great read already hinted at above is Joel Spolsky's &lt;a href="http://www.joelonsoftware.com/articles/Unicode.html"&gt;The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)&lt;/a&gt;. To make the discussion digestible for newcomers, I sometimes slightly distorted facts about how things are "really really" done. And some inaccuracies may be genuine mistakes. In any case, please let me know in the comments! I'm grateful for feedback and looking to improve this material; I'll fix the mistakes and consider ditching some of the simplifications if they prove untenable :)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="unicode"></category><category term="encoding"></category><category term="charset"></category><category term="programming"></category><category term="linguistics"></category><category term="python"></category></entry><entry><title>Úprava rozhraní konkordanceru KonText -- vylepšená verze</title><link href="http://dlukes.github.io/kontext-interface-tweak-update.html" rel="alternate"></link><published>2015-05-14T00:00:00+02:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2015-05-14:kontext-interface-tweak-update.html</id><summary type="html">&lt;p&gt;Před nějakou dobou jsem zde vyvěsil
&lt;a href="http://dlukes.github.io/kontext-interface-tweak.html"&gt;skript&lt;/a&gt;, jehož pomocí lze lehce
"přeskládat" a upravit rozhraní korpusového konkordanceru
&lt;a href="https://kontext.korpus.cz"&gt;KonText&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;menu je umístěné po straně místo nahoře a permanentně rozbalené&lt;/li&gt;
&lt;li&gt;nad vyhledanou konkordancí je umístěn rychlý hledací box, v němž lze
  předchozí dotaz pohodlně upravit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Víc o motivaci těchto úprav se dočtete
&lt;a href="kontext-interface-tweak.html#background"&gt;v původním článku&lt;/a&gt;. Stále
platí, že ČNK nemá v plánu tyto změny začlenit přímo do oficiální verze
KonTextu, zejména proto, že rychlý hledací box sice v jistých situacích může
být užitečný, nicméně oproti standardnímu formuláři &lt;em&gt;Nový dotaz&lt;/em&gt; výrazně
omezuje možnosti pro zadání dotazu.&lt;/p&gt;
&lt;p&gt;Vylepšená verze, která je k dispozici níže, odstraňuje některé předchozí
nedostatky skriptu: rychlý hledací box nad konkordancí je větší, ukazuje &lt;strong&gt;vždy
CQL podobu posledního zadaného dotazu&lt;/strong&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, a především zůstává zobrazený i
během listování konkordancí (tj. není k dispozici jen na její první
stránce). Dotaz lze nyní navíc pro větší přehlednost rozdělit do více řádků,
takže opětovné vyhledávání se nově spouští stiskem kombinace kláves
&lt;strong&gt;Ctrl+Enter&lt;/strong&gt; (místo jen Enteru).&lt;/p&gt;
&lt;p&gt;Výsledné upravené rozhraní KonText vypadá stále podobně:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Upravené rozhraní KonText." src="images/kontext_interface_tweak_update.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;h1&gt;Postup instalace skriptu&lt;/h1&gt;
&lt;p&gt;Nová verze skriptu je k dispozici zde:&lt;/p&gt;
&lt;script src="https://gist.github.com/dlukes/a99dca231db63c9d5bb7.js"&gt;&lt;/script&gt;

&lt;p&gt;Kroky k jeho zprovoznění zůstávají stejné:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Nainstalovat si do svého prohlížeče plugin
    &lt;a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en"&gt;Tampermonkey&lt;/a&gt;,
    pokud používáte Chrome, nebo
    &lt;a href="https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/"&gt;Greasemonkey&lt;/a&gt;,
    pokud používáte Firefox. (Pokud používáte Internet Explorer, budete muset
    dočasně přesedlat na Chrome nebo Firefox.) Testovaný je skript zatím jen na
    Chromu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Založit v daném pluginu nový skript (pro Chrome je tutorial
    &lt;a href="http://hibbard.eu/tampermonkey-tutorial/"&gt;zde&lt;/a&gt;, pro Firefox
    &lt;a href="http://hayageek.com/greasemonkey-tutorial/"&gt;zde&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Smazat kostru nového skriptu a nahradit ji skriptem, který si zkopírujete výše.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skript uložit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Používat KonText jako normálně -- skript už by podle adresy měl sám poznat,
    že se má spustit. Pokud se tak nestane, nejspíš to znamená, že je
    prohlížečový plugin (Tampermonkey nebo Greasemonkey) deaktivovaný a je
    potřeba jej znovu aktivovat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;V předchozí verzi se po aplikaci libovolného filtru změnil obsah
hledacího boxu na parametry filtrování.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="KonText"></category><category term="korpus"></category><category term="konkordance"></category><category term="NoSke"></category><category term="Bonito"></category></entry><entry><title>Úprava rozhraní konkordanceru KonText</title><link href="http://dlukes.github.io/kontext-interface-tweak.html" rel="alternate"></link><published>2015-02-17T00:00:00+01:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2015-02-17:kontext-interface-tweak.html</id><summary type="html">&lt;h1&gt;!POZOR!&lt;/h1&gt;
&lt;p&gt;K dispozici je nyní
&lt;a href="http://dlukes.github.io/kontext-interface-tweak-update.html"&gt;vylepšená verze níže popsaného skriptu&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Hledání v korpusech ČNK&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://korpus.cz"&gt;Český národní korpus&lt;/a&gt; je sbírka jazykových korpusů částečně
vytvářených &lt;a href="http://ucnk.ff.cuni.cz"&gt;Ústavem Českého národního korpusu&lt;/a&gt; a
částečně jinými institucemi. Všechny jsou hostované na jednom serveru a
dostupné skrz různá vyhledávací rozhraní
(tzv. &lt;a href="http://wiki.korpus.cz/doku.php/pojmy:korpusovy_manazer"&gt;konkordancery&lt;/a&gt;),
např. &lt;a href="https://www.korpus.cz/corpora"&gt;NoSke&lt;/a&gt;,
&lt;a href="http://ucnk.ff.cuni.cz/bonito/index.php"&gt;Bonito&lt;/a&gt; či nejnověji
&lt;a href="https://kontext.korpus.cz"&gt;KonText&lt;/a&gt;. Koncem března 2015 ovšem bude podpora
starších rozhraní ukončena a nadále půjde k datům v ČNK přistupovat primárně
pouze přes KonText.&lt;/p&gt;
&lt;p&gt;(Pokud vám odstavec výše nedává příliš smysl, s jazykovými korpusy se setkáváte
poprvé, ale chcete se dozvědět víc, raději si místo tohoto postu přečtěte,
&lt;a href="http://wiki.korpus.cz/doku.php/pojmy:korpus"&gt;k čemu je takový korpus dobrý&lt;/a&gt;, a
&lt;a href="https://kontext.korpus.cz"&gt;zkuste si v něm něco pro zajímavost vyhledat&lt;/a&gt;. Pokud
se vám při vzpomínce na Bonito či NoSke naopak zaskvěla slza v oku, čtěte dál!)&lt;/p&gt;
&lt;h1&gt;&lt;a id="background"&gt;&lt;/a&gt;KonText vs. Bonito / NoSke&lt;/h1&gt;
&lt;p&gt;KonText má oproti starším rozhraním řadu výhod -- bohatší funkcionalitu, mnohé
pomůcky, které vám pomohou se zadáním složitějších dotazů (sestavení
morfologického tagu či podmínky &lt;code&gt;within&lt;/code&gt;), a v neposlední řadě mnohem lépe
vypadá, což kupříkladu mně při práci působí jako balzám na duši. Nicméně
dlouholetí uživatelé ČNK byli jednoduše zvyklí na některé aspekty Bonita a
NoSke, které jim teď v KonTextu chybí.&lt;/p&gt;
&lt;p&gt;Onehdy při rozhovoru s jedním z nich vyplavaly na povrch jako hodně důležité
dvě stížnosti:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Vrchní menu v KonTextu je zákeřné, schovává se, člověk nemá přehled nad
   dostupnými funkcemi. Oproti tomu NoSke má menu po straně a je permanentně
   rozvinuté, takže uživatel má všechny možnosti interakce s konkordancí
   soustavně jako na dlani.&lt;/li&gt;
&lt;li&gt;Po zadání dotazu člověk často na základě konkordance zjistí, že jej
   potřebuje ještě trochu upravit / zjemnit. KonText si sice předchozí dotazy
   pamatuje, je ale potřeba se k nim doklikat; šikovnější by bylo, kdyby tato
   možnost byla dostupná přímo ze stránky konkordance v podobě nějakého
   zjednodušeného hledacího boxu. (NoSke tohle vlastně taky neumí, v Bonitu je
   to jednodušší.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;V obou případech jde o smysluplné požadavky, jenže KonText je poměrně velká a
složitá aplikace, takže i pokud se ČNK rozhodne do ní tyto podněty v nějaké
podobě zapracovat (např. jako možnost přepnutí zobrazení menu), bude nějakou
chvíli trvat, než se implementace navrhne, vytvoří, řádně otestuje a konečně
dostane k uživatelům. Nicméně aby bylo možné alespoň vyzkoušet, jak by zmíněné
změny vypadaly v praxi, dal jsem dohromady krátký skript, který již v
prohlížeči nahraný KonText trochu "přestaví" a upraví. Výsledek vypadá
následovně:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Upravené rozhraní KonText." src="images/kontext_interface_tweak.png" style="max-width: 100%;"&gt;&lt;/p&gt;
&lt;p&gt;Rovnou předesílám: ten skript je nevzhledný bastl přilepený na KonText
zvnějšku; proto taky bylo možné jej dát dohromady poměrně rychle, protože si
neklade nárok na spolehlivost, která se vyžaduje od oficiální verze
KonTextu. Je to spíš prototyp, jehož účelem je otestovat výše popsané změny v
praxi a získat představu o tom, zda a do jaké míry jsou přínosné. (Vlastní
zkušenost: po chvíli používání mi přijde přídatný hledací box nad konkordancí
hodně šikovný a užitečný.)&lt;/p&gt;
&lt;p&gt;Teď k jádru pudla: &lt;strong&gt;pokud máte zájem, můžete si KonText takto k obrazu svému&lt;/strong&gt;
(resp. k obrázku o odstavec výš) &lt;strong&gt;upravit také&lt;/strong&gt; a vyzkoušet, jak vám takové
nastavení vyhovuje. Když se vám jedna z úprav bude líbit (nebo vás u toho
napadne jiná, kterou by si KonText zasloužil), můžete pak zadat
&lt;a href="https://podpora.korpus.cz/projects/kontext/issues/new"&gt;požadavek na nový feature&lt;/a&gt;.
Návod, jak si KonText upravit, následuje níže.&lt;/p&gt;
&lt;h1&gt;Postup instalace skriptu&lt;/h1&gt;
&lt;p&gt;Skript samotný je k dispozici zde:&lt;/p&gt;
&lt;script src="https://gist.github.com/dlukes/0764590b7a8464cbd000.js"&gt;&lt;/script&gt;

&lt;p&gt;K jeho zprovoznění jsou potřeba následující kroky:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Nainstalovat si do svého prohlížeče plugin
    &lt;a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en"&gt;Tampermonkey&lt;/a&gt;,
    pokud používáte Chrome, nebo
    &lt;a href="https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/"&gt;Greasemonkey&lt;/a&gt;,
    pokud používáte Firefox. (Pokud používáte Internet Explorer, budete muset
    dočasně přesedlat na Chrome nebo Firefox.) Testovaný je skript zatím jen na
    Chromu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Založit v daném pluginu nový skript (pro Chrome je tutorial
    &lt;a href="http://hibbard.eu/tampermonkey-tutorial/"&gt;zde&lt;/a&gt;, pro Firefox
    &lt;a href="http://hayageek.com/greasemonkey-tutorial/"&gt;zde&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Smazat kostru nového skriptu a nahradit ji skriptem, který si zkopírujete výše.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skript uložit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Používat KonText jako normálně -- skript už by podle adresy měl sám poznat,
    že se má spustit. Pokud se tak nestane, nejspíš to znamená, že je
    prohlížečový plugin (Tampermonkey nebo Greasemonkey) deaktivovaný a je
    potřeba jej znovu aktivovat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Omezení&lt;/h1&gt;
&lt;p&gt;Skript má pravděpodobně hromadu drobných much, na které se mi zatím nepodařilo
přijít -- budu se je snažit průběžně opravovat, když na ně padnu, nebo
&lt;a href="pages/about.html"&gt;když mi o nich dáte vědět&lt;/a&gt;. Krom toho má i některé mouchy, o
nichž už vím, ale bohužel toho s nimi nejde moc dělat.&lt;/p&gt;
&lt;p&gt;Asi nejnápadnější je, že přidaný hledací box funguje jen na těch stránkách, kde
je původní dotaz i součástí adresy URL (což nejsou všechny -- třeba když
začnete &lt;strong&gt;listovat konkordancí&lt;/strong&gt; na druhou stránku a dál, &lt;strong&gt;dotaz je z adresy
vyjmut&lt;/strong&gt; a &lt;strong&gt;pomocný hledací box tedy zmizí&lt;/strong&gt;). Ale vzhledem k tomu, že jeho
hlavní účel má být možnost lehce upravit dotaz po prvním rychlém nahlédnutí do
konkordance, snad to nebude takový problém. Pokud někdy bude podobný box řádně
přidán přímo do KonTextu, takovými nedostatky samozřejmě trpět nebude.&lt;/p&gt;
&lt;p&gt;A ještě k &lt;strong&gt;používání přidaného hledacího boxu&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Typ dotazu, který je do něj potřeba zadat, je stejný jako ten, který jste
   při prvotním vyhledání konkordance zadali na stránce
   &lt;a href="https://kontext.korpus.cz/first_form"&gt;Nový dotaz&lt;/a&gt;. Pokud tento prvotní
   dotaz byl &lt;em&gt;Základní&lt;/em&gt; dotaz, můžete pomocí rychlého boxu zadat jiný
   &lt;em&gt;Základní&lt;/em&gt; dotaz; pokud to byl &lt;em&gt;CQL&lt;/em&gt; dotaz, můžete ho upravit zas jen na
   další &lt;em&gt;CQL&lt;/em&gt; dotaz. Důvodem je, že &lt;strong&gt;smyslem&lt;/strong&gt; tohoto pomocného boxu &lt;strong&gt;není
   nahradit plnohodnotný formulář&lt;/strong&gt; pro zadání dotazu, jen poskytnout rychlou
   možnost, jak již &lt;strong&gt;zadaný dotaz upravit&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Pomocný hledací box se objeví i poté, co na konkordanci provedete
   filtrování. V takové situaci se dá použít k tomu, abyste &lt;strong&gt;pozměnili zadání
   aktuálního filtru&lt;/strong&gt;, tj. filtrování se provede znovu na původní konkordanci,
   ne na této již filtrované. Pokud chcete opakovaně filtrovat tu samou
   konkordanci a postupně podle daných kritérií vyřazovat / přidávat řádky, je
   potřeba místo hledacího boxu opakovaně použít menu &lt;em&gt;Filtr&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Komu si stěžovat, když to nebude fungovat&lt;/h1&gt;
&lt;p&gt;Skript je volně šiřitelný pod licencí
&lt;a href="http://www.gnu.org/copyleft/gpl.html"&gt;GNU GPL v3&lt;/a&gt;, takže se na něj neváže
žádná záruka. Když se vám ale nebude dařit jej zprovoznit, rád se pokusím
pomoct! Stačí se ozvat na adresu uvedenou &lt;a href="pages/about.html"&gt;zde&lt;/a&gt;.&lt;/p&gt;</summary><category term="KonText"></category><category term="korpus"></category><category term="konkordance"></category><category term="NoSke"></category><category term="Bonito"></category></entry><entry><title>Beyond semantic versioning? (cross-post)</title><link href="http://dlukes.github.io/beyond-semver.html" rel="alternate"></link><published>2014-12-14T00:00:00+01:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2014-12-14:beyond-semver.html</id><summary type="html">&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;Ever since I first read about &lt;a href="http://semver.org/"&gt;semantic versioning&lt;/a&gt;, I've
thought of it as a neat idea. But only recently did it occur to me that what
I liked about the idea was its goal, much less its execution (more on that
below). What made it obvious was &lt;a href="https://github.com/jashkenas/underscore/issues/1805"&gt;this lengthy
discussion&lt;/a&gt; about breaking
changes introduced in v1.7 of &lt;a href="http://underscorejs.org/"&gt;underscore.js&lt;/a&gt; without
an accompanying major version bump.&lt;/p&gt;
&lt;p&gt;Even though I still think sticking to semver is the right thing to do if your
community of users expects you to (even if you don't personally like the
system), I am convinced there are fundamentally better ways of dealing with the
problem of safely and consistently updating dependencies.&lt;/p&gt;
&lt;p&gt;It made me want to add &lt;a href="https://github.com/jashkenas/underscore/issues/1805#issuecomment-66929684"&gt;my two cents to the
discussion&lt;/a&gt;,
as someone who's more of a dabbler in programming and not really part of the
community, so feel free to ignore me :) I attach my commentary below for
reference (it's virtually the same text as in the link above).&lt;/p&gt;
&lt;h1&gt;tl;dr&lt;/h1&gt;
&lt;p&gt;semver is trying to do the right thing, but doing it wrong -- instead of
&lt;strong&gt;implicitly&lt;/strong&gt; encoding severity of change information in &lt;strong&gt;version numbers&lt;/strong&gt;,
&lt;strong&gt;explicit keywords&lt;/strong&gt; like :patch, :potentially-breaking or :major-api-change
would make much more sense.&lt;/p&gt;
&lt;h1&gt;More verbosely&lt;/h1&gt;
&lt;p&gt;I've always found the goals of semver worthy, but this thread has made me
realize that while its aims are commendable, its methods are kind of broken:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;semver tries to take an existing semiotic system (= version numbers), which
has developed informally and is therefore a loose convention rather than an
exact spec, and reinterpret it in terms of an exact spec (or impose that spec on
it). trouble is, the prior informal meaning won't go away so easily (why should
it?), especially for projects that have been around longer than semver. the
problem then is, since the two systems (the informal one and semver) look the
same in terms of their symbolic representation, it's hard to guess which one
you're dealing with by just eyeballing the version number of a library (or
project in general).&lt;/p&gt;
&lt;p&gt;it's like if someone decided that "f*ck" should mean "orchid" from now on,
because it's nicer -- on hearing the word, you'd never know if it's being
used as the original profanity, or in its new meaning. homonymy is a pain to
deal with when it's accidental (cf. NLP), so why introduce it on purpose?
the job that semver set out to do should be fulfilled by a new formal means
which is instantly recognizable, not by hijacking an existing one and
overlaying additional interpretation on it and thus making it &lt;strong&gt;ambiguous&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;even if version numbers hadn't existed before semver, they're terribly
&lt;strong&gt;inadequate&lt;/strong&gt; for the purpose of conveying information about the severity of
changes introduced by an update (though I understand their appeal to
mathematically-minded people). they're inadequate because they're &lt;strong&gt;implicit&lt;/strong&gt;
-- it's a bit like if someone decided they don't need hash maps because they can
make do with arrays by remembering the order in which they're adding in the
key-val pairs. if I remember the order, then I know which key the given index
implicitly refers to, and the result is as good as a hash map, isn't it?&lt;/p&gt;
&lt;p&gt;except it isn't. keys are useful because they have &lt;strong&gt;explicit semantics&lt;/strong&gt;,
making it instantly clear what kind of value you're retrieving. in the same
way, encoding the information about the severity of changes into version
numbers makes it implicit (in addition to being ambiguous, as stated
previously). why not use explicit keyword tags along with the version number
(which can be romantic, semantic -- whichever floats the dev team's boat and
best reflects the progress of the project) to give a heads up as to the
nature of the update? e.g. :patch, :potentially-breaking, :major-api-change
etc.&lt;/p&gt;
&lt;p&gt;granted, even language is a code which needs to be learned, like semver
(gross oversimplification here, but let's not get into the details of
language acquisition), but since it's widely established and
conventionalized for conveying the kinds of meanings semver is trying to
convey, &lt;strong&gt;why not just use it when it's available&lt;/strong&gt;? why use a system
(version numbers) which is less well-suited to the purpose &lt;strong&gt;and&lt;/strong&gt; ambiguous
to boot?&lt;/p&gt;
&lt;p&gt;(on the other hand, numbers are eminently well-suited for keeping track of
which version is newer than which and how much so -- the original purpose of
version numbering -- because they are designed to have orderings defined on
them. by contrast, words would do a terrible job at this. if you care to
indicate the evolution of your codebase, you might introduce your own
disciplined &lt;a href="http://sentimentalversioning.org/"&gt;romantic or sentimental&lt;/a&gt;
versioning scheme, which ironically is a more meaningful and ergo semantic
way of doing versioning than semver, because it sticks to the conventional
semantics of numbers (the closer the numbers, the more similar the
versions). if you don't care about this, which is perfectly fine, you might
as well use dates for version numbers.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;keyword tags have the advantage that they're instantly human-readable by anyone
who has a basic command of English. if there is sufficient will in the
community, a useful subset can be frozen in a binding spec, so that they are
machine-readable as well.&lt;/p&gt;
&lt;p&gt;I'm not sure whether these keywords should be an appendix to the version number
(like v2.3.4-:potentially-breaking), or whether the information they provide
should be more extensive and included in a formalized preamble to the changelog
(finally forcing people to at least take a glance at it ;) ). using the latter
approach, the information provided could be (optionally) even more targeted,
e.g. detailing explicitly which parts of the API are affected in a non-backwards
compatible manner by the update.&lt;/p&gt;
&lt;p&gt;anyways, just a few ideas :) I am not primarily a coder, so there may be obvious
drawbacks to this scheme that I can't see or which have already been discussed
by the community on multiple occasions which have escaped my attention. in which
case, please bear with me and excuse my lack of sophistication.&lt;/p&gt;</summary><category term="floss"></category><category term="semver"></category><category term="versioning"></category><category term="underscore.js"></category><category term="library"></category><category term="development"></category><category term="dependency"></category></entry><entry><title>Filling (hardwrapping) paragraphs in Airmail with `par`</title><link href="http://dlukes.github.io/fill-par-in-airmail.html" rel="alternate"></link><published>2014-06-27T00:00:00+02:00</published><author><name>dlukes</name></author><id>tag:dlukes.github.io,2014-06-27:fill-par-in-airmail.html</id><summary type="html">&lt;h1&gt;tl;dr&lt;/h1&gt;
&lt;p&gt;Jump directly to &lt;a href="#solution"&gt;the proposed solution&lt;/a&gt;. Tested on OS X 10.9
(Mavericks).&lt;/p&gt;
&lt;h1&gt;Back story&lt;/h1&gt;
&lt;p&gt;Airmail is a great application -- being very happy with Gmail's in-browser UI,
it's honestly the first e-mail desktop client that I ever felt even remotely
tempted to use. It has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a sleek, functional design&lt;/li&gt;
&lt;li&gt;almost flawless integration with Gmail (except for categories -- but there's
a
&lt;a href="http://airmail.tenderapp.com/help/discussions/suggestion-new-features/396-workaround-for-gmail-categories"&gt;not-too-hackish way&lt;/a&gt;
to deal with those)&lt;/li&gt;
&lt;li&gt;a Markdown compose mode (yay!) -- and tons of other good stuff.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Especially that last feature almost got me sold -- you see, I like my e-mail
hardwrapped (what Emacs calls "filling paragraphs"), because most of the time,
I view it on monitors that are too wide for soft line wrapping to achieve a
comfortable text width.&lt;/p&gt;
&lt;p&gt;(By the way, Airmail's layout deals with this issue very elegantly, but I know
I won't be using only Airmail. Plus there are the obvious
&lt;a href="https://wiki.openstack.org/wiki/MailingListEtiquette#Line_Wrapping"&gt;netiquette issues&lt;/a&gt;
-- lines "should be" wrapped at 72 characters etc.)&lt;/p&gt;
&lt;p&gt;In Gmail, I therefore use plain-text compose, which is fine for the purposes
described above, but frustrating whenever you want to apply formatting
(obviously, you can't -- it's plain text). I tried using the usual replacements
for formatting like stars &amp;amp; co., and I don't know about your grandma, but
&lt;em&gt;mine&lt;/em&gt; certainly doesn't take *...* to mean emphasis.&lt;/p&gt;
&lt;p&gt;I thought the Markdown compose mode in Airmail would solve my problems -- I
could apply formatting if and when I wanted (using the frankly more streamlined
process of &lt;em&gt;typing it in&lt;/em&gt; rather than fumbling around for the right button in
the GUI) &lt;em&gt;and&lt;/em&gt; fill my paragraphs, because I somehow automatically assumed
there'd by a hard-wrap feature like in any decent editor (read: emacs or
vi). Markdown is plain text after all, isn't it?&lt;/p&gt;
&lt;p&gt;Long story short, as of yet, &lt;strong&gt;there isn't&lt;/strong&gt;. There isn't even one for the
plain-text compose mode, as far as I'm aware. So I added my two cents to
&lt;a href="http://feedback.airmailapp.com/forums/209001-airmail-mac-1-2/suggestions/4078595-add-line-wrap-for-plain-text-mails"&gt;this feature request thread&lt;/a&gt;
and went back to the Gmail in-browser UI.&lt;/p&gt;
&lt;h1&gt;Solution &lt;a name="solution"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;But then I realized (it took me a while, I'm still very much an OS X newbie):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;in OS X, you can define custom actions with shortcuts&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; for any
   application using Automator Services&lt;/li&gt;
&lt;li&gt;these actions can be easily set to receive text selected in the application
   as input&lt;/li&gt;
&lt;li&gt;these actions can also involve shell scripts&lt;/li&gt;
&lt;li&gt;there already &lt;em&gt;is&lt;/em&gt; a great (command line) program for filling paragraphs --
   it's called &lt;code&gt;par&lt;/code&gt;, and as much as I admire what Airmail's developers have
   achieved, it's unlikely that they'd come up with a more sophisticated
   hard-wrapping algorithm than &lt;code&gt;par&lt;/code&gt;'s simply as a side project for Airmail
   (see the EXAMPLES section in &lt;code&gt;man par&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With that in mind, you can have hard-wrapping in Markdown or plain-text Airmail
compose at your fingertips in no time flat. If you don't have &lt;code&gt;homebrew&lt;/code&gt;, start
by installing that (or any other ports manager that will allow you to install
&lt;code&gt;par&lt;/code&gt;; I'll assume &lt;code&gt;homebrew&lt;/code&gt; below) by pasting&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;at a Terminal prompt. Then:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;install &lt;code&gt;par&lt;/code&gt; with &lt;code&gt;brew install par&lt;/code&gt; at a Terminal prompt&lt;/li&gt;
&lt;li&gt;open Automator (e.g. by typing "Automator" into Spotlight) and create a new
   Service&lt;/li&gt;
&lt;li&gt;select the applications for which you want the service to be active (for me,
   that's just Airmail) and tick the "Output replaces selected text" box&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;drag the "Run Shell Script" action onto the workflow canvas, and as the
   shell script, paste in&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;PARINIT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;rTbgqR B=.,?_A_a Q=_s&amp;gt;|&amp;quot;&lt;/span&gt; /usr/local/bin/par 79
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;the $PARINIT environment variable contains the default recommended
  settings for &lt;code&gt;par&lt;/code&gt; (if you want to customize its behavior, you can -- good
  luck wrapping your head around &lt;code&gt;par&lt;/code&gt;'s manpage, though)&lt;/li&gt;
&lt;li&gt;you should set the full path to the &lt;code&gt;par&lt;/code&gt; executable, the shell spawned by
  the Service might not inherit your $PATH -- for &lt;code&gt;par&lt;/code&gt; installed via
  &lt;code&gt;homebrew&lt;/code&gt;, it's &lt;code&gt;/usr/local/bin/par&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;the parameter at the end is the max number of characters per
  line -- mailing list etiquette stipulates 72, I personally prefer the
  pythonesque 79, but it's your choice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, your service should look something like in the screenshot
below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Fill Paragraph Service in Automator" src="images/fill-par.png" /&gt;&lt;/p&gt;
&lt;p&gt;Save it, open Keyboard preferences (type "Keyboard" into Spotlight), navigate
to Shortcuts → Services → Text and set a keyboard shortcut for your newly
created Service, e.g. Cmd+Opt+P. Next time you compose an e-mail in Airmail,
just select the entire text when you're done (Cmd+A), press Cmd+Opt+P, and
voilà! Your lines have been hardwrapped, your paragraphs filled :) (Same thing,
I know.)&lt;/p&gt;
&lt;p&gt;If the shortcut doesn't appear to work&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, try fiddling around with it,
resetting it (maybe the one you've chosen conflicts with a pre-existing one?),
restarting Airmail, logging out and back in, rebooting... The custom shortcut
part is unfortunately the least reliable aspect of this whole setup. Automator
is a great idea, I was pleasantly surprised by it when I started using OS X a
few days back, but it could seriously use some bug-squashing.&lt;/p&gt;
&lt;p&gt;If you fail miserably at getting the shortcut to work, you can &lt;strong&gt;still access
your fill paragraph service via the menu&lt;/strong&gt; (select the text you want to
hard-wrap, then navigate to Airmail → Services → &amp;lt;name of your fill paragraph
service&gt;). Clicking around in a GUI is tedious (though hey -- it's the Apple
way after all, isn't it?), but it shouldn't be too much of a bother since you
need to do it only once per e-mail.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bottom line&lt;/strong&gt;: I am now officially completely sold on Airmail (even bought
the released version instead of using the free beta) and look forward to the
joy of using it!&lt;/p&gt;
&lt;p&gt;EDIT: In order to have the &lt;strong&gt;least trouble possible getting the shell script up
and running as a Service&lt;/strong&gt;, two rules of thumb:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Leave it completely up to OS X where it stores the Service (.workflow)
   file. This will probably be in &lt;code&gt;~/Library/Services&lt;/code&gt;, and I learnt the hard
   way not to tinker with it -- if &lt;code&gt;Services&lt;/code&gt; is a symlink instead of a real
   directory, the OS won't discover new Service files (though old ones will
   still be accessible).&lt;/li&gt;
&lt;li&gt;If the Service doesn't show up in the keyboard shortcuts menu after
   creation, try refreshing the service list with
   &lt;code&gt;/System/Library/CoreServices/pbs -update&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Those shortcuts are in fact quite buggy, especially those that you want
to be global (not specific to a concrete app) -- at least on Mavericks (OS
X 10.9). They tend to get disabled on a whim, especially if you tinker with
them, and are a pain to get working again (login, logout, reboot -- anything
goes). If anyone knows why, please let me know!&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="osx"></category><category term="par"></category><category term="airmail"></category><category term="automator"></category><category term="services"></category><category term="fill"></category><category term="wrap"></category><category term="lines"></category></entry></feed>